---
title: "Topographic, single-cell gene expression profiling of Periaqueductal Gray neurons"
subtitle: "Part III: normalization and batch correction"
author:
  - name: "Oriol Pavón Arocas, Sarah F. Olesen and Tiago Branco"
    affiliation: "Sainsbury Wellcome Centre for Neural Circuits and Behaviour, University College London, UK"
    email: "oriol.pavon.16@ucl.ac.uk"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_notebook:
    highlight: pygments
    number_sections: FALSE
    theme: lumen
    toc: TRUE
    toc_float: TRUE

#output: rmdformats::readthedown:
  #highlight: pygments
---

***
This is a pipeline to analyse single-cell RNA sequencing data from Periaqueductal Gray neurons (1) isolated from acute midbrain slices of transgenic mice using visually guided aspiration via patch pipettes and (2) processed using SMART-seq2 (Picelli et al. Nature Protocols 2014). 

This pipeline has been generated following the online course on [Analysis of single cell RNA-seq data](https://github.com/hemberg-lab/scRNA.seq.course) by the [Hemberg Lab](http://hemberg-lab.github.io/scRNA.seq.course), the [Orchestrating Single-Cell Analysis with Bioconductor book](https://osca.bioconductor.org/) by Robert Amezquita and Stephanie Hicks, the [simpleSingleCell workflow in Bioconductor](https://bioconductor.org/packages/3.8/workflows/html/simpleSingleCell.html) maintained by Aaron Lun, and by attending the [EMBL-EBI RNA-Sequence Analysis Course](https://www.ebi.ac.uk/training/events/2019/rna-sequence-analysis).

Other key resources are Bioconductor (Huber et al. Nature Methods 2015), scater (McCarty et al. Bioinformatics 2017), scran (Lun et al. F1000Res 2016), and SC3 (Kiselev et al. Nature Methods 2017).

***

# STEP 3 | Normalization of cell-specific biases
_The following theory has been summarised from the online course on [Analysis of single cell RNA-seq data](https://github.com/hemberg-lab/scRNA.seq.course) by the [Hemberg Lab](http://hemberg-lab.github.io/scRNA.seq.course)._

Library sizes vary because scRNA-seq data is often sequenced on highly multiplexed platforms and the total reads which are derived from each cell may differ substantially. Library size must be corrected for by multiplying or dividing each column of the expression matrix by a normalization factor which is an estimate of the library size relative to the other cells. Many methods to correct for library size have been developped for bulk RNA-seq (e.g. UQ, SF, CPM, RPKM, FPKM, TPM).

* __Upperquartile (UQ)__: In the upperquartile method (Bullard et al. 2010), each column is divided by the 75% quantile of the counts for each library. Often the calculated quantile is scaled by the median across cells to keep the absolute level of expression relatively consistent. A drawback to this method is that for low-depth scRNASeq experiments the large number of undetected genes may result in the 75% quantile being zero (or close to it). This limitation can be overcome by generalizing the idea and using a higher quantile (eg. the 99% quantile is the default in scater) or by excluding zeros prior to calculating the 75% quantile.

* __Relative log expression (RLE) size factor (SF)__: The size factor (SF) was proposed and popularized by DESeq (Anders and Huber 2010). First the geometric mean of each gene across all cells is calculated. The size factor for each cell is the median across genes of the ratio of the expression to the gene geometric mean. A drawback to this method is that since it uses the geometric mean only genes with non-zero expression values across all cells can be used in its calculation, making it unadvisable for large low-depth scRNASeq experiments.

* __CPM (counts per million)__: The simplest way to normalize RNAseq data is to convert it to counts per million (CPM) by dividing each column by its total then multiplying by 1,000,000. __RPKM__ (read per kilobase per milion), __FPKM__ (fragment per kilobase per million) and __TPM__ (transcripts per million) are variants on CPM which further adjust counts by the length of the respective gene/transcript. 
    + Spike-ins should be excluded from the calculation of total expression in order to correct for total cell RNA content (we should only use endogenous genes).
    + One potential drawback of CPM is if your sample contains genes that are both very highly expressed and differentially expressed across the cells. In this case, the total molecules in the cell may depend of whether such genes are on/off in the cell and normalizing by total molecules may hide the differential expression of those genes and/or falsely create differential expression for the remaining genes.  

* __scran (scRNAseq specific)__: The `scran` package implements a variant on CPM specialized for single-cell data (Lun et al. Genome Biology 2016). Briefly this method deals with the problem of vary large numbers of zero values per cell by pooling cells together calculating a normalization factor (similar to CPM) for the sum of each pool. Since each cell is found in many different pools, cell-specific factors can be deconvoluted from the collection of pool-specific factors using linear algebra.

* __SCnorm (scRNAseq specific)__: Another method developed to normalize scRNAseq data (Bacher et al. Nature Methods 2017).

***
__A note on scaling normalization strategies__ from the [simpleSingleCell workflow in Bioconductor](https://bioconductor.org/packages/3.8/workflows/html/simpleSingleCell.html) maintained by Aaron Lun.

Scaling normalization strategies for scRNA-seq data can be broadly divided into two classes. The first class assumes that there exists a subset of genes that are not DE between samples. The second class uses the fact that the same amount of spike-in RNA was added to each cell, and therefore differences in the coverage of the spike-in transcripts can only be due to cell-specific biases (e.g., in capture efficiency or sequencing depth). Scaling normalization is then applied to equalize spike-in coverage across cells.

The choice between these two normalization strategies depends on the biology of the cells and the features of interest. If the majority of genes are expected to be DE and there is no reliable house-keeping set, spike-in normalization may be the only option for removing cell-specific biases. Spike-in normalization should also be used if differences in the total RNA content of individual cells are of interest. In any particular cell, an increase in the amount of endogenous RNA will not increase spike-in coverage (with or without library quantification). Thus, the former will not be represented as part of the bias in the latter, which means that the effects of total RNA content on expression will not be removed upon scaling. With non-DE normalization, an increase in RNA content will systematically increase the expression of all genes in the non-DE subset, such that it will be treated as bias and removed.

In our case, we expect our dataset to contain a homogeneous population of neurons, with the majority of genes not differentially expressed between samples. Therefore, we will compute size factors separately for endogenous and spike-in transcripts.

## Step 3.1 | Compute size factors for endogenous genes
We will use `scran` to calculate size factors for our samples and then use them for normalization. Importantly, see Vallejos et al., Nature Methos 2017 for an explanation of why it is not a good idea to use CPM normalization on scRNAseq data.
```{r}
# If starting from stored results, load saved filtered dataset from previous Step:
set.seed(1991)
options(stringsAsFactors = FALSE)
library(SingleCellExperiment)
library(scater)
library(scran)

PAG_sceset_qc <- readRDS("PAG_sceset_qc.rds") # Contains filtered cells and genes
assayNames(PAG_sceset_qc)
```

We should __not__ include spike-ins in the normalization step, as we want to normalize by the genes each cell endogenously expressed. We can later calculate separate size factors for the spike-in transcripts.
```{r}
# For large datasets of highly heterogeneous data with multiple cell types we should run a preclustering step:
# qclust <- quickCluster(PAG_sceset_qc, min.size = 30)
# PAG_sceset_qc <- computeSumFactors(PAG_sceset_qc, sizes = 15, clusters = qclust)
# PAG_sceset_qc <- normalize(PAG_sceset_qc)

# For small datasets like ours (< 1000 samples), the quickCluster step above can be ommited and we can run computeSumFactors straight away.
PAG_sceset_qc <- computeSumFactors(PAG_sceset_qc, sizes=seq(21, 101, 5))
```

`scran` sometimes calculates negative or zero size factors. These will completely distort the normalized expression matrix. If you find scran has calculated negative size factors try increasing the cluster and pool sizes until they are all positive. We can check the size factors scran has computed:
```{r}
summary(sizeFactors(PAG_sceset_qc))
```

Plotting the size factors against the library sizes should show some positive correlation.
```{r}
plot(sizeFactors(PAG_sceset_qc), PAG_sceset_qc$total_counts/1e6, log="xy", ylab="Library size (millions)", xlab="Size factor")
```
The size factors are tightly correlated with the library sizes for all cells. This suggests that the systematic differences between cells are primarily driven by differences in capture efficiency or sequencing depth. Any DE between cells would yield a non-linear trend between the total count and size factor, and/or increased scatter around the trend. This does not occur here as strong DE is unlikely to exist within a homogeneous population of cells.

## Step 3.2 | Compute size factors for spike-in transcripts
Size factors computed from the counts for endogenous genes are usually not appropriate for normalizing the counts for spike-in transcripts. The normalization we implemented in the previous step corrects for RNA content. HOwever, spike-in transcripts are not affected by RNA content, as we theoretically added the same amount to each sample. Therefore, using gene-based size factors would "over-normalize" spike-ins. To ensure spike-in normalization is performed correctly, we compute a separate set of size factors for the spike-in set. For each cell, the spike-in-specific size factor is defined as the total count across all transcripts in the spike-in set.

These size factors are stored in a separate field of the `SCE` object by setting `general.use=FALSE` in `computeSpikeFactors`. This ensures that they will only be used with the spike-in transcripts and not the endogenous genes. Although we are only using spike-ins for quality control, we could use the spike-in size factors to normalize all genes by setting `general.use=TRUE`.
```{r}
PAG_sceset_qc <- computeSpikeFactors(PAG_sceset_qc, type="ERCC", general.use=FALSE)
summary(sizeFactors(PAG_sceset_qc, "ERCC"))
```

The two sets of size factors tend to agree less due to the effects of heterogeneity in total RNA content between cells - this is expected.
```{r}
plot(sizeFactors(PAG_sceset_qc, 'ERCC'), 
     sizeFactors(PAG_sceset_qc),
    log="xy", 
    xlab="Size factor (ERCC)", 
    ylab="Size factor (genes)")
```

_If we were to apply the the spike-in factors to all counts, we would set `general.use=TRUE` and use the `computeSpikeFactors` method to estimate size factors for all cells. This would compute the total count over all spike-in transcripts in each cell, and calculate size factors to equalize the total spike-in count across cells. Finally, running normalize would use the spike-in-based size factors to compute normalized log-expression values, and unlike what we actually did, we would not have to define separate size factors for the spike-in transcripts, as the relevant factors would already be used for all genes and spike-in transcripts when `general.use=TRUE`._

## Step 3.3 | Apply the size factors to normalize gene expression
The count data are used to compute normalized log-expression values for use in downstream analyses. Each value is defined as the log-ratio of each count to the size factor for the corresponding cell, after adding a pseudo-count of 1 to avoid undefined values at zero counts. Division of the counts for each gene by its appropriate size factor ensures that any cell-specific biases are removed. If spike-in-specific size factors are present in `SCE`, they will be automatically applied to normalize the spike-in transcripts separately from the endogenous genes.

The log-transformation provides some measure of variance stabilization (Law et al., 2014), so that high-abundance genes with large variances do not dominate downstream analyses. The computed values are stored as an expression matrix in addition to the other assay elements.
```{r}
PAG_sceset_qc <- normalize(PAG_sceset_qc)
assayNames(PAG_sceset_qc)
```

## Step 3.4 | Compare the effects of different normalization strategies
To compare the efficiency of different normalization methods we can use visual inspection of PCA plots and calculation of cell-wise relative log expression via scater's plotRLE() function. Namely, cells with many (few) reads have higher (lower) than median expression for most genes resulting in a positive (negative) RLE across the cell, whereas normalized cells have an RLE close to zero.

If we look at the RLE plot, the graph shows a box plot of the RLE values for each cell (each line is a boxplot), the circles indicate the median (nearly all should be at 0 after normalization), and the line indicates the interquartile range.
```{r}
library(ggplot2)

# Without log-transformation
p1 <- plotRLE(
    PAG_sceset_qc, 
    exprs_values = "counts",
    exprs_logged = TRUE,
    legend = TRUE#,
    #colour_by = "mouse.id"
) + ggtitle("Raw counts")

# With log-transformation
p2 <- plotRLE(
    PAG_sceset_qc, 
    exprs_values = "logcounts_raw",
    exprs_logged = TRUE,
    legend = TRUE,
    colour_by = "mouse.id"
) + ggtitle("Logcounts Raw")

# After scran normalization
p3 <- plotRLE(
    PAG_sceset_qc, 
    exprs_values = "logcounts",
    exprs_logged = TRUE,
    legend = TRUE#,
    #colour_by = "mouse.id"
) + ggtitle("scran")

multiplot(p1, p2, p3, cols=2)
```

# STEP 4 | Batch correction

## STEP 3.2: Identifying confounding and technical factors [NEEDS COMPLETED METADATA]
A big source of variability in scRNA-seq data, besides bad cells, are batch effects: the person processing the samples, date of processing, reagent kit, etc. We want to try to identify such effects and remove them, so our dataset picks up mainly biological effects.

### STEP 3.2.1: Checking for important technical factors or explanatory variables
We check whether there are technical factors that contribute substantially to the heterogeneity of gene expression. If so, the factor may need to be regressed out to ensure that it does not inflate the variances or introduce spurious correlations. scater can compute the marginal R2 for each variable when fitting a linear model regressing expression values for each gene against just that variable, and display a density plot of the gene-wise marginal R2 values for the variables.

For each gene, it calculates the percentage of the variance of the expression values that is explained by the variable. Small percentages (1-3%) indicate that the expression profiles of most genes are not strongly associated with this factor. If, on the other hand, we get density curves that are shifted to the right (i.e. with a peak towards the 100% end of the x-axis), this tells us that for a large proportion of the genes in our dataset this particular variable explains a large proportion of the variation.
```{r}
# How much of the variance does each variable explain? Some of these variables are calculated when we run the CalculateQC function from scater, and others are added by us (such as batch or individual).

# Without log-transformation
explV1 <- plotExplanatoryVariables(
    PAG_sceset_qc,
    nvars_to_plot = 10,
    exprs_values = "counts",
    variables = c(
        "total_features_by_counts",
        "total_counts",
        #"pct_counts_ERCC",
        "pct_counts_Mitochondrial",
        "pct_counts_Ribosomal",
        "mouse.id",
        "mouse.sex",
        "mouse.age",
        "cell.type",
        "PAG.hemisphere",
        "PAG.areacollection"
    )
) + ggtitle("Raw counts")

# With log-transformatio
explV2 <- plotExplanatoryVariables(
    PAG_sceset_qc,
    nvars_to_plot = 10,
    exprs_values = "logcounts_raw",
    variables = c(
        "total_features_by_counts",
        "total_counts",
        #"pct_counts_ERCC",
        "pct_counts_Mitochondrial",
        "pct_counts_Ribosomal",
        "mouse.id",
        "mouse.sex",
        "mouse.age",
        "cell.type",
        "PAG.hemisphere",
        "PAG.areacollection"
    )
) + ggtitle("Logcounts Raw")

# After scran normalization
explV3 <- plotExplanatoryVariables(
    PAG_sceset_qc,
    nvars_to_plot = 10,
    exprs_values = "logcounts",
    variables = c(
        "total_features_by_counts",
        "total_counts",
        #"pct_counts_ERCC",
        "pct_counts_Mitochondrial",
        "pct_counts_Ribosomal",
        "mouse.id",
        "mouse.sex",
        "mouse.age",
        "cell.type",
        "PAG.hemisphere",
        "PAG.areacollection"
    )
) + ggtitle("Scran")

multiplot(explV1, explV2, explV3, cols=2)
```

After identifying important confounding factors and explanatory variables, scater allows us to account for these variables in subsequent statistical models or to condition them out using __normaliseExprs()__.

[190404] Seems like normaliseExprs() has been deprecated in favor to computeSumFactors(). How to model/regress confounding factors?

### STEP 3.2.2: Correlations with Principal Components
scater allows one to identify principal components that correlate with experimental and QC variables of interest (it ranks principle components by R2 from a linear model regressing PC value against any variable or annotation we have associated with each cell) to see which factor is driving a particular principal component.
```{r}
plotExplanatoryPCs(PAG_sceset_qc,
                   nvars_to_plot = 10,
                   npcs_to_plot = 10,
                   exprs_values = "logcounts", 
                   variables = c(
                     "total_features_by_counts",
                     "total_counts",
                     #"pct_counts_ERCC",
                     "pct_counts_Mitochondrial",
                     "pct_counts_Ribosomal",
                     "mouse.id",
                     "mouse.sex",
                     "mouse.age",
                     "cell.type",
                     "PAG.hemisphere",
                     "PAG.areacollection"
                   )
)
```
It seems that component 1 correlates quite well with the number of detected genes.

## STEP 3.3: Dealing with confounders (Batch correction) [TO DO] 
To account for technical confounders we need to identify and remove sources of variation in the expression data that are not related to the biological signal of interest. We could use spike-ins for this (in theory you add the same amount of ERCC in each cell lysate, so any variability should be technical noise), but in our case these turn out to be extremely variable across cells. Instead, we could use endogenous or housekeeping genes that do not vary systematically between cells. Where we have a large number of endogenous genes that, on average, do not vary systematically between cells and where we expect technical effects to affect a large number of genes (a very common and reasonable assumption), then such methods (for example, the RUVs method) can perform well.

NOTE: you can't really use any of the methods, as you don't have a balanced design (for the first samples each animal was processed in a different batch for library preparation). You could try it with the last samples, as we managed to get a balanced desing (samples from each animal were processed together).

You can't really use RUVseq (remove unwanted variation) as it depends on ERCCs having a constant expression across samples (which we know is not the case in our data, as they are pretty variable). You could try GLM (generalised linear model) or RUVs.

Try different methods and evaluate their effectiveness.

See: http://hemberg-lab.github.io/scRNA.seq.course/cleaning-the-expression-matrix.html#dealing-with-confounders

### Exploring obvious biases with the table function
The table function allows us to quickly inspect if we have any obvious biases or confounds (i.e. all the cells come from male or female mice, or from a particular location or sequencing batch).
```{r}
# Check if any technical factors are confounded
table(PAG_sceset$cell.type, PAG_sceset$PAG.hemisphere)
table(PAG_sceset$cell.type, PAG_sceset$mouse.sex)
#table(PAG_sceset$cell.type, PAG_sceset$reads.mitochondrial)
```

```{r}
# You can also check the distribution of each of these metadata classifications:
summary(factor(PAG_sceset$cell.type))
summary(factor(PAG_sceset$PAG.hemisphere))
summary(factor(PAG_sceset$PAG.areacollection))
summary(factor(PAG_sceset$mouse.sex))
```

### Remove Unwanted Variation
- RUVg uses negative control genes (e.g. ERCCs), assumed to have constant expression across samples;

- RUVs uses centered (technical) replicate/negative control samples for which the covariates of interest are constant;

- RUVr uses residuals, e.g., from a first-pass GLM regression of the counts on the covariates of interest.

### Combat
If you have an experiment with a balanced design, Combat can be used to eliminate batch effects while preserving biological effects by specifying the biological effects using the mod parameter.

### mnnCorrect
This method was developed to merge different datasets obtained from the same biological system.
mnnCorrect (Haghverdi et al. 2017) assumes that each batch shares at least one biological condition with each other batch. Thus it works well for a variety of balanced experimental designs. However, the Tung data contains multiple replicates for each invidividual rather than balanced batches, thus we will normalized each individual separately. Note that this will remove batch effects between batches within the same individual but not the batch effects between batches in different individuals, due to the confounded experimental design.

### GLM (generalised linear model)
A general linear model is a simpler version of Combat. It can correct for batches while preserving biological effects if you have a balanced design. In a confounded/replicate design biological effects will not be fit/preserved. Similar to mnnCorrect we could remove batch effects from each individual separately in order to preserve biological (and technical) variance between individuals. 

### Effectiveness of the methods
We can evaluate the effectiveness of the normalization by inspecting the PCA plot where colour corresponds the technical replicates and shape corresponds to different biological samples (individuals). Separation of biological samples and interspersed batches indicates that technical variation has been removed. We always use log2-cpm normalized data to match the assumptions of PCA.
```{r}
for(n in assayNames(PAG_sceset_qc)) {
    print(
        plotPCA(
            PAG_sceset_qc[endogenous_genes, ],
            colour_by = "batch.processing",
            shape_by = "mouse.id",
            size_by = "total_features_by_counts",
            exprs_values = n
        ) +
        ggtitle(n)
    )
}
```

We can also examine the effectiveness of correction using the relative log expression (RLE) across cells to confirm technical noise has been removed from the dataset. Note RLE only evaluates whether the number of genes higher and lower than average are equal for each cell - i.e. systemic technical effects. Random technical noise between batches may not be detected by RLE.
```{r}
res <- list()
for(n in assayNames(PAG_sceset_qc)) {
    res[[n]] <- suppressWarnings(calc_cell_RLE(assay(PAG_sceset_qc, n), erccs))
}
par(mar=c(6,4,1,1))
boxplot(res, las=2)
```

```{r}
for(n in assayNames(PAG_sceset_qc)) {
    print(
        plotQC(
            PAG_sceset_qc[endogenous_genes, ],
            type = "expl",
            exprs_values = n,
            variables = c(
              "total_features_by_counts",
              "total_counts",
              "pct_counts_ERCC",
              "pct_counts_MT",
              "mouse.id",
              "mouse.sex",
              "mouse.age",
              "cell.id",
              "cell.type",
              "cell.fluorophor",
              "cell.number",
              "PAG.hemisphere",
              "PAG.areacollection",
              "slice.depth", 
              "slice.number",
              "time.aspiration",
              "time.sinceslicing",
              "sequencing.round"
            )
        ) +
        ggtitle(n)
    )
}
```

# STEP 5 | Modelling technical and biological variability
## Step 5.1 | Identifying Highly Variable Genes [DO WHEN SPIKE-INS ARE ADDED]
We identify HVGs to focus on the genes that are driving heterogeneity across the population of cells. This requires estimation of the variance in expression for each gene, followed by decomposition of the variance into biological and technical components. HVGs are then identified as those genes with the largest biological components. This avoids prioritizing genes that are highly variable due to technical factors such as sampling noise during RNA capture and library preparation.

Ideally, the technical component would be estimated by fitting a mean-variance trend to the spike-in transcripts using the trendVar function. Recall that the same set of spike-ins was added in the same quantity to each cell. This means that the spike-in transcripts should exhibit no biological variability, i.e., any variance in their counts should be technical in origin. Given the mean abundance of a gene, the fitted value of the trend can be used as an estimate of the technical component for that gene. The biological component of the variance can then be calculated by subtracting the technical component from the total variance of each gene with the decomposeVar function.

In practice, this strategy is compromised by the small number of spike-in transcripts, the uneven distribution of their abundances and (for low numbers of cells) the imprecision of their variance estimates. This makes it difficult to accurately fit a complex mean-dependent trend to the spike-in variances. An alternative approach is to fit the trend to the variance estimates of the endogenous genes, using the use.spikes=FALSE setting as shown below. This assumes that the majority of genes are not variably expressed, such that the technical component dominates the total variance for those genes. The fitted value of the trend is then used as an estimate of the technical component. __NB__: fitting the trend to the variances of the genes with use.spikes=FALSE probably overestimates the technical component.
```{r}
var.fit <- trendVar(PAG_sceset_qc, method="loess", use.spikes=FALSE, loess.args=list(span=0.2)) 
# Try use.spikes=TRUE if you have them
# Some tinkering may be required to get a good fit, usually by modifying span= (default is 0.75).

var.out <- decomposeVar(PAG_sceset_qc, var.fit)
head(var.out)
```

We assess the suitability of the trend fitted to the endogenous variances by examining whether it is consistent with the spike-in variances. If the trend passes through or close to most of the spike-in variances, this indicates that our assumption (that most genes have low levels of biological variability) is valid. This strategy exploits the large number of endogenous genes to obtain a stable trend, with the spike-in transcripts used as diagnostic features rather than in the trend fitting itself. However, if our assumption did not hold, we would instead fit the trend directly to the spike-in variances with the default use.spikes=TRUE. This sacrifices stability to reduce systematic errors in the estimate of the biological component for each gene.
```{r}
spikeNames(PAG_sceset) # Do this only with ERCCs?

plot(var.out$mean, 
     var.out$total, 
     pch=16, cex=0.6, 
     xlab="Mean log-expression", 
     ylab="Variance of log-expression")

o <- order(var.out$mean) 
lines(var.out$mean[o], var.out$tech[o], col="dodgerblue", lwd=2) 
# curve(var.fit$trend(x), add=TRUE, col="dodgerblue", lwd=2)
cur.spike <- isSpike(PAG_sceset_qc) 
points(var.out$mean[cur.spike], var.out$total[cur.spike], col="red", pch=16)
```

HVGs are defined as genes with biological components that are significantly greater than zero at a false discovery rate (FDR) of 5%. These genes are interesting as they drive differences in the expression profiles between cells, and should be prioritized for further investigation. In addition, we only consider a gene to be a HVG if it has a biological component greater than or equal to 0.5. For transformed expression values on the log2 scale, this means that the average difference in true expression between any two cells will be at least 2-fold. (This reasoning assumes that the true log-expression values are Normally distributed with variance of 0.5. The root-mean-square of the difference between two values is treated as the average log2-fold change between cells and is equal to unity.) We rank the results by the biological component to focus on genes with larger biological variability.
```{r}
hvg.out <- var.out[which(var.out$FDR <= 0.05 & var.out$bio >= 0.5),] 
hvg.out <- hvg.out[order(hvg.out$bio, decreasing=TRUE),] 
nrow(hvg.out)

write.table(file="hsc_hvg.tsv", hvg.out, sep="\t", quote=FALSE, col.names=NA) 
head(hvg.out)

# Check the distribution of expression values for the top HVGs to ensure that the variance estimate is not being dominated by one or two outlier cells:
plotExpression(PAG_sceset_qc, rownames(hvg.out)[1:20])
```

### Alternative [do check what happens with data]
It’s wise to check the distribution of expression values for the top HVGs to ensure that the variance estimate is not being dominated by one or two outlier cells.
```{r}
top <- rownames(var.out)[order(var.out$bio, decreasing=TRUE)[1:10]]
plotExpression(sce, features = top)
```

## Step 5.2 | Identifying correlated gene pairs with Spearman's rho
Another useful procedure is to identify the HVGs that are highly correlated with one another. This distinguishes between HVGs caused by random noise and those involved in driving systematic differences between subpopulations. Correlations between genes are quantified by computing Spearman's rho, which accommodates non-linear relationships in the expression values. Gene pairs with significantly large positive or negative values of rho are identified using the correlatePairs function. We only apply this function to the set of HVGs, because these genes have large biological components and are more likely to exhibit strong correlations driven by biology. In contrast, calculating correlations for all possible gene pairs would require too much computational time and increase the severity of the multiple testing correction. It may also prioritize uninteresting genes that have strong correlations but low variance, e.g., tightly co-regulated house-keeping genes.
```{r}
set.seed(1991)
var.cor <- correlatePairs(PAG_sceset_qc, subset.row=rownames(hvg.out)) 
write.table(file="hsc_cor.tsv", var.cor, sep="\t", quote=FALSE, row.names=FALSE) 
head(var.cor)
```

The significance of each correlation is determined using a permutation test. For each pair of genes, the null hypothesis is that the expression profiles of two genes are independent. Shuffling the profiles and recalculating the correlation yields a null distribution that is used to obtain a p-value for each observed correlation value (Phipson & Smyth, 2010). Correction for multiple testing across many gene pairs is performed by controlling the FDR at 5%. Correlated gene pairs can be directly used for experimental validation with orthogonal techniques (e.g., fluorescence-activated cell sorting, immunohistochemistry or RNA fluorescence in situ hybridization) to verify that these expression patterns are genuinely present across the cell population.
```{r}
sig.cor <- var.cor$FDR <= 0.05 
summary(sig.cor)
```

Larger sets of correlated genes are assembled by treating genes as nodes in a graph and each pair of genes with significantly large correlations as an edge. In particular, an undirected graph is constructed using methods in the RBGL package. Highly connected subgraphs are then identified and defined as gene sets. This provides a convenient summary of the pairwise correlations between genes.
```{r}
library(RBGL) 
g <- ftM2graphNEL(cbind(var.cor$gene1, var.cor$gene2)[sig.cor,], W=NULL, V=NULL, edgemode="undirected")
cl <- highlyConnSG(g)$clusters 
cl <- cl[order(lengths(cl), decreasing=TRUE)] 
head(cl)
```

Significant correlations provide evidence for substructure in the dataset, i.e., subpopulations of cells with systematic differences in their expression profiles. The number of significantly correlated HVG pairs represents the strength of the substructure. If many pairs were significant, this would indicate that the subpopulations were clearly defined and distinct from one another. 

## Step 5.3 | Using correlated HVGs for further data exploration
#### Heatmaps
We visualize the expression profiles of the correlated HVGs with a heatmap. All expression values are mean-centred for each gene to highlight the relative differences in expression between cells. If any subpopulations were present, they would manifest as rectangular "blocks" in the heatmap, corresponding to sets of genes that are systematically up- or down-regulated in specific groups of cells. 
```{r}
chosen <- unique(c(var.cor$gene1[sig.cor], var.cor$gene2[sig.cor])) 
norm.exprs <- exprs(PAG_sceset_qc)[chosen,,drop=FALSE] 
heat.vals <- norm.exprs - rowMeans(norm.exprs) 
library(gplots) 
heat.out <- heatmap.2(heat.vals, col=bluered, symbreak=TRUE, trace='none', cexRow=0.6)
```

#### PCA
We also apply dimensionality reduction techniques to visualize the relationships between cells. This is done by constructing a PCA plot from the normalized log-expression values of the correlated HVGs. Cells with similar expression profiles should be located close together in the plot, while dissimilar cells should be far apart. We only use the correlated HVGs in plotPCA because any substructure should be most pronounced in the expression profiles of these genes.
```{r}
plotPCA(
    PAG_sceset_qc[endogenous_genes, ],
    rerun = TRUE,
    run_args = list(feature_set = chosen),
    colour_by = "PAG.areacollection",
    size_by = "total_features_by_counts"
)
```

Additional components can be visualized by increasing the ncomponents argument in plotPCA to construct pairwise plots. The percentage of variance explained by each component can also be obtained by running plotPCA with return_SCESet=TRUE, and then calling reducedDimension on the returned object. This information may be useful for selecting high-variance components (possibly corresponding to interesting underlying factors) for further examination.

#### tSNE
Another widely used approach is the t-stochastic neighbour embedding (t-SNE) method (Van der Maaten & Hinton, 2008). t-SNE tends to work better than PCA for separating cells in more diverse populations. This is because the former can directly capture non-linear relationships in high-dimensional space, whereas the latter must represent them (suboptimally) as linear components. However, this improvement comes at the cost of more computational effort and complexity. In particular, t-SNE is a stochastic method, so users should run the algorithm several times to ensure that the results are representative, and then set a seed to ensure that the chosen results are reproducible. It is also advisable to test different settings of the "perplexity" parameter as this will affect the distribution of points in the low-dimensional space.
```{r}
set.seed(1991) 
out5 <- plotTSNE(
  PAG_sceset_qc[endogenous_genes, ],
  rerun = TRUE, 
  run_args = list(perplexity=5, feature_set=chosen),
  colour_by="Slc17a6"
) + ggtitle("Perplexity = 5")

out10 <- plotTSNE(
  PAG_sceset_qc[endogenous_genes, ],
  rerun = TRUE, 
  run_args = list(perplexity=10, feature_set=chosen),
  colour_by="Slc17a6"
) + ggtitle("Perplexity = 10")

out20 <- plotTSNE(
  PAG_sceset_qc[endogenous_genes, ],
  rerun = TRUE, 
  run_args = list(perplexity=20, feature_set=chosen),
  colour_by="Slc17a6"
) + ggtitle("Perplexity = 20")

out50 <- plotTSNE(
  PAG_sceset_qc[endogenous_genes, ],
  rerun = TRUE, 
  run_args = list(perplexity=50, feature_set=chosen),
  colour_by="Drd1",
  shape_by="PAG.areacollection"
) + ggtitle("Perplexity = 50")

multiplot(out5, out10, out20, out50, cols=2)
```

# 2.7.1 | One last thing...
Consider dropping any Ribosomal, Mitochondrial, ERCC, transgenes (EYFP, tdTomato, Cre) and genes used for transgenic labeling of cells (VGAT and VGluT2) from the dataset before proceeding to downstream analysis, as they will not be biologically informative.
```{r}
# sceset <- sceset[!fData(sceset)$is_feature_control_Mitochondrial, ]
```
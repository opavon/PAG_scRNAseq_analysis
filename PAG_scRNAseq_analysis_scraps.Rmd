---
title: "Topographic, single-cell gene expression profiling of Periaqueductal Gray neurons"
subtitle: "Code scraps"
author:
  - name: "Oriol Pavon Arocas, Sarah F. Olesen, and Tiago Branco"
    affiliation: "Sainsbury Wellcome Centre for Neural Circuits and Behaviour, University College London, UK"
    email: "oriol.pavon.16@ucl.ac.uk"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_notebook:
    highlight: pygments
    number_sections: FALSE
    theme: lumen
    toc: TRUE
    toc_float: TRUE

#output: rmdformats::readthedown:
  #highlight: pygments
---

***
This is a pipeline to analyse single-cell RNA sequencing data from Periaqueductal Gray neurons (1) isolated from acute midbrain slices of transgenic mice using visually guided aspiration via patch pipettes and (2) processed using SMART-seq2 (Picelli et al. Nature Protocols 2014). 

This pipeline has been generated after attending the [EMBL-EBI RNA-Sequence Analysis Course](https://www.ebi.ac.uk/training/events/2019/rna-sequence-analysis) and [attending](https://training.csx.cam.ac.uk/bioinformatics/event/2823386) and following the online course on [Analysis of single cell RNA-seq data](https://github.com/hemberg-lab/scRNA.seq.course) by the [Hemberg Lab](https://www.sanger.ac.uk/science/groups/hemberg-group). Many other resources have been used, including the [Orchestrating Single-Cell Analysis with Bioconductor book](https://osca.bioconductor.org/) by Robert Amezquita and Stephanie Hicks, the [simpleSingleCell workflow in Bioconductor](https://bioconductor.org/packages/3.9/workflows/html/simpleSingleCell.html) maintained by Aaron Lun, the [rnaseqGene workflow](https://bioconductor.org/packages/release/workflows/html/rnaseqGene.html) maintained by Michael Love, the [RNAseq123 workflow](https://bioconductor.org/packages/release/workflows/html/RNAseq123.html) maintained by Matthew Ritchie, and the [EGSEA123 workflow](https://bioconductor.org/packages/release/workflows/html/EGSEA123.html) maintained by Matthew Ritchie.

Other key resources are Bioconductor (Huber et al., Nature Methods 2015), [scRNA-tools](https://www.scrna-tools.org/), `scater` (McCarty et al., Bioinformatics 2017), `scran` (Lun et al. F1000Res 2016), `SC3` (Kiselev et al., Nature Methods 2017), `Seurat` (Butler et al., Nature Biotechnology 2018), `clusterExperiment` (Risso et al., PLOS Computational Biology 2018), `limma` (Ritchie et al., Nucleic Acids Research 2015), `DESeq2` (Love et al., Genome Biology 2014), `iSEE` (Rue-Albrecht & Marini et al., F1000Research 2018), `t-SNE` (van der Maaten & Hinton, Journal of Machine Learning Research 2008).

***

Below are some code scraps that have been taken out of the pipeline in favour of other preferred alternatives. They most likely require further adaptations before being reincorporated. 

# STEP 2 | Quality Control and pre-processing
## Step 2.5b | Cell cycle phase [OPTIONAL]
It is possible to classify cells into cell cycle phases based on the gene expression data using the function `cyclone` (Sciealdone et al. 2015). This, however, is not super useful in the brain, as many neuronal cell types are expected to lie in the G0 resting phase, which is distinct from the other phases of the cell cycle (Coller et al., 2006). We run it anyway and observe that all the cells are in G1.

Cells are classified as being in G1 phase if the G1 score is above 0.5 and greater than the G2/M score; in G2/M phase if the G2/M score is above 0.5 and greater than the G1 score; and in S phase if neither score is above 0.5.

*See McCarthy et al. F1000Research 2016 for an explanation of this step and the code.*
```{r}
library(scran)
library(AnnotationDbi)
library(org.Mm.eg.db)
set.seed(1991)

mm.pairs <- readRDS(system.file("exdata", "mouse_cycle_markers.rds", package="scran")) 
assignments <- cyclone(PAG_sceset, mm.pairs, gene.names=rowData(PAG_sceset)$ENSEMBL) 
plot(assignments$score$G1, assignments$score$G2M, xlab="G1 score", ylab="G2/M score", pch=16, xlim=c(0,1), ylim=c(0,1))
```

We could store the cell cycle phases for future use:
```{r}
PAG_sceset$cycle_phase <- assignments$phases
```

# STEP 4 | Modelling technical and biological variability in gene expression and identifying highly variable genes
## PATH "A" to feature selection - trendVar
### Step 4a.4 | Identifying correlated gene pairs with Spearman's rho
Another useful procedure is to identify the HVGs that are highly correlated with one another. This distinguishes between HVGs caused by random noise and those involved in driving systematic differences between subpopulations. Correlations between genes can be quantified by computing Spearman's rho, which accommodates non-linear relationships in the expression values. Gene pairs with significantly large positive or negative values of rho are identified using the `correlatePairs` function. We only apply this function to the set of HVGs, because these genes have large biological components and are more likely to exhibit strong correlations driven by biology. In contrast, calculating correlations for all possible gene pairs would require too much computational time and increase the severity of the multiple testing correction. It may also prioritize uninteresting genes that have strong correlations but low variance, e.g., tightly co-regulated house-keeping genes.
```{r}
# Takes around 1 min
set.seed(1991)
library(scran)

start_time_c1 <- Sys.time()
var.cor <- correlatePairs(PAG_sceset_qc_norm_filt, 
                          subset.row=metadata(PAG_sceset_qc_norm_filt)$hvg_out_no_spikes_filt) 
write.table(file="PAG_correlated_genes.tsv", var.cor, sep="\t", quote=FALSE, row.names=FALSE) 
head(var.cor)
end_time_c1 <- Sys.time()
end_time_c1 - start_time_c1
```

The significance of each correlation is determined using a permutation test. For each pair of genes, the null hypothesis is that the expression profiles of two genes are independent. Shuffling the profiles and recalculating the correlation yields a null distribution that is used to obtain a p-value for each observed correlation value (Phipson & Smyth, 2010). Correction for multiple testing across many gene pairs is performed by controlling the FDR at 5%. Correlated gene pairs can be directly used for experimental validation with orthogonal techniques (e.g., fluorescence-activated cell sorting, immunohistochemistry or RNA fluorescence in situ hybridization) to verify that these expression patterns are genuinely present across the cell population.
```{r}
sig.cor <- var.cor$FDR <= 0.05 
summary(sig.cor)
```

The use of `correlatePairs` is primarily intended to identify correlated gene pairs for validation studies. Obviously, non-zero correlations do not provide evidence for a direct regulatory interaction, let alone specify causality. To construct regulatory networks involving many genes, we suggest using dedicated packages such as _[WGCNA](https://horvath.genetics.ucla.edu/html/CoexpressionNetwork/Rpackages/WGCNA/)_.

#### 4a.4.1 | Larger sets of genes
Larger sets of correlated genes are assembled by treating genes as nodes in a graph and each pair of genes with significantly large correlations as an edge. In particular, an undirected graph is constructed using methods in the `RBGL` package. Highly connected subgraphs are then identified and defined as gene sets. This provides a convenient summary of the pairwise correlations between genes.
```{r}
# Takes around 15 min
library(RBGL) 
start_time_c2 <- Sys.time()
g <- ftM2graphNEL(cbind(var.cor$gene1, var.cor$gene2)[sig.cor,], W=NULL, V=NULL, edgemode="undirected")
cl <- highlyConnSG(g)$clusters # Time consuming step
cl <- cl[order(lengths(cl), decreasing=TRUE)] 
head(cl)
end_time_c2 <- Sys.time()
end_time_c2 - start_time_c2
```

Significant correlations provide evidence for substructure in the dataset, i.e., subpopulations of cells with systematic differences in their expression profiles. The number of significantly correlated HVG pairs represents the strength of the substructure. If many pairs were significant, this would indicate that the subpopulations were clearly defined and distinct from one another. 

## PATH "B" to feature selection - M3Drop
__Based on the online course on [Analysis of single cell RNA-seq data](https://github.com/hemberg-lab/scRNA.seq.course) by the [Hemberg Lab](https://www.sanger.ac.uk/science/groups/hemberg-group).__

We continue using the `PAG_sceset_qc_norm` after normalization. We should thus have a `logcounts` slot in`assays`:
```{r}
# If starting from stored results, load saved filtered dataset from previous Step:
set.seed(1991)
options(stringsAsFactors = FALSE)
library(SingleCellExperiment)
library(scater)
library(scran)
library(matrixStats)
library(M3Drop)

PAG_sceset_qc_norm <- readRDS("PAG_sceset_qc_norm.rds") # Contains filtered cells and genes, and normalized data
assayNames(PAG_sceset_qc_norm)
PAG_sceset_qc_norm
```

scRNA-seq is capable of measuring the expression of many thousands of genes in every cell. However, in most situations only a portion of those will show a response to the biological condition of interest, e.g. differences in cell-type, drivers of differentiation, respond to an environmental stimulus. Most genes detected in a scRNA-seq experiment will only be detected at different levels due to technical noise. One consequence of this is that technical noise and batch effects can obscure the biological signal of interest. Thus, it is often advantageous to perform feature selection to remove those genes which only exhibit technical noise from downstream analysis. Not only does this generally increase the signal:noise ratio in the data; it also reduces the computational complexity of analyses, by reducing the total amount of data to be processed.

For scRNA-seq data, we will be focusing on unsupervised methods of feature selection which don’t require any a priori information, such as cell-type labels or biological group, since they may not be available, or may be unreliable, for many experiments. In contrast, differential expression can be considered a form of supervised feature selection since it uses the known biological label of each sample to identify features (i.e. genes) which are expressed at different levels across groups.

__One important thing...__
Before identifying HVGs, consider dropping any Ribosomal, Mitochondrial, ERCC, sex-specific genes (e.g. XIST), transgenes (EYFP, tdTomato, Cre, TSO concatamers) and genes used for transgenic labeling of cells (VGAT and VGluT2) from the dataset before proceeding to downstream analysis, as some of them are not be biologically informative and others have been used to select the cells.
```{r}
dim(PAG_sceset_qc_norm)

is_X_qc_norm <- (rowData(PAG_sceset_qc_norm)$Chromosome == "X") # Find which genes correspond to chromosome X 
is_Y_qc_norm <- (rowData(PAG_sceset_qc_norm)$Chromosome == "Y") # Find which genes correspond to chromosome Y
is_feature_control_qc_norm <- (rowData(PAG_sceset_qc_norm)$is_feature_control) # Find which genes correspond to feature controls (Ribosomal, Mitochondrial, ERCC, transgenes)

filter_genes_qc_norm <- !(is_X_qc_norm | is_Y_qc_norm | is_feature_control_qc_norm)
PAG_sceset_qc_norm <- PAG_sceset_qc_norm[filter_genes_qc_norm, ]
dim(PAG_sceset_qc_norm)
```

Feature selection is performed after QC. `M3Drop` contains two different feature selection methods `M3DropFeatureSelection` which is based on a Michaelis-Menten curve and is designed for full-transcript single-cell RNA-seq data (such as Smart-seq2) and `NBumiFeatureSelectionCombinedDrop` which is based on a negative binomial model and is designed for UMI count data. We will use the former.

`M3Drop` feature selection runs on a normalized (but not log-transformed) expression matrix. This can be extracted from our `SingleCellExperiment` object using the command below. This function is compatible with most single-cell RNA-seq analysis packages including: `scater`, `SingleCellExperiment`, `monocle`, and `Seurat`. It can also convert an existing expression matrix to the correct form (removing undetected genes & normalizing/delogging) if you specify whether the matrix is raw counts, or log transformed. Check the manual for details.
```{r}
#expr_matrix <- M3Drop::M3DropConvertData(PAG_sceset_qc_norm) #
#expr_matrix <- M3DropConvertData(PAG_sceset_qc_norm@assays[["logcounts_raw"]], is.log=TRUE, is.counts=FALSE)
expr_matrix <- M3DropConvertData(PAG_sceset_qc_norm@assays[["counts"]], is.log=FALSE, is.counts=TRUE)
nrow(counts(PAG_sceset_qc_norm)) - nrow(expr_matrix) # check the ConvertData function has dropped undetected genes
```

### Step 4b.1 | Identifying genes vs a Null Model
There are two main approaches to unsupervised feature selection. The first is to identify genes which behave differently from a null model describing just the technical noise expected in the dataset.

If the dataset contains spike-in RNAs they can be used to directly model technical noise. However, measurements of spike-ins may not experience the same technical noise as endogenous transcripts (Svensson et al., 2017). In addition, scRNA-seq experiments often contain only a small number of spike-ins which reduces our confidence in fitted model parameters. We will not use spike-in transcripts beyond QC in our analysis.

#### 4b.1.1 | Highly Variable Genes
The first method proposed to identify features in scRNA-seq datasets was to identify highly variable genes (HVG). HVG assumes that if genes have large differences in expression across cells some of those differences are due to biological difference between the cells rather than technical noise. However, because of the nature of count data, there is a positive relationship between the mean expression of a gene and the variance in the read counts across cells. This relationship must be corrected for to properly identify HVGs.
```{r}
# Plot the relationship between mean expression and variance for all genes in this dataset:
plot(
    rowMeans(expr_matrix), 
    rowVars(expr_matrix), 
    log="xy", 
    pch=16,
    xlab="Mean Expression", 
    ylab="Variance", 
    main=""
)
```

A popular method to correct for the relationship between variance and mean expression was proposed by [Brennecke et al. 2013](http://www.nature.com/nmeth/journal/v10/n11/full/nmeth.2645.html). To use the Brennecke method, we first normalize for library size and then calculate the mean and the square coefficient of variation (variation divided by the squared mean expression). A quadratic curve is fit to the relationship between these two variables for the ERCC spike-in, and then a chi-square test is used to find genes significantly above the curve. This method is included in the `M3Drop` package as the `Brennecke_getVariableGenes(counts, spikes)` function. If the dataset does not contain spike-ins we can use the entire dataset to estimate the technical noise.

In the figure below the red curve is the fitted technical noise model and the dashed line is the 95% CI. Pink dots are the genes with significant biological variability after multiple-testing correction.
```{r}
Brennecke_HVG <- M3Drop::BrenneckeGetVariableGenes(expr_matrix,
                                                   fdr = 0.01,
                                                   minBiolDisp = 0.5
                                                   )
```

This function returns a matrix of significant genes as well as their estimated effect size (difference between observed and expected coefficient of variation), and their significance as raw p.values and FDR corrected q.values. For now we will just keep the names of the significant HVG genes.
```{r}
HVG_genes <- Brennecke_HVG$Gene
length(HVG_genes)
```

#### 4b.1.2 | High Dropout Genes
An alternative to finding HVGs is to identify genes with unexpectedly high numbers of zeros. The frequency of zeros, known as the "dropout rate", is very closely related to expression level in scRNASeq data. Zeros are the dominant feature of single-cell RNASeq data, typically accounting for over half of the entries in the final expression matrix. These zeros predominantly result from the failure of mRNAs failing to be reversed transcribed (Andrews and Hemberg, 2016). Reverse transcription is an enzyme reaction thus can be modelled using the Michaelis-Menten equation: Pdropout=1−S/(K+S) where S is the mRNA concentration in the cell (we will estimate this as average expression) and K is the Michaelis-Menten constant.

Because the Michaelis-Menten equation is a convex non-linear function, genes which are differentially expression across two or more populations of cells in our dataset will be shifted up/right of the Michaelis-Menten model. We use M3Drop to identify significant outliers to the right of the MM curve. We also apply 1% FDR multiple testing correction:
```{r}
M3Drop_genes <- M3DropFeatureSelection(expr_matrix,
                                       mt_method = "fdr",
                                       mt_threshold = 0.01
                                       )
M3Drop_genes <- M3Drop_genes$Gene
length(M3Drop_genes)
```

### Step 4b.2 | Correlated Expression
A completely different approach to feature selection is to use gene-gene correlations. This method is based on the idea that multiple genes will be differentially expressed between different cell-types or cell-states. Genes which are expressed in the same cell-population will be positively correlated with each other where as genes expressed in different cell-populations will be negatively correated with each other. Thus important genes can be identified by the magnitude of their correlation with other genes.

The limitation of this method is that it assumes technical noise is random and independent for each cell, thus shouldn't produce gene-gene correlations, but this assumption is violated by batch effects which are generally systematic between different experimental batches and will produce gene-gene correlations. As a result it is more appropriate to take the top few thousand genes as ranked by gene-gene correlation than consider the significance of the correlations.
```{r}
cor_feat <- M3Drop::corFS(expr_matrix) # Takes a long time
Cor_genes <- names(cor_feat)[1:1500]
```

### Step 4b.3 | PCA loadings
Lastly, another common method for feature selection in scRNASeq data is to use PCA loadings. Genes with high PCA loadings are likely to be highly variable and correlated with many other variable genes, thus may be relevant to the underlying biology. However, as with gene-gene correlations PCA loadings tend to be susceptible to detecting systematic variation due to batch effects; thus it is recommended to plot the PCA results to determine those components corresponding to the biological variation rather than batch effects.
```{r}
# PCA is typically performed on log-transformed expression data
pca <- prcomp(log(expr_matrix + 1) / log(2))

# plot projection
plot(
    pca$rotation[,1], 
    pca$rotation[,2], 
    pch = 16
)
```

```{r}
# calculate loadings for components 1 and 2
score <- rowSums(abs(pca$x[,c(1,2)])) 
names(score) <- rownames(expr_matrix)
score <- score[order(-score)]
PCA_genes <- names(score[1:1500])
```

```{r}
#Consider the top 5 principal components. Which ones appear to be most biologically relevant? How do the top 1,500 features change if you consider the loadings for those components?
plot(
    pca$rotation[,2], 
    pca$rotation[,3], 
    pch = 16
)

plot(
    pca$rotation[,3], 
    pca$rotation[,4], 
    pch = 16
)

# calculate loadings for components 1 and 2
score <- rowSums(abs(pca$x[,c(2, 3, 4)]))
names(score) <- rownames(expr_matrix)
score <- score[order(-score)]
PCA_genes2 = names(score[1:1500])
```

### Step 4b.4 | Comparing Methods
We can check whether the identified features really do represent genes differentially expressed between cell-types in this dataset.
```{r}
M3DropExpressionHeatmap(M3Drop_genes,
                        expr_matrix,
                        cell_labels = PAG_sceset_qc_norm$cell.type
                        )
```

```{r}
M3DropExpressionHeatmap(HVG_genes,
                        expr_matrix,
                        cell_labels = PAG_sceset_qc_norm$cell.type
                        )
```

```{r}
M3DropExpressionHeatmap(Cor_genes,
                        expr_matrix,
                        cell_labels = PAG_sceset_qc_norm$cell.type
                        )
```

```{r}
M3DropExpressionHeatmap(PCA_genes,
                        expr_matrix,
                        cell_labels = PAG_sceset_qc_norm$cell.type
                        )
```

```{r}
M3DropExpressionHeatmap(PCA_genes2,
                        expr_matrix,
                        cell_labels = PAG_sceset_qc_norm$cell.type
                        )
```

We can also consider how consistent each feature selection method is with the others using the Jaccard Index:
```{r}
list_of_features <- list(M3Drop_genes,
                         HVG_genes, 
                         Cor_genes, 
                         PCA_genes, 
                         PCA_genes2
                         )

Out <- matrix(0, 
              ncol = length(list_of_features), 
              nrow = length(list_of_features)
              )

for(i in 1:length(list_of_features) ) {
    for(j in 1:length(list_of_features) ) {
        Out[i,j] <- sum(list_of_features[[i]] %in% list_of_features[[j]])/
            length(unique(c(list_of_features[[i]], list_of_features[[j]])))
     }
}

colnames(Out) <- rownames(Out) <- c("M3Drop", "HVG", "Cor", "PCA", "PCA2")
Out
```

# STEP 7 | Clustering
## Step 7.1 | Hierarchical clustering on Euclidean distances
The denoised log-expression values can be used to cluster cells into putative subpopulations. Specifically, we perform hierarchical clustering on the Euclidean distances between cells, using Ward's criterion to minimize the total variance within each cluster. This yields a dendrogram that groups together cells with similar expression patterns across the chosen genes.
```{r}
principal_components <- reducedDim(PAG_sceset_qc_norm, "PCA")
PAG_dist <- dist(principal_components) # Making a distance matrix
PAG_tree <- hclust(PAG_dist, method="ward.D2") # Building a tree
plot(PAG_tree)
```

### 7.1.1 | Cutree
We can next cut the tree into different clusters and see how these correspond to the known sample conditions:
```{r}
PAG_clusters <- cutree(PAG_tree, k=3) 
table(PAG_clusters, PAG_sceset_qc_norm$PAG.area)
```

Color the t-SNE according to the cluster identity:
```{r}
PAG_sceset_qc_norm$Cluster <- factor(PAG_clusters)
plotTSNE(PAG_sceset_qc_norm, colour_by='Cluster')
```

We next use a heatmap to visualize the expression profiles of the top 100 genes with the largest biological components. If there is structure, we should see "blocks" in expression that correspond nicely to known sample features. We possibly could have subclustered further, in which case we would subset and repeat the above process.
```{r}
library(pheatmap)
plotHeatmap(PAG_sceset_qc_norm, 
            features=rownames(var_out_no_spikes)[order(var_out_no_spikes$bio, decreasing=TRUE)[1:100]],
            cluster_cols=PAG_tree, colour_columns_by="PAG.area",
            center=TRUE, symmetric=TRUE)
```

When clustering, it is often useful to look at silhouette plots to assess cluster separatedness. Each bar corresponds to a cell, and is proportional to the difference in the average distances to all other cells in the same cluster versus cells in the nearest neighbouring cluster. A good gauge for the number of clusters is that which maximizes the average silhouette width.
```{r}
library(cluster)
par(mfrow=c(2,2))
for (k in 2:5) { 
    example_clusters <- cutree(PAG_tree, k=k)
    sil <- silhouette(example_clusters, dist=PAG_dist)
    plot(sil, col=rainbow(k)[sort(sil[,1])])
}
```

Other options for clustering are:

* Use the `cutreeDynamic()` function in the _dynamicTreeCut_ package, for topology-aware cutting of the tree (doesn't require specifying the number of clusters).
* Use graph-based methods such as `buildSNNGraph()` or `buildKNNGraph()`, followed by clustering methods from _igraph_.
* Use methods with pre-specified number of clusters, e.g., k-means with `kmeans()` and _SC3_, self-organizing maps in _flowSOM_.

### 7.1.2 | DynamicTreeCut
Clusters are explicitly defined by applying a dynamic tree cut (Langfelder, Zhang, and Horvath 2008) to the dendrogram. This exploits the shape of the branches in the dendrogram to refine the cluster definitions, and is more appropriate than `cutree` for complex dendrograms. Greater control of the empirical clusters can be obtained by manually specifying cutHeight in  `cutreeDynamic`. We also set `minClusterSize` to a lower value than the default of 20, to avoid spurious aggregation of distant small clusters.
```{r}
library(dynamicTreeCut)
PAG_clusters <- unname(cutreeDynamic(PAG_tree, distM=as.matrix(PAG_dist), 
                                     minClusterSize=10, verbose=0))
```

We examine the distribution of cells in each cluster with respect to known factors. We check whether each cluster is comprised of cells from both batches, which would indicate that the clustering is not driven by a batch effect. Differences in the composition of each cluster are observed with respect to `cell.type` or `PAG.area`.
```{r}
table(PAG_clusters, PAG_sceset_qc_norm$cell.type)
table(PAG_clusters, PAG_sceset_qc_norm$PAG.area)
```

We can now visualize the cluster assignments for all cells on the t-SNE we created before. Adjacent cells are generally assigned to the same cluster, indicating that the clustering procedure was applied correctly.
```{r}
PAG_sceset_qc_norm$Cluster <- factor(PAG_clusters)
plotTSNE(PAG_sceset_qc_norm, colour_by="Cluster") + fontsize
```

We check the separatedness of the clusters using the silhouette width. Cells with large positive silhouette widths are closer to other cells in the same cluster than to cells in different clusters. Conversely, cells with negative widths are closer to other clusters than to other cells in the cluster to which it was assigned. Each cluster would ideally contain many cells with large positive widths, indicating that it is well-separated from other clusters.
```{r}
library(cluster)
clust.col <- scater:::.get_palette("tableau10medium") # hidden scater colours
sil <- silhouette(PAG_clusters, dist = PAG_dist)
sil.cols <- clust.col[ifelse(sil[,3] > 0, sil[,1], sil[,2])]
sil.cols <- sil.cols[order(-sil[,1], sil[,3])]
plot(sil, main = paste(length(unique(PAG_clusters)), "clusters"), 
     border=sil.cols, col=sil.cols, do.col.sort=FALSE)
```

The silhouette width can be used to determine the parameter values that maximize the separation between clusters. For example, we could vary the cut height or splitting depth in `cutreeDynamic` to maximize the average silhouette width across all cells. This usually provides a satisfactory initial clustering for further examination. However, keep in mind that the granularity of clustering is much like the magnification on a microscope. Different views of the data can be obtained with different granularities, some of which may be suboptimal on measures of separation. Users should not fixate on the clustering with the greatest separation if it does not provide the desired granularity for a particular biological question.

* Small silhouette positive widths indicates that the separation between clusters is weak. This may be symptomatic of over-clustering where clusters that are clearly defined are further split into subsets that are less well separated. 
* An alternative clustering strategy is to use a matrix of distances derived from correlations (e.g., as in `quickCluster`). This is more robust to noise and normalization errors, but is also less sensitive to subtle changes in the expression profiles.
* Both Ward's criterion and complete linkage yield spherical, compact clusters. In particular, complete linkage favours the formation of clusters with the same diameter. This may be desirable in some cases but is less appropriate when subpopulations differ in their variance. Thus, we typically use Ward's criterion for our initial clustering. Of course, it is simple (and recommended) to try other approaches provided that some assessment is performed, e.g., using the silhouette width.

## Step 7.2 | Identifying marker genes between subpopulations
Once putative subpopulations are identified by clustering, we can identify marker genes for each cluster using the `findMarkers` function. This performs Welch t-tests on the log-expression values for every gene and between every pair of clusters (Soneson and Robinson 2018). The aim is to test for DE in each cluster compared to the others while blocking on uninteresting factors such as the plate of origin. The top DE genes are likely to be good candidate markers as they can effectively distinguish between cells in different clusters.
```{r}
marker_genes <- findMarkers(PAG_sceset_qc_norm, clusters=PAG_clusters, block=PAG_sceset_qc_norm$mouse.id)
```

For each cluster, the DE results of the relevant comparisons are consolidated into a single output table. This allows a set of marker genes to be easily defined by taking the top DE genes from each pairwise comparison between clusters. For example, to construct a marker set for cluster 1 from the top 10 genes of each comparison, one would filter `marker.set` to retain rows with `Top` less than or equal to 10. Other statistics are also reported for each gene, including the adjusted p-values and the log-fold changes relative to every other cluster.
```{r}
marker_set_2 <- marker_genes[[2]] # Marker set for cluster 2
head(marker_set_2)

# Check what Top represents:
#marker_set_2[marker_set_2$Top <= 1,]
```

We save the list of candidate marker genes for further examination.
```{r}
write.table(marker.set, file="PAG_marker_genes_2.tsv", sep="\t", 
            quote=FALSE, col.names=NA)
```

We visualize the expression profiles of the top candidates to verify that the DE signature is robust. A more comprehensive investigation of the function of these markers can be performed with gene set enrichment analyses, e.g., using `kegga` or `goana` from _limma_.
```{r}
top_markers_2 <- rownames(marker_set_2)[marker_set_2$Top <= 10]
plotHeatmap(PAG_sceset_qc_norm, 
            features=top_markers_2,
            columns=order(PAG_sceset_qc_norm$Cluster),
            cluster_cols=PAG_tree, # try cluster_cols=FALSE
            colour_columns_by=c("Cluster", "cell.type", "PAG.area"),
            center=TRUE, symmetric=TRUE, zlim=c(-5, 5))
```

A valid alternative strategy is to detect marker genes that are uniquely up-regulated or down-regulated in each cluster (set `pval.type="all"`). However, be aware that no such genes may exist. Many of the markers might not uniquely up- or downregulated in the chosen cluster. Testing for unique DE tends to be too stringent as it overlooks important genes that are expressed in two or more clusters. A better approach is to pick up as candidate markers genes that will be DE between at least one pair of subpopulations. A combination of markers can then be chosen to characterize a subpopulation, which is more flexible than trying to find uniquely DE genes.

We strongly recommend selecting some markers for use in validation studies with an independent replicate population of cells. The aim is to identify a corresponding subset of cells that express the upregulated markers and do not express the downregulated markers. Ideally, a different technique for quantifying expression would also be used during validation, e.g., fluorescent in situ hybridisation or quantitative PCR. This confirms that the subpopulation genuinely exists and is not an artifact of scRNA-seq or the computational analysis.

* By setting `direction="up"`, `findMarkers` will only return genes that are upregulated in each cluster compared to the others. This is convenient in highly heterogeneous populations to focus on genes that can immediately identify each cluster. While lack of expression may also be informative, it is less useful for positive identification.
* `findMarkers` can also be directed to find genes that are DE between the chosen cluster and all other clusters. This should be done by setting `pval.type="all"`, which defines the p-value for each gene as the maximum value across all pairwise comparisons involving the chosen cluster. Combined with `direction="up"`, this can be used to identify unique markers for each cluster. However, this is sensitive to overclustering, as unique marker genes will no longer exist if a cluster is split into two smaller subclusters.
* It must be stressed that the (adjusted) p-values computed here cannot be properly interpreted as measures of significance. This is because the clusters have been empirically identified from the data.
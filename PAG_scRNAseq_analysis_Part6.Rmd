---
title: "Topographic, single-cell gene expression profiling of Periaqueductal Gray neurons"
subtitle: "Part VI: clustering"
author:
  - name: "Oriol Pavon Arocas, Sarah F. Olesen, and Tiago Branco"
    affiliation: "Sainsbury Wellcome Centre for Neural Circuits and Behaviour, University College London, UK"
    email: "oriol.pavon.16@ucl.ac.uk"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_notebook:
    highlight: pygments
    number_sections: FALSE
    theme: lumen
    toc: TRUE
    toc_float: TRUE

#output: rmdformats::readthedown:
  #highlight: pygments
---

***

This is a pipeline to analyse single-cell RNA sequencing data from Periaqueductal Gray neurons (1) isolated from acute midbrain slices of transgenic mice using visually guided aspiration via patch pipettes and (2) processed using SMART-seq2 (Picelli et al., Nature Protocols 2014).

This pipeline has been generated after attending the [EMBL-EBI RNA-Sequence Analysis Course](https://www.ebi.ac.uk/training/events/2019/rna-sequence-analysis) and [attending](https://training.csx.cam.ac.uk/bioinformatics/event/2823386) and following the online course on [Analysis of single cell RNA-seq data](https://github.com/hemberg-lab/scRNA.seq.course) by the [Hemberg Lab](https://www.sanger.ac.uk/science/groups/hemberg-group). Many other resources have been used, including the [Orchestrating Single-Cell Analysis with Bioconductor book](https://bioconductor.org/books/release/OSCA/) by Robert Amezquita, Aaron Lun, Stephanie Hicks, and Raphael Gottardo, the [simpleSingleCell workflow in Bioconductor](https://bioconductor.org/packages/3.9/workflows/html/simpleSingleCell.html) maintained by Aaron Lun, the [rnaseqGene workflow](https://bioconductor.org/packages/3.10/workflows/html/rnaseqGene.html) maintained by Michael Love, the [RNAseq123 workflow](https://bioconductor.org/packages/3.10/workflows/html/RNAseq123.html) maintained by Matthew Ritchie, and the [EGSEA123 workflow](https://bioconductor.org/packages/3.10/workflows/html/EGSEA123.html) maintained by Matthew Ritchie.

Other key resources include [Bioconductor](http://www.bioconductor.org/) (Huber et al., Nature Methods 2015), [scRNA-tools](https://www.scrna-tools.org/), `scater` (McCarthy et al., Bioinformatics 2017), `scran` (Lun et al., F1000Res 2016), `SC3` (Kiselev et al., Nature Methods 2017), `Seurat` (Butler et al., Nature Biotechnology 2018), `clusterExperiment` (Risso et al., PLOS Computational Biology 2018), `limma` (Ritchie et al., Nucleic Acids Research 2015), `DESeq2` (Love et al., Genome Biology 2014), `edgeR` (Robinson et al., Bioinformatics 2010), `MAST` (Finak, McDavid, Yajima et al., Genome Biology 2015), `iSEE` (Rue-Albrecht & Marini et al., F1000Research 2018), `t-SNE` (van der Maaten & Hinton, Journal of Machine Learning Research 2008), `UMAP` (McInnes et al., arXiv 2018), and the [Mathematical Statistics and Machine Learning for Life Sciences](https://towardsdatascience.com/tagged/stats-ml-life-sciences) column by Nikolay Oskolkov.

***

# STEP 6 | Clustering
We have now normalised the data, identified highly variable genes, corrected confounding factors, and applied dimensionality reduction techniques to better visualize, denoise, and summarize our data. We can now proceed to carry out analyses that are relevant to the biological questions at hand.

scRNA-seq data allow de novo discovery and annotation of cell-types based on gene expression profiles. Computationally, we need to identify groups of cells based on the similarities of their transcriptomes without any prior knowledge of the labels, nor the number of clusters we will end up with. This is very challenging due to the high level of noise (both technical and biological) and the large number of dimensions (i.e. genes x cells).

Clustering is an unsupervised learning procedure that is used in scRNA-seq data analysis to empirically define groups of cells with similar expression profiles. This allows us to describe population heterogeneity in terms of discrete labels that are easily understood, rather than attempting to comprehend the high-dimensional manifold on which the cells truly reside. After annotation based on marker genes, the clusters can be treated as proxies for more abstract biological concepts such as cell types or states. Clustering is thus a critical step for extracting biological insights from scRNA-seq data. Some of the most popular approaches are _graph-based clustering_, _k-means clustering_, and _hierarchical clustering_.

At this point, it is worth stressing the distinction between clusters and cell types. The former is an empirical construct while the latter is a biological truth (albeit a vaguely defined one). For this reason, questions like “what is the true number of clusters?” are usually meaningless. We can define as many clusters as we like, with whatever algorithm we like - each clustering will represent its own partitioning of the high-dimensional expression space, and is as “real” as any other clustering. A more relevant question is “how well do the clusters approximate the cell types?”. Unfortunately, this is difficult to answer given the context-dependent interpretation of biological truth. Some analysts will be satisfied with resolution of the major cell types; other analysts may want resolution of subtypes; and others still may require resolution of different states (e.g., metabolic activity, stress) within those subtypes. Moreover, two clusterings can be highly inconsistent yet both valid, simply partitioning the cells based on different aspects of biology.

We continue using the `PAG_sceset_qc_norm_filt_corr` after normalisation, filtering, and batch correction. We should thus have a `corrected` slot in `assays`, and different PCA, tSNE, and UMAP solutions in the `reducedDim` slot:
```{r}
# Set the directory where your data and scripts are:
setwd("D:/Dropbox (UCL - SWC)/Project_transcriptomics/analysis/PAG_scRNAseq_analysis")

# Set the path to save figures from this Part:
path_for_figures <- "D:/Dropbox (UCL - SWC)/Project_transcriptomics/figures/R_figures_Part6_clustering/"
date <- Sys.Date()
date <- gsub("-", "_", date)

# Load packages:
library(tidyverse)
library(SingleCellExperiment)
library(scater)
library(scran)
library(ggplot2)
library(SC3)
library(pheatmap)
library(mclust)
library(dynamicTreeCut)
library(dendextend)
library(cluster)
library(patchwork)
library(extrafont)
```

```{r}
# If starting from stored results, load saved filtered dataset from previous Step:
options(stringsAsFactors = FALSE)

PAG_sceset_qc_norm_filt_corr <- readRDS("PAG_sceset_qc_norm_filt_corr.rds") # Contains filtered cells and genes, log-normalised, filtered, and corrected data
assayNames(PAG_sceset_qc_norm_filt_corr)
reducedDimNames(PAG_sceset_qc_norm_filt_corr)
```

## Step 6.1 | Graph-based clustering
Graph-based clustering is a flexible and scalable technique for clustering large scRNA-seq datasets. We first build a graph where each node is a cell that is connected to its nearest neighbours in the high-dimensional space. Edges are weighted based on the similarity between the cells involved, with higher weight given to cells that are more closely related. We then apply algorithms to identify “communities” of cells that are more connected to cells in the same community than they are to cells of different communities. Each community represents a cluster that we can use for downstream interpretation.

The major advantage of graph-based clustering lies in its scalability. It only requires a k-nearest neighbor search that can be done in log-linear time on average, in contrast to hierachical clustering methods with runtimes that are quadratic with respect to the number of cells. Graph construction avoids making strong assumptions about the shape of the clusters or the distribution of cells within each cluster, compared to other methods like k-means (that favor spherical clusters) or Gaussian mixture models (that require normality). From a practical perspective, each cell is forcibly connected to a minimum number of neighboring cells, which reduces the risk of generating many uninformative clusters consisting of one or two outlier cells.

The main drawback of graph-based methods is that, after graph construction, no information is retained about relationships beyond the neighbouring cells. This has some practical consequences in datasets that exhibit differences in cell density, as more steps through the graph are required to move the same distance through a region of higher cell density. From the perspective of community detection algorithms, this effect “inflates” the high-density regions such that any internal substructure or noise is more likely to cause formation of subclusters. The resolution of clustering thus becomes dependent on the density of cells, which can occasionally be misleading if it overstates the heterogeneity in the data.

`scran` provides several graph construction methods based on shared nearest neighbors (Xu and Su 2015) through the `buildSNNGraph()` function. This is most commonly generated from the selected PCs, after which methods from the `igraph` package can be used to identify clusters.

### 6.1.1 | Implementation of graph-based clustering
There are several considerations in the practical execution of a graph-based clustering method: (1) How many neighbors are considered when constructing the graph, (2) What scheme is used to weight the edges, and (3) Which community detection algorithm is used to define the clusters. The `buildSNNGraph` method builds a shared nearest-neighbour graph using cells as nodes. For each cell, its `k` nearest neighbours are identified using the `findKNN` function, based on distances between their expression profiles (Euclidean by default). An edge is drawn between all pairs of cells that share at least one neighbour, and weighted by the characteristics of the shared nearest neighbors. 

For example, we could use a code that uses the `k = 10` nearest neighbors of each cell to construct a shared nearest neighbor graph. If `type = "rank"`, two cells are connected by an edge if any of their nearest neighbors are shared, with the edge weight defined from the highest average rank of the shared neighbors (Xu and Su 2015): The weight between two nodes is `k - r/2` where `r` is the smallest sum of ranks for any shared neighboring node. For example, if one node was the closest neighbor of each of two nodes, the weight between the two latter nodes would be `k - 1`. For the purposes of this ranking, each node has a rank of zero in its own nearest-neighbor set. More shared neighbors, or shared neighbors that are close to both cells, will generally yield larger weights. The `Walktrap` method from the `igraph` package can then be used to identify communities. All calculations are performed using the top PCs to take advantage of data compression and denoising. 

An alternative approach can be performed by changing the edge weighting scheme during graph construction. Setting `type = "number"` will weight edges based on the number of nearest neighbors that are shared between two cells (in other words, the weight between two nodes is simply the number of shared nearest neighbors between them). Similarly, `type = "jaccard"` will weight edges between nodes according to the Jaccard index of the two sets of neighbors. This weight can range from 0 to 1, and is a monotonic transformation of the weight used by `type = "number"`. We can also disable weighting altogether by using `buildKNNGraph()`, which is occasionally useful for downstream graph operations that do not support weights. Pipelines involving `scran` default to rank-based weights followed by Walktrap clustering. In contrast, `Seurat` uses Jaccard-based weights followed by Louvain clustering. Both of these strategies work well.

One of the most important parameters is `k`, the number of nearest neighbors used to construct the graph. The choice of `k` controls the connectivity of the graph and the resolution of the community detection algorithms. Smaller values of `k` will generally yield smaller, finer clusters, while increasing `k` will increase the connectivity of the graph and make it more difficult to resolve different communities, thereby yielding a more inter-connected graph and broader clusters. The value of `k` can be roughly interpreted as the anticipated size of the smallest subpopulation. If a subpopulation in the data has fewer than `k+1` cells, `buildSNNGraph` will forcibly construct edges between cells in that subpopulation and cells in other subpopulations. This increases the risk that the subpopulation will not form its own cluster as it is more interconnected with the rest of the cells in the dataset. It is recommended to try different values of `k` and different weighting schemes to obtain the most informative resolution.

We will thus run a search for different `k` in both Rank-Walktrap and Jaccard-Louvain and compare the clustering results on the different tSNEs and UMAPs, using the number of PCs suggested by `scran` and the HVGs from both Var and CV2 modelling. Commented out as only needed to run once, jump to the next steps with a preselection of `k`.
```{r}
# library(scran)
# set.seed(42)
# 
# # Number of K to test
# range_of_k = list(5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15)
# 
# for(n_k in range_of_k) {
#   print(paste0("Clustering results using k = ", n_k))
#   
#   # Compute clustering results
#   ## Using top 12 or 25 PCs and HVGs obtained from mean-var modelling
#   # Using HVG from Var with rank-based weights
#   graph_var_rank <- buildSNNGraph(PAG_sceset_qc_norm_filt_corr,
#                                   k = n_k, # An integer scalar specifying the number of nearest neighbors to consider during graph construction
#                                   #d = 50, # An integer scalar specifying the number of dimensions to use for the search, try 12 or 25
#                                   type = "rank", # A string specifying the type of weighting scheme to use for shared neighbors. Try "rank" or "jaccard"
#                                   subset.row = metadata(PAG_sceset_qc_norm_filt_corr)$hvg_var_out_no_spikes_block_filt,
#                                   assay.type = "logcounts",
#                                   use.dimred = "PCA_HVG_var_logcounts_12") # Use existing PCs and ignore any setting of d, subset.row and get.spikes
#   clusters_var_rank <- igraph::cluster_walktrap(graph_var_rank)$membership # Use `cluster_louvain` if using `type = "jaccard"`, and `cluster_walktrap` if using `type = "rank"`
#   PAG_sceset_qc_norm_filt_corr$SNN_clusters_var_rank <- factor(clusters_var_rank)
# 
#   # Using HVG from Var with jaccard-based weights
#   graph_var_jaccard <- buildSNNGraph(PAG_sceset_qc_norm_filt_corr,
#                                      k = n_k, # An integer scalar specifying the number of nearest neighbors to consider during graph construction
#                                      #d = 50, # An integer scalar specifying the number of dimensions to use for the search, try 12 or 25
#                                      type = "jaccard", # A string specifying the type of weighting scheme to use for shared neighbors. Try "rank" or "jaccard"
#                                      subset.row = metadata(PAG_sceset_qc_norm_filt_corr)$hvg_var_out_no_spikes_block_filt,
#                                      assay.type = "logcounts",
#                                      use.dimred = "PCA_HVG_var_logcounts_12") # Use existing PCs and ignore any setting of d, subset.row and get.spikes
#   clusters_var_jaccard <- igraph::cluster_louvain(graph_var_jaccard)$membership # Use `cluster_louvain` if using `type = "jaccard"`
#   PAG_sceset_qc_norm_filt_corr$SNN_clusters_var_jaccard <- factor(clusters_var_jaccard)
# 
#   ## Using top 17 or 25 PCs and HVGs obtained from mean-cv2 modelling
#   # Using HVG from CV2 with rank-based weights
#   graph_cv2_rank <- buildSNNGraph(PAG_sceset_qc_norm_filt_corr,
#                                   k = n_k, # An integer scalar specifying the number of nearest neighbors to consider during graph constructio
#                                   #d = 50, # An integer scalar specifying the number of dimensions to use for the search, try 17 or 25
#                                   type = "rank", # A string specifying the type of weighting scheme to use for shared neighbors
#                                   subset.row = metadata(PAG_sceset_qc_norm_filt_corr)$hvg_cv2_out_no_spikes_filt,
#                                   assay.type = "logcounts",
#                                   use.dimred = "PCA_HVG_cv2_logcounts_17") # Use existing PCs and ignore any setting of d, subset.row and get.spikes
#   clusters_cv2_rank <- igraph::cluster_walktrap(graph_cv2_rank)$membership
#   PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_rank <- factor(clusters_cv2_rank)
# 
#   # Using HVG from CV2 with jaccard-based weights
#   graph_cv2_jaccard <- buildSNNGraph(PAG_sceset_qc_norm_filt_corr,
#                                      k = n_k, # An integer scalar specifying the number of nearest neighbors to consider during graph construction
#                                      #d = 50, # An integer scalar specifying the number of dimensions to use for the search, try 17 or 25
#                                      type = "jaccard", # A string specifying the type of weighting scheme to use for shared neighbors
#                                      subset.row = metadata(PAG_sceset_qc_norm_filt_corr)$hvg_cv2_out_no_spikes_filt,
#                                      assay.type = "logcounts",
#                                      use.dimred = "PCA_HVG_cv2_logcounts_17") # Use existing PCs and ignore any setting of d, subset.row and get.spikes
#   clusters_cv2_jaccard <- igraph::cluster_louvain(graph_cv2_jaccard)$membership
#   PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_jaccard <- factor(clusters_cv2_jaccard)
# 
#   
#   ## Set theme parameters
#   theme_args_tSNE_UMAP_clustering <- theme(plot.title = element_text(size = 11, face = "bold"),
#                                            axis.title = element_text(size = 11, face = "plain"),
#                                            axis.text = element_text(size = 10, face = "plain"), 
#                                            legend.text = element_text(size = 9, face = "plain"), 
#                                            strip.text = element_text(size = 10, face = "plain"))
#   ### Using t-SNE (var) ###
#   tSNE_var_PAGsubdivisions <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
#                                              dimred = "tSNE_var_corrected_perplexity_15",
#                                              colour_by = "PAG.area", shape_by = "cell.type",
#                                              point_alpha = 0.6, point_size = 2, theme_size = 11
#                                              ) + labs(title = "PAG subdivisions", x = "t-SNE 1", y = "t-SNE 2") + theme_args_tSNE_UMAP_clustering
#   
#   # Using HVG from Var with rank-based weights
#   tSNE_var_RankWalktrap <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
#                                              dimred = "tSNE_var_corrected_perplexity_15",
#                                              colour_by = "SNN_clusters_var_rank", shape_by = "cell.type", text_by = "SNN_clusters_var_rank",
#                                              point_alpha = 0.6, point_size = 2, theme_size = 11
#                                              ) + labs(title = "Rank-Walktrap", x = "t-SNE 1", y = "t-SNE 2") + theme_args_tSNE_UMAP_clustering
#   
#   # Using HVG from Var with jaccard-based weights
#   tSNE_var_JaccardLouvain <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
#                                                 dimred = "tSNE_var_corrected_perplexity_15",
#                                                 colour_by = "SNN_clusters_var_jaccard", shape_by = "cell.type", text_by = "SNN_clusters_var_jaccard",
#                                                 point_alpha = 0.6, point_size = 2, theme_size = 11
#                                                 ) + labs(title = "Jaccard-Louvain", x = "t-SNE 1", y = "t-SNE 2") + theme_args_tSNE_UMAP_clustering
#   
#   
#   ### Using t-SNE (cv2) ###
#   tSNE_cv2_PAGsubdivisions <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
#                                              dimred = "tSNE_cv2_corrected_perplexity_15",
#                                              colour_by = "PAG.area", shape_by = "cell.type",
#                                              point_alpha = 0.6, point_size = 2, theme_size = 11
#                                              ) + labs(title = "PAG subdivisions", x = "t-SNE 1", y = "t-SNE 2") + theme_args_tSNE_UMAP_clustering
#   
#   # Using HVG from CV2 with rank-based weights
#   tSNE_cv2_RankWalktrap <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
#                                           dimred = "tSNE_cv2_corrected_perplexity_15",
#                                           colour_by = "SNN_clusters_cv2_rank", shape_by = "cell.type",  text_by = "SNN_clusters_cv2_rank",
#                                           point_alpha = 0.6, point_size = 2, theme_size = 11
#                                           ) + labs(title = "Rank-Walktrap", x = "t-SNE 1", y = "t-SNE 2") + theme_args_tSNE_UMAP_clustering
#   
#   # Using HVG from CV2 with jaccard-based weights
#   tSNE_cv2_JaccardLouvain <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
#                                             dimred = "tSNE_cv2_corrected_perplexity_15",
#                                             colour_by = "SNN_clusters_cv2_jaccard", shape_by = "cell.type", text_by = "SNN_clusters_cv2_jaccard",
#                                             point_alpha = 0.6, point_size = 2, theme_size = 11
#                                             ) + labs(title = "Jaccard-Louvain", x = "t-SNE 1", y = "t-SNE 2") + theme_args_tSNE_UMAP_clustering
#   
#   
#   ### Using UMAP (var) ###
#   UMAP_var_PAGsubdivisions <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
#                                              dimred = "UMAP_var_corrected_15_neighbors_0.01_min_dist",
#                                              colour_by = "PAG.area", shape_by = "cell.type",
#                                              point_alpha = 0.6, point_size = 2, theme_size = 11
#                                              ) + labs(title = "PAG subdivisions", x = "UMAP 1", y = "UMAP 2") + theme_args_tSNE_UMAP_clustering
#   
#   # Using HVG from Var with rank-based weights
#   UMAP_var_RankWalktrap <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
#                                           dimred = "UMAP_var_corrected_15_neighbors_0.01_min_dist",
#                                           colour_by = "SNN_clusters_var_rank", shape_by = "cell.type", text_by = "SNN_clusters_var_rank",
#                                           point_alpha = 0.6, point_size = 2, theme_size = 11
#                                           ) + labs(title = "Rank-Walktrap", x = "UMAP 1", y = "UMAP 2") + theme_args_tSNE_UMAP_clustering
#   
#   # Using HVG from Var with jaccard-based weights
#   UMAP_var_JaccardLouvain <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
#                                             dimred = "UMAP_var_corrected_15_neighbors_0.01_min_dist",
#                                             colour_by = "SNN_clusters_var_jaccard", shape_by = "cell.type", text_by = "SNN_clusters_var_jaccard",
#                                             point_alpha = 0.6, point_size = 2, theme_size = 11
#                                             ) + labs(title = "Jaccard-Louvain", x = "UMAP 1", y = "UMAP 2") + theme_args_tSNE_UMAP_clustering
#   
#   
#   ### Using UMAP (cv2) - 10_neighbors_0.01_min_dist ###
#   UMAP_cv2_10_001_PAGsubdivisions <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
#                                                     dimred = "UMAP_cv2_corrected_10_neighbors_0.01_min_dist",
#                                                     colour_by = "PAG.area", shape_by = "cell.type",
#                                                     point_alpha = 0.6, point_size = 2, theme_size = 11
#                                                     ) + labs(title = "PAG subdivisions", x = "UMAP 1", y = "UMAP 2") + theme_args_tSNE_UMAP_clustering
#   
#   # Using HVG from CV2 with rank-based weights
#   UMAP_cv2_10_001_RankWalktrap <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
#                                                  dimred = "UMAP_cv2_corrected_10_neighbors_0.01_min_dist",
#                                                  colour_by = "SNN_clusters_cv2_rank", shape_by = "cell.type", text_by = "SNN_clusters_cv2_rank",
#                                                  point_alpha = 0.6, point_size = 2, theme_size = 11
#                                                  ) + labs(title = "Rank-Walktrap", x = "UMAP 1", y = "UMAP 2") + theme_args_tSNE_UMAP_clustering
#   
#   # Using HVG from CV2 with jaccard-based weights
#   UMAP_cv2_10_001_JaccardLouvain <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
#                                                    dimred = "UMAP_cv2_corrected_10_neighbors_0.01_min_dist",
#                                                    colour_by = "SNN_clusters_cv2_jaccard", shape_by = "cell.type", text_by = "SNN_clusters_cv2_jaccard",
#                                                    point_alpha = 0.6, point_size = 2, theme_size = 11
#                                                    ) + labs(title = "Jaccard-Louvain", x = "UMAP 1", y = "UMAP 2") + theme_args_tSNE_UMAP_clustering
#   
#   
#   ### Using UMAP (CV2) - 15_neighbors_0.01_min_dist ###
#   UMAP_cv2_15_001_PAGsubdivisions <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
#                                                     dimred = "UMAP_cv2_corrected_15_neighbors_0.01_min_dist",
#                                                     colour_by = "PAG.area", shape_by = "cell.type",
#                                                     point_alpha = 0.6, point_size = 2, theme_size = 11
#                                                     ) + labs(title = "PAG subdivisions", x = "UMAP 1", y = "UMAP 2") + theme_args_tSNE_UMAP_clustering
#   
#   # Using HVG from CV2 with rank-based weights
#   UMAP_cv2_15_001_RankWalktrap <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
#                                                  dimred = "UMAP_cv2_corrected_15_neighbors_0.01_min_dist",
#                                                  colour_by = "SNN_clusters_cv2_rank", shape_by = "cell.type", text_by = "SNN_clusters_cv2_rank",
#                                                  point_alpha = 0.6, point_size = 2, theme_size = 11
#                                                  ) + labs(title = "Rank-Walktrap", x = "UMAP 1", y = "UMAP 2") + theme_args_tSNE_UMAP_clustering
#   
#   # Using HVG from CV2 with jaccard-based weights
#   UMAP_cv2_15_001_JaccardLouvain <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
#                                                    dimred = "UMAP_cv2_corrected_15_neighbors_0.01_min_dist",
#                                                    colour_by = "SNN_clusters_cv2_jaccard", shape_by = "cell.type", text_by = "SNN_clusters_cv2_jaccard",
#                                                    point_alpha = 0.6, point_size = 2, theme_size = 11
#                                                    ) + labs(title = "Jaccard-Louvain", x = "UMAP 1", y = "UMAP 2") + theme_args_tSNE_UMAP_clustering
#   
#   
#   # Prepare and save composed plots
#   library(patchwork)
#   tSNE_var_SNN_clusters <- (tSNE_var_PAGsubdivisions + tSNE_var_RankWalktrap + tSNE_var_PAGsubdivisions + tSNE_var_JaccardLouvain) +
#     plot_annotation(title = paste0("Graph-based clustering on tSNE (Var) with k = ", n_k), tag_levels = "A", 
#                     theme = theme(plot.title = element_text(size = 12, face = "bold"), plot.tag = element_text(size = 11))) + plot_layout(ncol = 2)
#   
#   tSNE_cv2_SNN_clusters <- (tSNE_cv2_PAGsubdivisions + tSNE_cv2_RankWalktrap + tSNE_cv2_PAGsubdivisions + tSNE_cv2_JaccardLouvain) +
#     plot_annotation(title = paste0("Graph-based clustering on tSNE (CV2) with k = ", n_k), tag_levels = "A", 
#                     theme = theme(plot.title = element_text(size = 12, face = "bold"), plot.tag = element_text(size = 11))) + plot_layout(ncol = 2)
#   
#   UMAP_var_SNN_clusters <- (UMAP_var_PAGsubdivisions + UMAP_var_RankWalktrap + UMAP_var_PAGsubdivisions + UMAP_var_JaccardLouvain) +
#     plot_annotation(title = paste0("Graph-based clustering on UMAP (Var) with k = ", n_k), tag_levels = "A", 
#                     theme = theme(plot.title = element_text(size = 12, face = "bold"), plot.tag = element_text(size = 11))) + plot_layout(ncol = 2)
#   
#   UMAP_cv2_10_001_SNN_clusters <- (UMAP_cv2_10_001_PAGsubdivisions + UMAP_cv2_10_001_RankWalktrap + UMAP_cv2_10_001_PAGsubdivisions + UMAP_cv2_10_001_JaccardLouvain) +
#     plot_annotation(title = paste0("Graph-based clustering on UMAP (CV2) with k = ", n_k), tag_levels = "A", 
#                     theme = theme(plot.title = element_text(size = 12, face = "bold"), plot.tag = element_text(size = 11))) + plot_layout(ncol = 2)
#   
#   UMAP_cv2_15_001_SNN_clusters <- (UMAP_cv2_15_001_PAGsubdivisions + UMAP_cv2_15_001_RankWalktrap + UMAP_cv2_15_001_PAGsubdivisions + UMAP_cv2_15_001_JaccardLouvain) +
#     plot_annotation(title = paste0("Graph-based clustering on UMAP (CV2) with k = ", n_k), tag_levels = "A", 
#                     theme = theme(plot.title = element_text(size = 12, face = "bold"), plot.tag = element_text(size = 11))) + plot_layout(ncol = 2)
#   
#   # Save them
#   ggsave(filename = str_c(date, "_SNN_clusters_tSNE_var_composed_k", n_k, ".pdf"),
#          plot = tSNE_var_SNN_clusters,
#          device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
#          path = path_for_figures,
#          width = 8, height = 7, units = "in", dpi = 300,
#          family = "Arial", bg = "transparent"
#          )
#   
#   ggsave(filename = str_c(date, "_SNN_clusters_tSNE_cv2_composed_k", n_k, ".pdf"),
#          plot = tSNE_cv2_SNN_clusters,
#          device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
#          path = path_for_figures,
#          width = 8, height = 7, units = "in", dpi = 300,
#          family = "Arial", bg = "transparent"
#          )
#   
#   ggsave(filename = str_c(date, "_SNN_clusters_UMAP_var_composed_k", n_k, ".pdf"),
#          plot = UMAP_var_SNN_clusters,
#          device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
#          path = path_for_figures,
#          width = 8, height = 7, units = "in", dpi = 300,
#          family = "Arial", bg = "transparent"
#          )
#   
#   ggsave(filename = str_c(date, "_SNN_clusters_UMAP_cv2_10_001_composed_k", n_k, ".pdf"),
#          plot = UMAP_cv2_10_001_SNN_clusters,
#          device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
#          path = path_for_figures,
#          width = 8, height = 7, units = "in", dpi = 300,
#          family = "Arial", bg = "transparent"
#          )
#   
#   ggsave(filename = str_c(date, "_SNN_clusters_UMAP_cv2_15_001_composed_k", n_k, ".pdf"),
#          plot = UMAP_cv2_15_001_SNN_clusters,
#          device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
#          path = path_for_figures,
#          width = 8, height = 7, units = "in", dpi = 300,
#          family = "Arial", bg = "transparent"
#          )
# }
```

After visualizing the different clustering results embedded in our reduced dimensions we can clearly confirm two observations from the previous steps: (1) the UMAP visualizations are significantly better than the t-SNE plots for our data, and (2) using the PCs obtained from HVGs after modelling the CV2-mean trend provide more resolution than those from modelling Var-mean trend for both clustering and dimensionality reduction.

An informative exercise to compare our clustering results would be to use the Macrophage-enriched cluster to see how well do the different clustering approaches pick it up. If we look at the UMAP plot and magnify the region where that cluster falls, we can count 12 cells, so in theory, any good clustering solution for our dataset should correctly identify the right amount of cells.
```{r}
# # Count the number of cells each clustering approach assigns to the macrophage-enriched cluster ID (check that the cluster ID is indeed the correct one by looking at the UMAP plots above):
# paste0("Macrophage cluster has ", sum(PAG_sceset_qc_norm_filt_corr$SNN_clusters_var_rank==0), " cells in SNN_var_rank method")
# paste0("Macrophage cluster has ", sum(PAG_sceset_qc_norm_filt_corr$SNN_clusters_var_jaccard==8), " cells in SNN_var_jaccard method")
# paste0("Macrophage cluster has ", sum(PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_rank==6), " cells in SNN_cv2_rank method")
# paste0("Macrophage cluster has ", sum(PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_jaccard==1), " cells in SNN_cv2_jaccard method")
```

After running the two different graph-based clustering approaches with different `k` (from 5 to 15), we observe that when using the HVGs from Var modelling and the top 12 PCs, neither the Rank-Walktrap nor the Jaccard-Louvain approach manage to correctly identify the 12 cells in the Cd68+ cluster at any value of `k`. This, together with the fact that both the tSNEs and UMAPs obtained with the HVG-Var yield worse visualisations than their CV2 counterparts, leads us to not proceed with this approach.

When using the HVGs obtained from CV2 modelling and the top 17 PCs, we find that in most cases both the Rank-Walktrap and Jaccard-Louvain approaches successfully capture the 12 cells from the Cd68+ cluster. Most results identify between 2-4 VGAT clusters and between 4-6 VGluT2 clusters. After overlaying the results to the UMAP visualisation, we decide to keep the results from different `k` to further analyse.

For instance, when using the *Rank-Walktrap* approach `k = 5:10` finds 4 inhibitory clusters, whereas `k = 11:15` finds only 2. This suggests that there may be some substructure in the VGAT population, so if we want to investigate that we would have to pick a lower `k`. Furthermore, `k = 5:7` finds 6 VGluT2 clusters, whereas `k = 8:10` finds only 5. In addition, the VGluT2 clusters identified by `k = 11:13` are not great at discriminating lPAG from dmPAG cells, only `k = 12` would be good if we wanted to keep only 2 VGAT clusters and have slightly cleaner VGluT2 clusters. Finally, the VGluT2 cluster that we lose when using `k = 8:10` seems to be a slightly different subset of dmPAG cells, so if we would like to inspect them, we would keep a lower `k`, from which `k = 7` seems to be the best.

* `k = 7`: suggests 4 VGAT clusters and 6 VGluT2 clusters. 

* `k = 12`: suggests 2 VGAT clusters and 5 VGluT2 clusters. 


On the other hand, when using the *Jaccard-Louvain* approach, we find that most results match the structure found by the UMAP visualisation. Again, different `k` offer us different levels of resolution, so we can try to keep the ones below as they may offer different insights into VGAT or VGluT2 subpopulations.

* `k = 5`: suggests 4 VGAT clusters and 6 VGluT2 clusters. 

* `k = 8`: suggests 4 VGAT clusters and 5 VGluT2 clusters. 

* `k = 9`: suggests 3 VGAT clusters and 6 VGluT2 clusters. 

* `k = 13`: suggests 2 VGAT clusters and 5 VGluT2 clusters. 

We will keep the different solutions and further examine their stability and modularity. One thing is clear though, there are 3 main clusters in our dataset: VGAT neurons, VGluT2 neurons, and the small Cd68+ clusters. Furthermore, it seems that VGluT2 neurons may have a bit more granularity, with different subpopulations that trail the different PAG subdivisions. VGAT neurons seem to be slightly more homogeneous, but we consistently find at least 2 clusters that differentiate vlPAG neurons from the rest.
```{r}
library(scran)
set.seed(42)

## We will only do Graph-based clustering using the top 17 PCs and HVGs obtained from mean-cv2 modelling:
# Using HVG from CV2 with rank-based weights
graph_cv2_rank_k7 <- buildSNNGraph(PAG_sceset_qc_norm_filt_corr,
                                   k = 7, # An integer scalar specifying the number of nearest neighbors to consider during graph constructio
                                   #d = 50, # An integer scalar specifying the number of dimensions to use for the search, try 17 or 25
                                   type = "rank", # A string specifying the type of weighting scheme to use for shared neighbors
                                   subset.row = metadata(PAG_sceset_qc_norm_filt_corr)$hvg_cv2_out_no_spikes_filt,
                                   assay.type = "logcounts",
                                   use.dimred = "PCA_HVG_cv2_logcounts_17") # Use existing PCs and ignore any setting of d, subset.row and get.spikes
clusters_cv2_rank_k7 <- igraph::cluster_walktrap(graph_cv2_rank_k7)$membership
PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_rank_k7 <- factor(clusters_cv2_rank_k7)
print("Clustering results using Rank-Walktrap with k = 7")
table(PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_rank_k7)

graph_cv2_rank_k12 <- buildSNNGraph(PAG_sceset_qc_norm_filt_corr,
                                   k = 12, # An integer scalar specifying the number of nearest neighbors to consider during graph constructio
                                   #d = 50, # An integer scalar specifying the number of dimensions to use for the search, try 17 or 25
                                   type = "rank", # A string specifying the type of weighting scheme to use for shared neighbors
                                   subset.row = metadata(PAG_sceset_qc_norm_filt_corr)$hvg_cv2_out_no_spikes_filt,
                                   assay.type = "logcounts",
                                   use.dimred = "PCA_HVG_cv2_logcounts_17") # Use existing PCs and ignore any setting of d, subset.row and get.spikes
clusters_cv2_rank_k12 <- igraph::cluster_walktrap(graph_cv2_rank_k12)$membership
PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_rank_k12 <- factor(clusters_cv2_rank_k12)
print("Clustering results using Rank-Walktrap with k = 12")
table(PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_rank_k12)

# Using HVG from CV2 with jaccard-based weights
graph_cv2_jaccard_k5 <- buildSNNGraph(PAG_sceset_qc_norm_filt_corr,
                                      k = 5, # An integer scalar specifying the number of nearest neighbors to consider during graph construction
                                      #d = 50, # An integer scalar specifying the number of dimensions to use for the search, try 17 or 25
                                      type = "jaccard", # A string specifying the type of weighting scheme to use for shared neighbors
                                      subset.row = metadata(PAG_sceset_qc_norm_filt_corr)$hvg_cv2_out_no_spikes_filt,
                                      assay.type = "logcounts",
                                      use.dimred = "PCA_HVG_cv2_logcounts_17") # Use existing PCs and ignore any setting of d, subset.row and get.spikes
clusters_cv2_jaccard_k5 <- igraph::cluster_louvain(graph_cv2_jaccard_k5)$membership
PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_jaccard_k5 <- factor(clusters_cv2_jaccard_k5)
print("Clustering results using Jaccard-Louvain with k = 5")
table(PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_jaccard_k5)

graph_cv2_jaccard_k8 <- buildSNNGraph(PAG_sceset_qc_norm_filt_corr,
                                      k = 8, # An integer scalar specifying the number of nearest neighbors to consider during graph construction
                                      #d = 50, # An integer scalar specifying the number of dimensions to use for the search, try 17 or 25
                                      type = "jaccard", # A string specifying the type of weighting scheme to use for shared neighbors
                                      subset.row = metadata(PAG_sceset_qc_norm_filt_corr)$hvg_cv2_out_no_spikes_filt,
                                      assay.type = "logcounts",
                                      use.dimred = "PCA_HVG_cv2_logcounts_17") # Use existing PCs and ignore any setting of d, subset.row and get.spikes
clusters_cv2_jaccard_k8 <- igraph::cluster_louvain(graph_cv2_jaccard_k8)$membership
PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_jaccard_k8 <- factor(clusters_cv2_jaccard_k8)
print("Clustering results using Jaccard-Louvain with k = 8")
table(PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_jaccard_k8)

graph_cv2_jaccard_k9 <- buildSNNGraph(PAG_sceset_qc_norm_filt_corr,
                                      k = 9, # An integer scalar specifying the number of nearest neighbors to consider during graph construction
                                      #d = 50, # An integer scalar specifying the number of dimensions to use for the search, try 17 or 25
                                      type = "jaccard", # A string specifying the type of weighting scheme to use for shared neighbors
                                      subset.row = metadata(PAG_sceset_qc_norm_filt_corr)$hvg_cv2_out_no_spikes_filt,
                                      assay.type = "logcounts",
                                      use.dimred = "PCA_HVG_cv2_logcounts_17") # Use existing PCs and ignore any setting of d, subset.row and get.spikes
clusters_cv2_jaccard_k9 <- igraph::cluster_louvain(graph_cv2_jaccard_k9)$membership
PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_jaccard_k9 <- factor(clusters_cv2_jaccard_k9)
print("Clustering results using Jaccard-Louvain with k = 9")
table(PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_jaccard_k9)

graph_cv2_jaccard_k13 <- buildSNNGraph(PAG_sceset_qc_norm_filt_corr,
                                      k = 13, # An integer scalar specifying the number of nearest neighbors to consider during graph construction
                                      #d = 50, # An integer scalar specifying the number of dimensions to use for the search, try 17 or 25
                                      type = "jaccard", # A string specifying the type of weighting scheme to use for shared neighbors
                                      subset.row = metadata(PAG_sceset_qc_norm_filt_corr)$hvg_cv2_out_no_spikes_filt,
                                      assay.type = "logcounts",
                                      use.dimred = "PCA_HVG_cv2_logcounts_17") # Use existing PCs and ignore any setting of d, subset.row and get.spikes
clusters_cv2_jaccard_k13 <- igraph::cluster_louvain(graph_cv2_jaccard_k13)$membership
PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_jaccard_k13 <- factor(clusters_cv2_jaccard_k13)
print("Clustering results using Jaccard-Louvain with k = 13")
table(PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_jaccard_k13)
```

For each chosen solution, we have assigned the cluster assignments back into our `SingleCellExperiment` object as a factor in the column metadata. This allows us to conveniently visualize the distribution of clusters in a t-SNE or UMAP plot of our choice:
```{r}
# Set theme parameters
theme_args_UMAP_clustering <- theme(plot.title = element_text(size = 11, face = "bold"),
                                    axis.title = element_text(size = 11, face = "plain"),
                                    axis.text = element_text(size = 10, face = "plain"), 
                                    legend.text = element_text(size = 9, face = "plain"), 
                                    strip.text = element_text(size = 10, face = "plain"))

### Using UMAP (CV2) - 10_neighbors_0.01_min_dist ###
UMAP_cv2_10_001_PAGsubdivisions <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
                                                  dimred = "UMAP_cv2_corrected_10_neighbors_0.01_min_dist",
                                                  colour_by = "PAG.area", shape_by = "cell.type",
                                                  point_alpha = 0.6, point_size = 2, theme_size = 11
                                                  ) + labs(title = "PAG subdivisions", x = "UMAP 1", y = "UMAP 2") + theme_args_UMAP_clustering

# Using HVG from CV2 with rank-based weights
UMAP_cv2_10_001_RankWalktrap_k7 <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
                                                  dimred = "UMAP_cv2_corrected_10_neighbors_0.01_min_dist",
                                                  colour_by = "SNN_clusters_cv2_rank_k7", shape_by = "cell.type", text_by = "SNN_clusters_cv2_rank_k7",
                                                  point_alpha = 0.6, point_size = 2, theme_size = 11
                                                  ) + labs(title = "Rank-Walktrap (k = 7)", x = "UMAP 1", y = "UMAP 2") + theme_args_UMAP_clustering

UMAP_cv2_10_001_RankWalktrap_k12 <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
                                                  dimred = "UMAP_cv2_corrected_10_neighbors_0.01_min_dist",
                                                  colour_by = "SNN_clusters_cv2_rank_k12", shape_by = "cell.type", text_by = "SNN_clusters_cv2_rank_k12",
                                                  point_alpha = 0.6, point_size = 2, theme_size = 11
                                                  ) + labs(title = "Rank-Walktrap (k = 12)", x = "UMAP 1", y = "UMAP 2") + theme_args_UMAP_clustering

# Using HVG from CV2 with jaccard-based weights
UMAP_cv2_10_001_JaccardLouvain_k5 <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
                                                    dimred = "UMAP_cv2_corrected_10_neighbors_0.01_min_dist",
                                                    colour_by = "SNN_clusters_cv2_jaccard_k5", shape_by = "cell.type", text_by = "SNN_clusters_cv2_jaccard_k5",
                                                    point_alpha = 0.6, point_size = 2, theme_size = 11
                                                    ) + labs(title = "Jaccard-Louvain (k = 5)", x = "UMAP 1", y = "UMAP 2") + theme_args_UMAP_clustering

UMAP_cv2_10_001_JaccardLouvain_k8 <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
                                                    dimred = "UMAP_cv2_corrected_10_neighbors_0.01_min_dist",
                                                    colour_by = "SNN_clusters_cv2_jaccard_k8", shape_by = "cell.type", text_by = "SNN_clusters_cv2_jaccard_k8",
                                                    point_alpha = 0.6, point_size = 2, theme_size = 11
                                                    ) + labs(title = "Jaccard-Louvain (k = 8)", x = "UMAP 1", y = "UMAP 2") + theme_args_UMAP_clustering

UMAP_cv2_10_001_JaccardLouvain_k9 <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
                                                    dimred = "UMAP_cv2_corrected_10_neighbors_0.01_min_dist",
                                                    colour_by = "SNN_clusters_cv2_jaccard_k9", shape_by = "cell.type", text_by = "SNN_clusters_cv2_jaccard_k9",
                                                    point_alpha = 0.6, point_size = 2, theme_size = 11
                                                    ) + labs(title = "Jaccard-Louvain (k = 9)", x = "UMAP 1", y = "UMAP 2") + theme_args_UMAP_clustering

UMAP_cv2_10_001_JaccardLouvain_k13 <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
                                                    dimred = "UMAP_cv2_corrected_10_neighbors_0.01_min_dist",
                                                    colour_by = "SNN_clusters_cv2_jaccard_k13", shape_by = "cell.type", text_by = "SNN_clusters_cv2_jaccard_k13",
                                                    point_alpha = 0.6, point_size = 2, theme_size = 11
                                                    ) + labs(title = "Jaccard-Louvain (k = 13)", x = "UMAP 1", y = "UMAP 2") + theme_args_UMAP_clustering


### Using UMAP (CV2) - 15_neighbors_0.01_min_dist ###
UMAP_cv2_15_001_PAGsubdivisions <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
                                                  dimred = "UMAP_cv2_corrected_15_neighbors_0.01_min_dist",
                                                  colour_by = "PAG.area", shape_by = "cell.type",
                                                  point_alpha = 0.6, point_size = 2, theme_size = 11
                                                  ) + labs(title = "PAG subdivisions", x = "UMAP 1", y = "UMAP 2") + theme_args_UMAP_clustering

# Using HVG from CV2 with rank-based weights
UMAP_cv2_15_001_RankWalktrap_k7 <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
                                                  dimred = "UMAP_cv2_corrected_15_neighbors_0.01_min_dist",
                                                  colour_by = "SNN_clusters_cv2_rank_k7", shape_by = "cell.type", text_by = "SNN_clusters_cv2_rank_k7",
                                                  point_alpha = 0.6, point_size = 2, theme_size = 11
                                                  ) + labs(title = "Rank-Walktrap (k = 7)", x = "UMAP 1", y = "UMAP 2") + theme_args_UMAP_clustering

UMAP_cv2_15_001_RankWalktrap_k12 <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
                                                  dimred = "UMAP_cv2_corrected_15_neighbors_0.01_min_dist",
                                                  colour_by = "SNN_clusters_cv2_rank_k12", shape_by = "cell.type", text_by = "SNN_clusters_cv2_rank_k12",
                                                  point_alpha = 0.6, point_size = 2, theme_size = 11
                                                  ) + labs(title = "Rank-Walktrap (k = 12)", x = "UMAP 1", y = "UMAP 2") + theme_args_UMAP_clustering

# Using HVG from CV2 with jaccard-based weights
UMAP_cv2_15_001_JaccardLouvain_k5 <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
                                                    dimred = "UMAP_cv2_corrected_15_neighbors_0.01_min_dist",
                                                    colour_by = "SNN_clusters_cv2_jaccard_k5", shape_by = "cell.type", text_by = "SNN_clusters_cv2_jaccard_k5",
                                                    point_alpha = 0.6, point_size = 2, theme_size = 11
                                                    ) + labs(title = "Jaccard-Louvain (k = 5)", x = "UMAP 1", y = "UMAP 2") + theme_args_UMAP_clustering

UMAP_cv2_15_001_JaccardLouvain_k8 <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
                                                    dimred = "UMAP_cv2_corrected_15_neighbors_0.01_min_dist",
                                                    colour_by = "SNN_clusters_cv2_jaccard_k8", shape_by = "cell.type", text_by = "SNN_clusters_cv2_jaccard_k8",
                                                    point_alpha = 0.6, point_size = 2, theme_size = 11
                                                    ) + labs(title = "Jaccard-Louvain (k = 8)", x = "UMAP 1", y = "UMAP 2") + theme_args_UMAP_clustering

UMAP_cv2_15_001_JaccardLouvain_k9 <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
                                                    dimred = "UMAP_cv2_corrected_15_neighbors_0.01_min_dist",
                                                    colour_by = "SNN_clusters_cv2_jaccard_k9", shape_by = "cell.type", text_by = "SNN_clusters_cv2_jaccard_k9",
                                                    point_alpha = 0.6, point_size = 2, theme_size = 11
                                                    ) + labs(title = "Jaccard-Louvain (k = 9)", x = "UMAP 1", y = "UMAP 2") + theme_args_UMAP_clustering

UMAP_cv2_15_001_JaccardLouvain_k13 <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
                                                    dimred = "UMAP_cv2_corrected_15_neighbors_0.01_min_dist",
                                                    colour_by = "SNN_clusters_cv2_jaccard_k13", shape_by = "cell.type", text_by = "SNN_clusters_cv2_jaccard_k13",
                                                    point_alpha = 0.6, point_size = 2, theme_size = 11
                                                    ) + labs(title = "Jaccard-Louvain (k = 13)", x = "UMAP 1", y = "UMAP 2") + theme_args_UMAP_clustering


# Prepare and save composed plots
library(patchwork)
UMAP_cv2_10_001_SNN_clusters_RankWalktrap <- ((UMAP_cv2_10_001_PAGsubdivisions + UMAP_cv2_10_001_RankWalktrap_k7) /
                                                (UMAP_cv2_10_001_PAGsubdivisions + UMAP_cv2_10_001_RankWalktrap_k12)) +
  plot_annotation(title = "Graph-based clustering on UMAP (CV2 - Rank)", tag_levels = "A", 
                  theme = theme(plot.title = element_text(size = 12, face = "bold"), plot.tag = element_text(size = 11))) + 
  plot_layout(guides = "collect")

UMAP_cv2_10_001_SNN_clusters_JaccardLouvain <- ((UMAP_cv2_10_001_PAGsubdivisions + UMAP_cv2_10_001_PAGsubdivisions) /
                                                  (UMAP_cv2_10_001_JaccardLouvain_k5 + UMAP_cv2_10_001_JaccardLouvain_k8) /
                                                  (UMAP_cv2_10_001_JaccardLouvain_k9 + UMAP_cv2_10_001_JaccardLouvain_k13)) +
  plot_annotation(title = "Graph-based clustering on UMAP (CV2 - Jaccard)", tag_levels = "A", 
                  theme = theme(plot.title = element_text(size = 12, face = "bold"), plot.tag = element_text(size = 11))) + 
  plot_layout(guides = "collect")

UMAP_cv2_15_001_SNN_clusters_RankWalktrap <- ((UMAP_cv2_15_001_PAGsubdivisions + UMAP_cv2_15_001_RankWalktrap_k7) /
                                                (UMAP_cv2_15_001_PAGsubdivisions + UMAP_cv2_15_001_RankWalktrap_k12)) +
  plot_annotation(title = "Graph-based clustering on UMAP (CV2 - Rank)", tag_levels = "A", 
                  theme = theme(plot.title = element_text(size = 12, face = "bold"), plot.tag = element_text(size = 11))) + 
  plot_layout(guides = "collect")

UMAP_cv2_15_001_SNN_clusters_JaccardLouvain <- ((UMAP_cv2_15_001_PAGsubdivisions + UMAP_cv2_15_001_PAGsubdivisions) /
                                                  (UMAP_cv2_15_001_JaccardLouvain_k5 + UMAP_cv2_15_001_JaccardLouvain_k8) /
                                                  (UMAP_cv2_15_001_JaccardLouvain_k9 + UMAP_cv2_15_001_JaccardLouvain_k13)) +
  plot_annotation(title = "Graph-based clustering on UMAP (CV2 - Jaccard)", tag_levels = "A", 
                  theme = theme(plot.title = element_text(size = 12, face = "bold"), plot.tag = element_text(size = 11))) + 
  plot_layout(guides = "collect")


# Plot them
UMAP_cv2_10_001_SNN_clusters_RankWalktrap
UMAP_cv2_10_001_SNN_clusters_JaccardLouvain
UMAP_cv2_15_001_SNN_clusters_RankWalktrap
UMAP_cv2_15_001_SNN_clusters_JaccardLouvain

# Save them
ggsave(filename = str_c(date, "_SNN_clusters_UMAP_cv2_10_001_Rank_composed.pdf"),
       plot = UMAP_cv2_10_001_SNN_clusters_RankWalktrap,
       device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
       path = path_for_figures,
       width = 8, height = 7, units = "in", dpi = 300,
       family = "Arial", bg = "transparent"
       )

ggsave(filename = str_c(date, "_SNN_clusters_UMAP_cv2_10_001_Jaccard_composed.pdf"),
       plot = UMAP_cv2_10_001_SNN_clusters_JaccardLouvain,
       device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
       path = path_for_figures,
       width = 8, height = 10, units = "in", dpi = 300,
       family = "Arial", bg = "transparent"
       )

ggsave(filename = str_c(date, "_SNN_clusters_UMAP_cv2_15_001_Rank_composed.pdf"),
       plot = UMAP_cv2_15_001_SNN_clusters_RankWalktrap,
       device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
       path = path_for_figures,
       width = 8, height = 7, units = "in", dpi = 300,
       family = "Arial", bg = "transparent"
       )

ggsave(filename = str_c(date, "_SNN_clusters_UMAP_cv2_15_001_Jaccard_composed.pdf"),
       plot = UMAP_cv2_15_001_SNN_clusters_JaccardLouvain,
       device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
       path = path_for_figures,
       width = 8, height = 10, units = "in", dpi = 300,
       family = "Arial", bg = "transparent"
       )
```

### 6.1.2 | Assessing cluster separation
When dealing with graphs, the modularity is a natural metric for evaluating the separation between communities/clusters. This is defined as the (scaled) difference between the observed total weight of edges between nodes in the same cluster and the expected total weight if edge weights were randomly distributed across all pairs of nodes. Larger modularity values indicate that most edges occur within clusters, suggesting that the clusters are sufficiently well separated to avoid edges forming between neighboring cells in different clusters.

The standard approach is to report a single modularity value for a clustering on a given graph. This is useful for comparing different clusterings on the same graph - and indeed, some community detection algorithms are designed with the aim of maximizing the modularity - but it is less helpful for interpreting a given clustering. We can instead use the `clusterModularity()` function with `as.ratio = TRUE`, which returns the ratio of the observed to expected sum of weights between each pair of clusters. We use the ratio instead of the difference as the former is less dependent on the number of cells in each cluster. 

A well-separated cluster should have mostly intra-cluster edges and a high modularity score on the corresponding diagonal entry, while two closely related clusters that are weakly separated will have many inter-cluster edges and a high off-diagonal score. We would usually expect to see high observed weights between cells in the same cluster with minimal weights between clusters, indicating that the clusters are well-separated. Off-diagonal entries indicate that some clusters are closely related, which is useful to know for checking that they are annotated consistently.
```{r}
ratio_cv2_rank_k7 <- clusterModularity(graph_cv2_rank_k7, clusters_cv2_rank_k7, as.ratio = TRUE)
ratio_cv2_rank_k7

ratio_cv2_rank_k12 <- clusterModularity(graph_cv2_rank_k12, clusters_cv2_rank_k12, as.ratio = TRUE)
ratio_cv2_rank_k12

ratio_cv2_jaccard_k5 <- clusterModularity(graph_cv2_jaccard_k5, clusters_cv2_jaccard_k5, as.ratio = TRUE)
ratio_cv2_jaccard_k5

ratio_cv2_jaccard_k8 <- clusterModularity(graph_cv2_jaccard_k8, clusters_cv2_jaccard_k8, as.ratio = TRUE)
ratio_cv2_jaccard_k8

ratio_cv2_jaccard_k9 <- clusterModularity(graph_cv2_jaccard_k9, clusters_cv2_jaccard_k9, as.ratio = TRUE)
ratio_cv2_jaccard_k9

ratio_cv2_jaccard_k13 <- clusterModularity(graph_cv2_jaccard_k13, clusters_cv2_jaccard_k13, as.ratio = TRUE)
ratio_cv2_jaccard_k13
```

In each matrix, each row/column corresponds to a cluster, and each entry of the matrix contains the ratio of the observed to total weight of edges between cells in the respective clusters. A dataset containing well-separated clusters should contain most of the observed total weight on the diagonal entries, meaning that most edges occur between cells in the same cluster. Concentration of the weight on the diagonal indicates that most of the clusters are well-separated, while some modest off-diagonal entries represent closely related clusters with more inter-connecting edges.

If we log2 transform the values of the matrices above, we can see that although all values are between 0 and 7, each matrix has a different `max` and `min` value. Given that we want to be able to visually compare the different methods and choose the one that provides the highest values in the diagonal, we can use `breaks =` in the `pheatmap()` function to ensure the color scale covers from 0 to 7 in all cases. This ensures that the colors in the different heatmaps cover the full range, and thus ensures that a matrix with a lower `max` value will have a different color than one with a higher `max` value. Otherwise the colors would be different for each plot, and not directly comparable. This will allow us to visualise the best diagonal:
```{r}
library(pheatmap)
cluster_modularity_cv2_rank_k7 <- pheatmap(log2(ratio_cv2_rank_k7 + 1), 
                                           main = "Cluster Modularity: Rank-Walktrap (k = 7)", fontsize = 10,
                                           border_color = "grey60", cellwidth = 20, cellheight = 20,
                                           cluster_cols = FALSE, cluster_rows = FALSE, angle_col = 0, 
                                           color = rev(viridis::magma(100)), # color = colorRampPalette(c("white", "blue"))(100) or color = rev(viridis::magma(100))
                                           legend_breaks = c(0, 1, 2, 3, 4, 5, 6), breaks = seq(0, 6, length = 100))

cluster_modularity_cv2_rank_k12 <- pheatmap(log2(ratio_cv2_rank_k12 + 1), 
                                            main = "Cluster Modularity: Rank-Walktrap (k = 12)", fontsize = 10,
                                            border_color = "grey60", cellwidth = 20, cellheight = 20,
                                            cluster_cols = FALSE, cluster_rows = FALSE, angle_col = 0, 
                                            color = rev(viridis::magma(100)), # color = colorRampPalette(c("white", "blue"))(100) or color = rev(viridis::magma(100))
                                            legend_breaks = c(0, 1, 2, 3, 4, 5, 6), breaks = seq(0, 6, length = 100))

cluster_modularity_cv2_jaccard_k5 <- pheatmap(log2(ratio_cv2_jaccard_k5 + 1), 
                                              main = "Cluster Modularity: Jaccard-Louvain (k = 5)", fontsize = 10,
                                              border_color = "grey60", cellwidth = 20, cellheight = 20,
                                              cluster_cols = FALSE, cluster_rows = FALSE, angle_col = 0, 
                                              color = rev(viridis::magma(100)), # color = colorRampPalette(c("white", "blue"))(100) or color = rev(viridis::magma(100))
                                              legend_breaks = c(0, 1, 2, 3, 4, 5, 6), breaks = seq(0, 6, length = 100))

cluster_modularity_cv2_jaccard_k8 <- pheatmap(log2(ratio_cv2_jaccard_k8 + 1),
                                              main = "Cluster Modularity: Jaccard-Louvain (k = 8)", fontsize = 10,
                                              border_color = "grey60", cellwidth = 20, cellheight = 20,
                                              cluster_cols = FALSE, cluster_rows = FALSE, angle_col = 0, 
                                              color = rev(viridis::magma(100)), # color = colorRampPalette(c("white", "blue"))(100) or color = rev(viridis::magma(100))
                                              legend_breaks = c(0, 1, 2, 3, 4, 5, 6), breaks = seq(0, 6, length = 100))

cluster_modularity_cv2_jaccard_k9 <- pheatmap(log2(ratio_cv2_jaccard_k9 + 1), 
                                              main = "Cluster Modularity: Jaccard-Louvain (k = 9)", fontsize = 10,
                                              border_color = "grey60", cellwidth = 20, cellheight = 20,
                                              cluster_cols = FALSE, cluster_rows = FALSE, angle_col = 0, 
                                              color = rev(viridis::magma(100)), # color = colorRampPalette(c("white", "blue"))(100) or color = rev(viridis::magma(100))
                                              legend_breaks = c(0, 1, 2, 3, 4, 5, 6), breaks = seq(0, 6, length = 100))

cluster_modularity_cv2_jaccard_k13 <- pheatmap(log2(ratio_cv2_jaccard_k13 + 1), 
                                               main = "Cluster Modularity: Jaccard-Louvain (k = 13)", fontsize = 10,
                                               border_color = "grey60", cellwidth = 20, cellheight = 20,
                                               cluster_cols = FALSE, cluster_rows = FALSE, angle_col = 0, 
                                               color = rev(viridis::magma(100)), # color = colorRampPalette(c("white", "blue"))(100) or color = rev(viridis::magma(100))
                                               legend_breaks = c(0, 1, 2, 3, 4, 5, 6), breaks = seq(0, 6, length = 100))

# Save them
ggsave(filename = str_c(date, "_SNN_cluster_modularity_cv2_rank_k7.pdf"),
       plot = cluster_modularity_cv2_rank_k7,
       device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
       path = path_for_figures,
       width = 5, height = 4, units = "in", dpi = 300,
       family = "Arial", bg = "transparent"
       )
ggsave(filename = str_c(date, "_SNN_cluster_modularity_cv2_rank_k12.pdf"),
       plot = cluster_modularity_cv2_rank_k12,
       device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
       path = path_for_figures,
       width = 5, height = 4, units = "in", dpi = 300,
       family = "Arial", bg = "transparent"
       )
ggsave(filename = str_c(date, "_SNN_cluster_modularity_cv2_jaccard_k5.pdf"),
       plot = cluster_modularity_cv2_jaccard_k5,
       device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
       path = path_for_figures,
       width = 5, height = 4, units = "in", dpi = 300,
       family = "Arial", bg = "transparent"
       )
ggsave(filename = str_c(date, "_SNN_cluster_modularity_cv2_jaccard_k8.pdf"),
       plot = cluster_modularity_cv2_jaccard_k8,
       device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
       path = path_for_figures,
       width = 5, height = 4, units = "in", dpi = 300,
       family = "Arial", bg = "transparent"
       )
ggsave(filename = str_c(date, "_SNN_cluster_modularity_cv2_jaccard_k9.pdf"),
       plot = cluster_modularity_cv2_jaccard_k9,
       device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
       path = path_for_figures,
       width = 5, height = 4, units = "in", dpi = 300,
       family = "Arial", bg = "transparent"
       )
ggsave(filename = str_c(date, "_SNN_cluster_modularity_cv2_jaccard_k13.pdf"),
       plot = cluster_modularity_cv2_jaccard_k13,
       device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
       path = path_for_figures,
       width = 5, height = 4, units = "in", dpi = 300,
       family = "Arial", bg = "transparent"
       )
```

These heatmaps are most useful when examined side by side with the clustering results embedded in the UMAP plots, as we can then assess the relationship between nearby and far apart clusters. For example, in _"Cluster Modularity (k = 8) - Jaccard Louvain (cv2)"_ we can see that cluster 1 has the highest score and doesn't relate to any other, which makes sense as it is the one with macrophage markers. However, clusters 5, 6, 7, 8 have relatively low diagonal scores and are related to each other, which makes sense as these are all VGluT2 cells sitting close to each other in the UMAP.

### 6.1.3 | Evaluating cluster stability
A desirable property of a given clustering is that it is stable to perturbations to the input data (Von Luxburg 2010). Stable clusters are logistically convenient as small changes to upstream processing will not change the conclusions; greater stability also increases the likelihood that those conclusions can be reproduced in an independent replicate study. `scran` uses bootstrapping to evaluate the stability of a clustering algorithm on a given dataset - that is, cells are sampled with replacement to create a “bootstrap replicate” dataset, and clustering is repeated on this replicate to see if the same clusters can be reproduced. 

Bootstrapping is conventionally used to evaluate the precision of an estimator by applying it to an in silico-generated replicate dataset. We can use this framework to determine the stability of the clusters in the context of a scRNA-seq analysis. We sample cells with replacement from `x`, perform clustering with `FUN` and compare the new clusters to clusters. The relevant statistic is the co-assignment probability for each pair of original clusters, i.e., the probability that a randomly chosen cells from each of the two original clusters will be put in the same bootstrap cluster. High co-assignment probabilities indicate that the two original clusters were not stably separated. We might then only trust separation between two clusters if their co-assignment probability was less than some threshold, e.g., 5%. The co-assignment probability of each cluster to itself provides some measure of per-cluster stability. A probability of 1 indicates that all cells are always assigned to the same cluster across bootstrap iterations, while internal structure that encourages the formation of subclusters will lower this probability.

We perform bootstrapping for our choice of graph clustering approaches:
```{r}
# Write functions for cv2 approaches
myClusterFUN_cv2_rank <- function(x, chosen_k) {
  g <- buildSNNGraph(x, k = chosen_k, type = "rank",
                     subset.row = metadata(PAG_sceset_qc_norm_filt_corr)$hvg_cv2_out_no_spikes_filt,
                     assay.type = "logcounts", use.dimred = "PCA_HVG_cv2_logcounts_17")
  igraph::cluster_walktrap(g)$membership
}

myClusterFUN_cv2_jaccard <- function(x, chosen_k) {
  g <- buildSNNGraph(x, k = chosen_k, type = "jaccard",
                     subset.row = metadata(PAG_sceset_qc_norm_filt_corr)$hvg_cv2_out_no_spikes_filt,
                     assay.type = "logcounts", use.dimred = "PCA_HVG_cv2_logcounts_17")
  igraph::cluster_louvain(g)$membership
}

# originals <- myClusterFUN(PAG_sceset_qc_norm_filt_corr) # Alternatively, simply input the previously computed clusters below

# Run bootstraping for each chosen graph clustering solution. 
set.seed(42)
start_time <- Sys.time() # Takes around 2 min with 50 iterations, and 35min with a 1000 iterations
coassign_cv2_rank_k7 <- suppressWarnings(bootstrapCluster(PAG_sceset_qc_norm_filt_corr,
                                                          FUN = myClusterFUN_cv2_rank,
                                                          clusters = clusters_cv2_rank_k7,
                                                          iterations = 1000, # default is 20, do 1000
                                                          chosen_k = 7))
dim(coassign_cv2_rank_k7)

coassign_cv2_rank_k12 <- suppressWarnings(bootstrapCluster(PAG_sceset_qc_norm_filt_corr,
                                                           FUN = myClusterFUN_cv2_rank,
                                                           clusters = clusters_cv2_rank_k12,
                                                           iterations = 1000, # default is 20, do 1000
                                                           chosen_k = 12))
dim(coassign_cv2_rank_k12)

coassign_cv2_jaccard_k5 <- suppressWarnings(bootstrapCluster(PAG_sceset_qc_norm_filt_corr,
                                                             FUN = myClusterFUN_cv2_jaccard,
                                                             clusters = clusters_cv2_jaccard_k5,
                                                             iterations = 1000, # default is 20, do 1000
                                                             chosen_k = 5))
dim(coassign_cv2_jaccard_k5)

coassign_cv2_jaccard_k8 <- suppressWarnings(bootstrapCluster(PAG_sceset_qc_norm_filt_corr,
                                                             FUN = myClusterFUN_cv2_jaccard,
                                                             clusters = clusters_cv2_jaccard_k8,
                                                             iterations = 1000, # default is 20, do 1000
                                                             chosen_k = 8))
dim(coassign_cv2_jaccard_k8)

coassign_cv2_jaccard_k9 <- suppressWarnings(bootstrapCluster(PAG_sceset_qc_norm_filt_corr,
                                                             FUN = myClusterFUN_cv2_jaccard,
                                                             clusters = clusters_cv2_jaccard_k9,
                                                             iterations = 1000, # default is 20, do 1000
                                                             chosen_k = 9))
dim(coassign_cv2_jaccard_k9)

coassign_cv2_jaccard_k13 <- suppressWarnings(bootstrapCluster(PAG_sceset_qc_norm_filt_corr,
                                                              FUN = myClusterFUN_cv2_jaccard,
                                                              clusters = clusters_cv2_jaccard_k13,
                                                              iterations = 1000, # default is 20, do 1000
                                                              chosen_k = 13))
dim(coassign_cv2_jaccard_k13)

end_time <- Sys.time()
end_time - start_time
```

The function returns a matrix of coassignment probabilities between every pair of original clusters. Each coassignment probability between clusters X and Y represents the probability that a randomly chosen cell from X and a randomly chosen cell from Y are assigned to the same cluster in the bootstrap replicate. High co-assignment probabilities indicate that X is not stable with respect to its separation from Y, given that their cells are liable to cluster together in the replicates. Ideally, we would hope for high coassignment probabilites on the diagonal (i.e., X cells cluster with themselves) and low probabilites off the diagonal.
```{r}
coassign_cv2_rank_k7
coassign_cv2_rank_k12
coassign_cv2_jaccard_k5
coassign_cv2_jaccard_k8
coassign_cv2_jaccard_k9
coassign_cv2_jaccard_k13
```

If we take a look at the matrices, we can see that although all values are between 0 and 1, each matrix has a different `max` and `min` value. Given that we want to be able to visually compare the different methods and choose the one that provides the highest values in the diagonal, we can use `breaks =` in the `pheatmap()` function to ensure the color scale covers from 0 to 1. This ensures that the colors in the different heatmaps go from 0 to 1, and thus ensures that a matrix with a lower `max` value will have a different color than one with a higher `max` value. Otherwise the colors would go from `coassign_var_rank_k8[which.min(coassign_var_rank_k8)]` to `coassign_var_rank_k8[which.max(coassign_var_rank_k8)]` and will be different for each plot, so not directly comparable. This will allow us to visualise the best diagonal:
```{r}
library(pheatmap)
cluster_stability_cv2_rank_k7 <- pheatmap(coassign_cv2_rank_k7,
                                          main = "Cluster Stability: Rank-Walktrap (k = 7)", fontsize = 10,
                                          border_color = "grey60", cellwidth = 20, cellheight = 20,
                                          cluster_cols = FALSE, cluster_rows = FALSE, angle_col = 0, 
                                          color = rev(viridis::magma(100)), # colorRampPalette(c("white", "blue"))(100)
                                          legend_breaks = c(0, 0.2, 0.4, 0.6, 0.8, 1), breaks = seq(0, 1, length = 100))

cluster_stability_cv2_rank_k12 <- pheatmap(coassign_cv2_rank_k12, 
                                           main = "Cluster Stability: Rank-Walktrap (k = 12)", fontsize = 10,
                                           border_color = "grey60", cellwidth = 20, cellheight = 20,
                                           cluster_cols = FALSE, cluster_rows = FALSE, angle_col = 0, 
                                           color = rev(viridis::magma(100)), # colorRampPalette(c("white", "blue"))(100)
                                           legend_breaks = c(0, 0.2, 0.4, 0.6, 0.8, 1), breaks = seq(0, 1, length = 100))

cluster_stability_cv2_jaccard_k5 <- pheatmap(coassign_cv2_jaccard_k5, 
                                             main = "Cluster Stability: Jaccard-Louvain (k = 5)", fontsize = 10,
                                             border_color = "grey60", cellwidth = 20, cellheight = 20,
                                             cluster_cols = FALSE, cluster_rows = FALSE, angle_col = 0, 
                                             color = rev(viridis::magma(100)), # colorRampPalette(c("white", "blue"))(100)
                                             legend_breaks = c(0, 0.2, 0.4, 0.6, 0.8, 1), breaks = seq(0, 1, length = 100))

cluster_stability_cv2_jaccard_k8 <- pheatmap(coassign_cv2_jaccard_k8,
                                             main = "Cluster Stability: Jaccard-Louvain (k = 8)", fontsize = 10,
                                             border_color = "grey60", cellwidth = 20, cellheight = 20,
                                             cluster_cols = FALSE, cluster_rows = FALSE, angle_col = 0, 
                                             color = rev(viridis::magma(100)), # colorRampPalette(c("white", "blue"))(100)
                                             legend_breaks = c(0, 0.2, 0.4, 0.6, 0.8, 1), breaks = seq(0, 1, length = 100))

cluster_stability_cv2_jaccard_k9 <- pheatmap(coassign_cv2_jaccard_k9, 
                                             main = "Cluster Stability: Jaccard-Louvain (k = 9)", fontsize = 10,
                                             border_color = "grey60", cellwidth = 20, cellheight = 20,
                                             cluster_cols = FALSE, cluster_rows = FALSE, angle_col = 0, 
                                             color = rev(viridis::magma(100)), # colorRampPalette(c("white", "blue"))(100)
                                             legend_breaks = c(0, 0.2, 0.4, 0.6, 0.8, 1), breaks = seq(0, 1, length = 100))

cluster_stability_cv2_jaccard_k13 <- pheatmap(coassign_cv2_jaccard_k13, 
                                              main = "Cluster Stability: Jaccard-Louvain (k = 13)", fontsize = 10,
                                              border_color = "grey60", cellwidth = 20, cellheight = 20,
                                              cluster_cols = FALSE, cluster_rows = FALSE, angle_col = 0, 
                                              color = rev(viridis::magma(100)), # colorRampPalette(c("white", "blue"))(100)
                                              legend_breaks = c(0, 0.2, 0.4, 0.6, 0.8, 1), breaks = seq(0, 1, length = 100))

# Save them
ggsave(filename = str_c(date, "_SNN_cluster_stability_cv2_rank_k7.pdf"),
       plot = cluster_stability_cv2_rank_k7,
       device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
       path = path_for_figures,
       width = 5, height = 4, units = "in", dpi = 300,
       family = "Arial", bg = "transparent"
       )
ggsave(filename = str_c(date, "_SNN_cluster_stability_cv2_rank_k12.pdf"),
       plot = cluster_stability_cv2_rank_k12,
       device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
       path = path_for_figures,
       width = 5, height = 4, units = "in", dpi = 300,
       family = "Arial", bg = "transparent"
       )
ggsave(filename = str_c(date, "_SNN_cluster_stability_cv2_jaccard_k5.pdf"),
       plot = cluster_stability_cv2_jaccard_k5,
       device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
       path = path_for_figures,
       width = 5, height = 4, units = "in", dpi = 300,
       family = "Arial", bg = "transparent"
       )
ggsave(filename = str_c(date, "_SNN_cluster_stability_cv2_jaccard_k8.pdf"),
       plot = cluster_stability_cv2_jaccard_k8,
       device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
       path = path_for_figures,
       width = 5, height = 4, units = "in", dpi = 300,
       family = "Arial", bg = "transparent"
       )
ggsave(filename = str_c(date, "_SNN_cluster_stability_cv2_jaccard_k9.pdf"),
       plot = cluster_stability_cv2_jaccard_k9,
       device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
       path = path_for_figures,
       width = 5, height = 4, units = "in", dpi = 300,
       family = "Arial", bg = "transparent"
       )
ggsave(filename = str_c(date, "_SNN_cluster_stability_cv2_jaccard_k13.pdf"),
       plot = cluster_stability_cv2_jaccard_k13,
       device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
       path = path_for_figures,
       width = 5, height = 4, units = "in", dpi = 300,
       family = "Arial", bg = "transparent"
       )
```

Bootstrapping is a general approach for evaluating cluster stability that is compatible with any clustering algorithm. The coassignment probability is also more informative than a single per-cluster stability measure as the former considers the relationships between clusters, e.g., unstable separation between X and Y does not penalize the stability of separation between X and another cluster Z. Of course, one should take these probabilities with a grain of salt, as bootstrapping only considers the effect of sampling noise and ignores other factors that affect reproducibility in an independent study (e.g., batch effects, donor variation). In addition, it is possible for a poor separation to be highly stable, so a highly stable cluster may not necessarily represent some distinct subpopulation.

### 6.1.4 | Double-check you have stored your clustering results
```{r}
summary(PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_rank_k7)
summary(PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_rank_k12)
summary(PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_jaccard_k5)
summary(PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_jaccard_k8)
summary(PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_jaccard_k9)
summary(PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_jaccard_k13)
```

## Step 6.2 | k-means clustering
K-means clustering is a classic technique that aims to partition cells into `k` clusters. Each cell is assigned to the cluster with the closest centroid, which is done by minimizing the within-cluster sum of squares using a *random* starting configuration for the `k` centroids. The main advantage of this approach lies in its speed, given the simplicity and ease of implementation of the algorithm. However, it suffers from a number of serious shortcomings that reduce its appeal for obtaining interpretable clusters:

* It implicitly favours spherical clusters of equal radius. This can lead to unintuitive partitionings on real datasets that contain groupings with irregular sizes and shapes.

* The number of clusters `k` must be specified beforehand and represents a hard cap on the resolution of the clustering. For example, setting `k` to be below the number of cell types will always lead to co-clustering of two cell types, regardless of how well separated they are. In contrast, other methods like graph-based clustering will respect strong separation even if the relevant resolution parameter is set to a low value.

* It is dependent on the randomly chosen initial coordinates. This requires multiple runs to verify that the clustering is stable. 

That said, k-means clustering is still one of the best approaches for sample-based data compression. We can set `k` to a large value such as the square root of the number of cells to obtain fine-grained clusters. These are not meant to be interpreted directly, but rather, the centroids are treated as “samples” for further analyses. The idea here is to obtain a single representative of each region of the expression space, reducing the number of samples and computational work in later steps like, e.g., trajectory reconstruction (Ji and Ji 2016). This approach will also eliminate differences in cell density across the expression space, ensuring that the most abundant cell type does not dominate downstream results.

### 6.2.1 | Choosing a reasonable "k"
We could first try to obtain a “reasonable” choice of `k` by computing the _gap statistic_ using methods from the `cluster` package. This is the log-ratio of the expected to observed within-cluster sum of squares, where the expected value is computed by randomly distributing cells within the minimum bounding box of the original data. A larger gap statistic represents a lower observed sum of squares - and thus better clustering - compared to a population with no structure. Ideally, we would choose the `k` that maximizes the gap statistic, but this is often unhelpful as the tendency of k-means to favour spherical clusters drives a large `k` to capture different cluster shapes. Instead, we choose the most parsimonious `k` beyond which the increases in the gap statistic are considered insignificant (when the curve is reaching saturation).
```{r}
library(cluster)
set.seed(1991)

# Using PCA from HVG_var_logcounts
gaps_var <- clusGap(reducedDim(PAG_sceset_qc_norm_filt_corr, "PCA_HVG_var_logcounts_12"), kmeans, K.max = 20)
best_k_var <- maxSE(gaps_var$Tab[,"gap"], gaps_var$Tab[,"SE.sim"])
best_k_var

plot(gaps_var$Tab[,"gap"], xlab = "Number of clusters", ylab = "Gap statistic", las = 1,
     main = "Reasonable K for HVG (Var)", sub = sprintf("Suggested value of K: %s", best_k_var))
abline(v = best_k_var, col = "red")
abline(v = 8, col = "aquamarine3", lty = "dotted", lwd = 2)

# Using PCA from HVG_cv2_logcounts
gaps_cv2 <- clusGap(reducedDim(PAG_sceset_qc_norm_filt_corr, "PCA_HVG_cv2_logcounts_17"), kmeans, K.max = 20)
best_k_cv2 <- maxSE(gaps_cv2$Tab[,"gap"], gaps_cv2$Tab[,"SE.sim"])
best_k_cv2

plot(gaps_cv2$Tab[,"gap"], xlab = "Number of clusters", ylab = "Gap statistic", las = 1,
     main = "Reasonable K for HVG (CV2)", sub = sprintf("Suggested value of K: %s", best_k_cv2))
abline(v = best_k_cv2, col = "red")
abline(v = 10, col = "aquamarine3", lty = "dotted", lwd = 2)

# Combine and save the plots
pdf(file = str_c(path_for_figures, date, "_kmeans_gap_statistic.pdf"),
    width = 6, height = 9,
    family = "Arial", bg = "transparent")
par(mfrow = c(2,1))
plot(gaps_var$Tab[,"gap"], xlab = "Number of clusters", ylab = "Gap statistic", las = 1,
     main = "Reasonable K for K-means clustering using HVG (Var)", sub = sprintf("Suggested value of K: %s", best_k_var))
abline(v = best_k_var, col = "red")
abline(v = 8, col = "aquamarine3", lty = "dotted", lwd = 2)
plot(gaps_cv2$Tab[,"gap"], xlab = "Number of clusters", ylab = "Gap statistic", las = 1,
     main = "Reasonable K for K-means clustering using HVG (CV2)", sub = sprintf("Suggested value of K: %s", best_k_cv2))
abline(v = best_k_cv2, col = "red")
abline(v = 10, col = "aquamarine3", lty = "dotted", lwd = 2)
dev.off()
```

It is a good idea to run this with different seeds to verify that the results are stable. In both cases, we can see that the suggested `k = 1` seems to be an artifact, and a value around `k = 8` or `k = 10` would perhaps be a better choice.

### 6.2.2 | Implementation of k-means clustering
Once we have a potential `k` to start with, we can perform k-means clustering with `k` values around the computed one before selecting one resulting in the desired resolution. Base R provides the `kmeans()` function that does as its name suggests. We call this on our top PCs to obtain a clustering for a specified number of clusters in the `centers =` argument, after setting the random seed to ensure that the results are reproducible. In general, the k-means clusters correspond to the visual clusters on a previously obtained t-SNE or UMAP plot, although there will be some divergences at least partially due to the fact that t-SNE and UMAP are graph-based and so will naturally agree more with a graph-based clustering strategy.
```{r}
set.seed(1991)

cluster_kmeans_var <- kmeans(reducedDim(PAG_sceset_qc_norm_filt_corr, "PCA_HVG_var_logcounts_12"), 
                             centers = 8, # either the number of clusters, say k, or a set of initial (distinct) cluster centres.
                             iter.max = 50, # the maximum number of iterations allowed.
                             nstart = 5) # if centers is a number, how many random sets should be chosen?
PAG_sceset_qc_norm_filt_corr$kmeans_clusters_var <- factor(cluster_kmeans_var$cluster)

cluster_kmeans_cv2 <- kmeans(reducedDim(PAG_sceset_qc_norm_filt_corr, "PCA_HVG_cv2_logcounts_17"), 
                             centers = 10, # either the number of clusters, say k, or a set of initial (distinct) cluster centres.
                             iter.max = 50, # the maximum number of iterations allowed.
                             nstart = 5) # if centers is a number, how many random sets should be chosen?
PAG_sceset_qc_norm_filt_corr$kmeans_clusters_cv2 <- factor(cluster_kmeans_cv2$cluster)

table(cluster_kmeans_var$cluster)
table(cluster_kmeans_cv2$cluster)
```

We can now visualize the clustering results on our preferred reduced dimensionality plot:
```{r}
# Set theme parameters
theme_args_kmeans <- theme(plot.title = element_text(size = 11, face = "bold"),
                           axis.title = element_text(size = 11, face = "plain"),
                           axis.text = element_text(size = 10, face = "plain"), 
                           legend.text = element_text(size = 9, face = "plain"), 
                           strip.text = element_text(size = 10, face = "plain"))

# UMAP using PCA from HVG_var_logcounts
UMAP_var_PAGsubdivisions <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
                                           dimred = "UMAP_var_corrected_15_neighbors_0.01_min_dist",
                                           colour_by = "PAG.area", shape_by = "cell.type", 
                                           point_alpha = 0.6, point_size = 2, theme_size = 11
                                           ) + labs(title = "HVG (Var)", x = "UMAP 1", y = "UMAP 2"
                                                    ) + theme_args_kmeans

UMAP_var_kmeans <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
                                  dimred = "UMAP_var_corrected_15_neighbors_0.01_min_dist",
                                  colour_by = "kmeans_clusters_var", shape_by = "cell.type", text_by = "kmeans_clusters_var",
                                  point_alpha = 0.6, point_size = 2, theme_size = 11
                                  ) + labs(title = "K-means (centers = 8)", x = "UMAP 1", y = "UMAP 2") + theme_args_kmeans

# UMAP using PCA from HVG_cv2_logcounts
UMAP_cv2_PAGsubdivisions <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
                                           dimred = "UMAP_cv2_corrected_15_neighbors_0.01_min_dist",
                                           colour_by = "PAG.area", shape_by = "cell.type", 
                                           point_alpha = 0.6, point_size = 2, theme_size = 11
                                           ) + labs(title = "HVG (CV2)", x = "UMAP 1", y = "UMAP 2"
                                                    ) + theme_args_kmeans

UMAP_cv2_kmeans <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
                                  dimred = "UMAP_cv2_corrected_15_neighbors_0.01_min_dist",
                                  colour_by = "kmeans_clusters_cv2", shape_by = "cell.type", text_by = "kmeans_clusters_cv2",
                                  point_alpha = 0.6, point_size = 2, theme_size = 11
                                  ) + labs(title = "K-means (centers = 10)", x = "UMAP 1", y = "UMAP 2") + theme_args_kmeans

# Prepare composed plots
library(patchwork)
UMAP_kmeans_clusters <- (UMAP_var_PAGsubdivisions + UMAP_var_kmeans +
                           UMAP_cv2_PAGsubdivisions + UMAP_cv2_kmeans +
                           plot_spacer() + plot_spacer()) +
  plot_annotation(title = "K-means clustering on UMAP", tag_levels = "A", 
                  theme = theme(plot.title = element_text(size = 12, face = "bold"), plot.tag = element_text(size = 11))) + 
  plot_layout(ncol = 2, guides = "collect")

# Plot them
UMAP_kmeans_clusters

# Save them
ggsave(filename = str_c(date, "_kmeans_UMAP_clusters_composed.pdf"),
       plot = UMAP_kmeans_clusters,
       device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
       path = path_for_figures,
       width = 8, height = 9, units = "in", dpi = 300,
       family = "Arial", bg = "transparent"
       )
```

### 6.2.3 | Overclustering
A more practical use of k-means is to deliberately set `k` to a large value to achieve overclustering. This will forcibly partition cells inside broad clusters that do not have well-defined internal structure. For example, we might be interested in the change in expression from one “side” of a cluster to the other, but the lack of any clear separation within the cluster makes it difficult to separate with graph-based methods, even at the highest resolution. k-means has no such problems and will readily split these broad clusters for greater resolution, though obviously one must be prepared for the additional work involved in interpreting a greater number of clusters.
```{r}
set.seed(1991)

overcluster_kmeans_var <- kmeans(reducedDim(PAG_sceset_qc_norm_filt_corr, "PCA_HVG_var_logcounts_12"), 
                                 centers = 20, iter.max = 50, nstart = 5)
PAG_sceset_qc_norm_filt_corr$kmeans_overcluster_var <- factor(overcluster_kmeans_var$cluster)

overcluster_kmeans_cv2 <- kmeans(reducedDim(PAG_sceset_qc_norm_filt_corr, "PCA_HVG_cv2_logcounts_17"), 
                                 centers = 20, iter.max = 50, nstart = 5)
PAG_sceset_qc_norm_filt_corr$kmeans_overcluster_cv2 <- factor(overcluster_kmeans_cv2$cluster)

table(overcluster_kmeans_var$cluster)
table(overcluster_kmeans_cv2$cluster)
```

```{r}
# Set theme parameters
theme_args_kmeans <- theme(plot.title = element_text(size = 11, face = "bold"),
                           axis.title = element_text(size = 11, face = "plain"),
                           axis.text = element_text(size = 10, face = "plain"), 
                           legend.text = element_text(size = 9, face = "plain"), 
                           strip.text = element_text(size = 10, face = "plain"))

# UMAP using PCA from HVG_var_logcounts
UMAP_var_PAGsubdivisions <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
                                           dimred = "UMAP_var_corrected_15_neighbors_0.01_min_dist",
                                           colour_by = "PAG.area", shape_by = "cell.type", 
                                           point_alpha = 0.6, point_size = 2, theme_size = 11
                                           ) + labs(title = "HVG (Var)", x = "UMAP 1", y = "UMAP 2"
                                                    ) + theme_args_kmeans

UMAP_var_kmeans_overcluster <- plotReducedDim(PAG_sceset_qc_norm_filt_corr,
                                              dimred = "UMAP_var_corrected_15_neighbors_0.01_min_dist",
                                              colour_by = "kmeans_overcluster_var", shape_by = "cell.type", text_by = "kmeans_overcluster_var",
                                              point_alpha = 0.6, point_size = 2, theme_size = 11
                                              ) + labs(title = "K-means (centers = 20)", x = "UMAP 1", y = "UMAP 2") + theme_args_kmeans

# UMAP using PCA from HVG_cv2_logcounts
UMAP_cv2_PAGsubdivisions <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
                                           dimred = "UMAP_cv2_corrected_15_neighbors_0.01_min_dist",
                                           colour_by = "PAG.area", shape_by = "cell.type", 
                                           point_alpha = 0.6, point_size = 2, theme_size = 11
                                           ) + labs(title = "HVG (CV2)", x = "UMAP 1", y = "UMAP 2"
                                                    ) + theme_args_kmeans

UMAP_cv2_kmeans_overcluster <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
                                              dimred = "UMAP_cv2_corrected_15_neighbors_0.01_min_dist",
                                              colour_by = "kmeans_overcluster_cv2", shape_by = "cell.type", text_by = "kmeans_overcluster_cv2",
                                              point_alpha = 0.6, point_size = 2, theme_size = 11
                                              ) + labs(title = "K-means (centers = 20)", x = "UMAP 1", y = "UMAP 2") + theme_args_kmeans

# Prepare composed plots
library(patchwork)
UMAP_kmeans_overclusters <- (UMAP_var_PAGsubdivisions + UMAP_var_kmeans_overcluster +
                               UMAP_cv2_PAGsubdivisions + UMAP_cv2_kmeans_overcluster +
                               plot_spacer() + plot_spacer()) +
  plot_annotation(title = "K-means overclustering on UMAP", tag_levels = "A", 
                  theme = theme(plot.title = element_text(size = 12, face = "bold"), plot.tag = element_text(size = 11))) + 
  plot_layout(ncol = 2, guides = "collect")

# Plot them
UMAP_kmeans_overclusters

# Save them
ggsave(filename = str_c(date, "_kmeans_UMAP_overclusters_composed.pdf"),
       plot = UMAP_kmeans_overclusters,
       device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
       path = path_for_figures,
       width = 8, height = 9, units = "in", dpi = 300,
       family = "Arial", bg = "transparent"
       )
```

### 6.2.4 | Assessing cluster separation
The within-cluster sum of squares (WCSS) for each cluster is the most relevant diagnostic for k-means, given that the algorithm aims to find a clustering that minimizes the WCSS. Specifically, we use the WCSS to compute the root-mean-squared deviation (RMSD) that represents the spread of cells within each cluster. A cluster is more likely to have a low RMSD if it has no internal structure and is separated from other clusters (such that there are not many cells on the boundaries between clusters, which would result in a higher sum of squares from the centroid).
```{r}
# Using PCA from HVG_var_logcounts
ncells_cluster_kmeans_var <- tabulate(cluster_kmeans_var$cluster)
tab_cluster_kmeans_var <- data.frame(wcss = cluster_kmeans_var$withinss, ncells = ncells_cluster_kmeans_var)
tab_cluster_kmeans_var$rms <- sqrt(tab_cluster_kmeans_var$wcss/tab_cluster_kmeans_var$ncells)
tab_cluster_kmeans_var

# Using PCA from HVG_cv2_logcounts
ncells_cluster_kmeans_cv2 <- tabulate(cluster_kmeans_cv2$cluster)
tab_cluster_kmeans_cv2 <- data.frame(wcss = cluster_kmeans_cv2$withinss, ncells = ncells_cluster_kmeans_cv2)
tab_cluster_kmeans_cv2$rms <- sqrt(tab_cluster_kmeans_cv2$wcss/tab_cluster_kmeans_cv2$ncells)
tab_cluster_kmeans_cv2

# Overclustering using PCA from HVG_var_logcounts
ncells_overcluster_kmeans_var <- tabulate(overcluster_kmeans_var$cluster)
tab_overcluster_kmeans_var <- data.frame(wcss = overcluster_kmeans_var$withinss, ncells = ncells_overcluster_kmeans_var)
tab_overcluster_kmeans_var$rms <- sqrt(tab_overcluster_kmeans_var$wcss/tab_overcluster_kmeans_var$ncells)
tab_overcluster_kmeans_var

# Overclustering using PCA from HVG_cv2_logcounts
ncells_overcluster_kmeans_cv2 <- tabulate(overcluster_kmeans_cv2$cluster)
tab_overcluster_kmeans_cv2 <- data.frame(wcss = overcluster_kmeans_cv2$withinss, ncells = ncells_overcluster_kmeans_cv2)
tab_overcluster_kmeans_cv2$rms <- sqrt(tab_overcluster_kmeans_cv2$wcss/tab_overcluster_kmeans_cv2$ncells)
tab_overcluster_kmeans_cv2
```

To explore the relationships between k-means clusters, a natural approach is to compute distances between their centroids. This directly lends itself to visualization as a tree after hierarchical clustering.
```{r}
library(dendextend)
# Distances from clustering with the estimated k
cent_tree_cluster_kmeans_var <- as.dendrogram(hclust(dist(cluster_kmeans_var$centers), "ward.D2"), hang = 0.1)
cent_tree_cluster_kmeans_cv2 <- as.dendrogram(hclust(dist(cluster_kmeans_cv2$centers), "ward.D2"), hang = 0.1)

# Distances from overclustering
cent_tree_overcluster_kmeans_var <- as.dendrogram(hclust(dist(overcluster_kmeans_var$centers), "ward.D2"), hang = 0.1)
cent_tree_overcluster_kmeans_cv2 <- as.dendrogram(hclust(dist(overcluster_kmeans_cv2$centers), "ward.D2"), hang = 0.1)

# Plot kmeans clusters dendrogram
par(mfrow = c(1,2), las = 1)
plot(cent_tree_cluster_kmeans_var, main = "K-means Dendrogram (Var)", xlab = "k = 8", ylab = "Height", sub = "")
plot(cent_tree_overcluster_kmeans_var, main = "K-means Dendrogram (Var)", xlab = "k = 20", ylab = "Height", sub = "")

# Plot kmeans overclusters dendrogram
par(mfrow = c(1,2), las = 1)
plot(cent_tree_cluster_kmeans_cv2, main = "K-means Dendrogram (CV2)", xlab = "k = 10", ylab = "Height", sub = "")
plot(cent_tree_overcluster_kmeans_cv2, main = "K-means Dendrogram (CV2)", xlab = "k = 20", ylab = "Height", sub = "")


# Prepare composed plots
library(patchwork)
UMAP_kmeans_var_composed <- (UMAP_var_PAGsubdivisions + UMAP_var_kmeans +
                               UMAP_var_PAGsubdivisions + UMAP_var_kmeans_overcluster +
                               plot_spacer() + plot_spacer()) +
  plot_annotation(title = "K-means clusters on UMAP (Var)", tag_levels = "A", 
                  theme = theme(plot.title = element_text(size = 12, face = "bold"), plot.tag = element_text(size = 11))) + 
  plot_layout(ncol = 2, guides = "collect")

UMAP_kmeans_cv2_composed <- (UMAP_cv2_PAGsubdivisions + UMAP_cv2_kmeans +
                               UMAP_cv2_PAGsubdivisions + UMAP_cv2_kmeans_overcluster +
                               plot_spacer() + plot_spacer()) +
  plot_annotation(title = "K-means clustering on UMAP (CV2)", tag_levels = "A", 
                  theme = theme(plot.title = element_text(size = 12, face = "bold"), plot.tag = element_text(size = 11))) + 
  plot_layout(ncol = 2, guides = "collect")

# Plot them
UMAP_kmeans_var_composed
UMAP_kmeans_cv2_composed

# Save plots
pdf(file = str_c(path_for_figures, date, "_kmeans_dendrogram_var.pdf"),
    width = 5, height = 8,
    family = "Arial", bg = "transparent")
par(mfrow = c(2,1), las = 1)
plot(cent_tree_cluster_kmeans_var, main = "K-means Dendrogram (Var)", xlab = "k = 8", ylab = "Height", sub = "")
plot(cent_tree_overcluster_kmeans_var, main = "K-means Dendrogram (Var)", xlab = "k = 20", ylab = "Height", sub = "")
dev.off()

pdf(file = str_c(path_for_figures, date, "_kmeans_dendrogram_cv2.pdf"),
    width = 5, height = 8,
    family = "Arial", bg = "transparent")
par(mfrow = c(2,1), las = 1)
plot(cent_tree_cluster_kmeans_cv2, main = "K-means Dendrogram (CV2)", xlab = "k = 10", ylab = "Height", sub = "")
plot(cent_tree_overcluster_kmeans_cv2, main = "K-means Dendrogram (CV2)", xlab = "k = 20", ylab = "Height", sub = "")
dev.off()

ggsave(filename = str_c(date, "_kmeans_UMAP_var_clusters_composed.pdf"),
       plot = UMAP_kmeans_var_composed,
       device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
       path = path_for_figures,
       width = 8, height = 9, units = "in", dpi = 300,
       family = "Arial", bg = "transparent"
       )

ggsave(filename = str_c(date, "_kmeans_UMAP_cv2_clusters_composed.pdf"),
       plot = UMAP_kmeans_cv2_composed,
       device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
       path = path_for_figures,
       width = 8, height = 9, units = "in", dpi = 300,
       family = "Arial", bg = "transparent"
       )
```

As we can see when looking at both the tree and the embedding of the k-means clusters on the UMAP, using PCs from mean-var modelling doesn't generate a tree that reflects the origin of the cells (i.e. excitatory or inhibitory cells), whereas we do see that in the results obtained with PCs from mean-cv2 modelling (it even separates the Cd68+ cluster in an entirely different branch). Overall we seem to obtain similar clusters to those we obtained from the graph-clustering approach, at least for the cv2 scenario.

## Step 6.3 | Hierarchical clustering
Hierarchical clustering aims to generate a dendrogram containing a hierarchy of samples. This is most commonly done by greedily agglomerating samples into clusters, then agglomerating those clusters into larger clusters, and so on until all samples belong to a single cluster. Variants of hierarchical clustering methods primarily differ in how they choose to perform the agglomerations. For example, complete linkage aims to merge clusters with the smallest maximum distance between their elements, while Ward’s method aims to minimize the increase in within-cluster variance.

In the context of scRNA-seq, the main advantage of hierarchical clustering lies in the production of the dendrogram. This is a rich summary that describes the relationships between cells and subpopulations at various resolutions and in a quantitative manner based on the branch lengths. Users can easily “cut” the tree at different heights to define clusters with different granularity, where clusters defined at high resolution are guaranteed to be nested within those defined at a lower resolution. (Guaranteed nesting can be helpful for interpretation.) The dendrogram is also a natural representation of the data in situations where cells have descended from a relatively recent common ancestor.

In practice, hierachical clustering is too slow to be used for anything but the smallest scRNA-seq datasets. Most variants require a cell-cell distance matrix that is prohibitively expensive to compute for many cells. Greedy agglomeration is also likely to result in a quantitatively suboptimal partitioning (as defined by the agglomeration measure) at higher levels of the dendrogram when the number of cells and merge steps is high.

### 6.3.1 | Implementation of hierarchical clustering
We compute a cell-cell distance matrix using the top PCs and we apply hierarchical clustering with Ward’s method. We can then inspect the resulting tree. While both Ward’s method and complete linkage (`hclust()`’s default) yield compact clusters, we prefer the former as it is less affected by differences in variance between clusters. This yields a dendrogram that groups together cells with similar expression patterns across the chosen genes.
```{r}
library(dendextend)

# Create palette for celltype_PAGarea:
colours_celltype_PAGarea <- c(`dmpag_VGAT` = "red", `dlpag_VGAT` = "coral2", `lpag_VGAT` = "salmon", `vlpag_VGAT` = "darksalmon",
                              `dmpag_VGluT2` = "cornflowerblue", `dlpag_VGluT2` = "cyan3", `lpag_VGluT2` = "aquamarine3", `vlpag_VGluT2` = "cadetblue3")

## Using PCA from HVG_var_logcounts
# Making a distance matrix
PAG_dist_var <- dist(reducedDim(PAG_sceset_qc_norm_filt_corr, "PCA_HVG_var_logcounts_12"), 
                     method = "euclidean" # Usual distance between the two vectors (2 norm aka L_2), sqrt(sum((x_i - y_i)^2)).
                     ) # Alternative distance, "manhattan" -> Absolute distance between the two vectors (1 norm aka L_1).
# Building a tree
PAG_tree_var <- hclust(PAG_dist_var, method = "ward.D2") # Agglomeration method to be used, default is "complete"
#plot(PAG_tree_var) # Raw tree

# Making a prettier dendrogram
PAG_tree_var$labels <- seq_along(PAG_tree_var$labels)
PAG_dend_var <- as.dendrogram(PAG_tree_var, hang = 0.1)
labels_colors(PAG_dend_var) <- colours_celltype_PAGarea[PAG_sceset_qc_norm_filt_corr$celltype_PAGarea][order.dendrogram(PAG_dend_var)]
plot(PAG_dend_var, main = "Dendrogram from hierarchical clustering (Var)", ylab = "Height", las = 1)
legend("topright", col = colours_celltype_PAGarea, pch = 19, cex = 0.75,  bty = "n",
       legend = levels(PAG_sceset_qc_norm_filt_corr$celltype_PAGarea))


## Using PCA from HVG_cv2_logcounts
# Making a distance matrix
PAG_dist_cv2 <- dist(reducedDim(PAG_sceset_qc_norm_filt_corr, "PCA_HVG_cv2_logcounts_17"), 
                     method = "euclidean" # Usual distance between the two vectors (2 norm aka L_2), sqrt(sum((x_i - y_i)^2)).
                     ) # Alternative distance, "manhattan" -> Absolute distance between the two vectors (1 norm aka L_1).
# Building a tree
PAG_tree_cv2 <- hclust(PAG_dist_cv2, "ward.D2")
# plot(PAG_tree_cv2) # Raw tree

# Making a prettier dendrogram
PAG_tree_cv2$labels <- seq_along(PAG_tree_cv2$labels)
PAG_dend_cv2 <- as.dendrogram(PAG_tree_cv2, hang = 0.1)
labels_colors(PAG_dend_cv2) <- colours_celltype_PAGarea[PAG_sceset_qc_norm_filt_corr$celltype_PAGarea][order.dendrogram(PAG_dend_cv2)]
plot(PAG_dend_cv2, main = "Dendrogram from hierarchical clustering (CV2)", ylab = "Height", las = 1)
legend("topright", col = colours_celltype_PAGarea, pch = 19, cex = 0.75,  bty = "n",
       legend = levels(PAG_sceset_qc_norm_filt_corr$celltype_PAGarea))

## Save plots
pdf(file = str_c(path_for_figures, date, "_hierarchical_dendrogram_hclust_var.pdf"),
    width = 8, height = 6,
    family = "Arial", bg = "transparent")
labels_colors(PAG_dend_var) <- colours_celltype_PAGarea[PAG_sceset_qc_norm_filt_corr$celltype_PAGarea][order.dendrogram(PAG_dend_var)]
plot(PAG_dend_var, main = "Dendrogram from hierarchical clustering (Var)", ylab = "Height", las = 1)
legend("topright", col =colours_celltype_PAGarea, pch = 19, cex = 0.75,  bty = "n",
       legend = levels(PAG_sceset_qc_norm_filt_corr$celltype_PAGarea))
dev.off()

pdf(file = str_c(path_for_figures, date, "_hierarchical_dendrogram_hclust_cv2.pdf"),
    width = 8, height = 6,
    family = "Arial", bg = "transparent")
labels_colors(PAG_dend_cv2) <- colours_celltype_PAGarea[PAG_sceset_qc_norm_filt_corr$celltype_PAGarea][order.dendrogram(PAG_dend_cv2)]
plot(PAG_dend_cv2, main = "Dendrogram from hierarchical clustering (CV2)", ylab = "Height", las = 1)
legend("topright", col = colours_celltype_PAGarea, pch = 19, cex = 0.75,  bty = "n",
       legend = levels(PAG_sceset_qc_norm_filt_corr$celltype_PAGarea))
dev.off()
```

Again, we can see how using HVG from CV2 modelling successfully separates exctitatory from inhibitory neurons, whereas the branching from the Var modelling is not as clean.

### 6.3.2 | Cutting the tree
To obtain explicit clusters, we can “cut” the tree by removing internal branches such that every subtree represents a distinct cluster. This is most simply done by removing internal branches above a certain height of the tree, as performed by the `cutree()` function. We can instead use the `dynamicTreeCut` package, which uses the shape of the branches to obtain a more suitable partitioning for complex dendrograms. Greater control of the empirical clusters can be obtained by manually specifying cutHeight in `cutreeDynamic`. We can also set `minClusterSize` to a lower value than the default of 20, to avoid spurious aggregation of distant small clusters.
```{r}
library(dynamicTreeCut)
library(dendextend)

# Create palette using scater colours:
cluster_colours_10 <- c(`1` = "#729ECE", `2` = "#FF9E4A", `3` = "#67BF5C", `4` = "#ED665D", `5` = "#AD8BC9",
                        `6` = "#A8786E", `7` = "#ED97CA", `8` = "#A2A2A2", `9` = "#CDCC5D", `10` = "#6DCCDA")

cluster_colours_20 <- c(`1` = "#1F77B4", `2` = "#AEC7E8", `3` = "#FF7F0E", `4` = "#FFBB78", `5` = "#2CA02C",
                        `6` = "#98DF8A", `7` = "#D62728", `8` = "#FF9896", `9` = "#9467BD", `10` = "#C5B0D5",
                        `11` = "#8C564B", `12` = "#C49C94", `13` = "#E377C2", `14` = "#F7B6D2", `15` = "#7F7F7F", 
                        `16` = "#C7C7C7", `17` = "#BCBD22", `18` = "#DBDB8D", `19` = "#17BECF", `20` = "#9EDAE5")

# From Var scenario
PAG_clust_var_cutreeDynamic <- cutreeDynamic(PAG_tree_var, distM = as.matrix(PAG_dist_var),
                                             minClusterSize = 15, # Default minimum cluster size is 20. minClusterSize needs to be turned down for small datasets
                                             deepSplit = 0.1) # Controls the resolution of the partitioning. The higher the value, the more and smaller clusters will be produced.
table(PAG_clust_var_cutreeDynamic)
labels_colors(PAG_dend_var) <- cluster_colours_10[PAG_clust_var_cutreeDynamic][order.dendrogram(PAG_dend_var)]
plot(PAG_dend_var, main = "Dendrogram from hierarchical clustering (Var)", sub = "Dynamic Tree Cut", ylab = "Height", las = 1)
legend("topright", col = cluster_colours_10, pch = 19, cex = 0.75,  bty = "n",
       legend = levels(factor(PAG_clust_var_cutreeDynamic)))

# From CV2 scenario
PAG_clust_cv2_cutreeDynamic <- cutreeDynamic(PAG_tree_cv2, distM = as.matrix(PAG_dist_cv2),
                                             minClusterSize = 15, # Default minimum cluster size is 20. minClusterSize needs to be turned down for small datasets
                                             deepSplit = 0.1) # Controls the resolution of the partitioning. The higher the value, the more and smaller clusters will be produced.
table(PAG_clust_cv2_cutreeDynamic)
labels_colors(PAG_dend_cv2) <- cluster_colours_20[PAG_clust_cv2_cutreeDynamic][order.dendrogram(PAG_dend_cv2)]
plot(PAG_dend_cv2, main = "Dendrogram from hierarchical clustering (CV2)", sub = "Dynamic Tree Cut", ylab = "Height", las = 1)
legend("topright", col = cluster_colours_20, pch = 19, cex = 0.75,  bty = "n",
       legend = levels(factor(PAG_clust_cv2_cutreeDynamic)))

## Save plots
pdf(file = str_c(path_for_figures, date, "_hierarchical_dendrogram_cutreeDynamic_var.pdf"),
    width = 8, height = 6,
    family = "Arial", bg = "transparent")
labels_colors(PAG_dend_var) <- cluster_colours_10[PAG_clust_var_cutreeDynamic][order.dendrogram(PAG_dend_var)]
plot(PAG_dend_var, main = "Dendrogram from hierarchical clustering (Var)", sub = "Dynamic Tree Cut", ylab = "Height", las = 1)
legend("topright", col = cluster_colours_10, pch = 19, cex = 0.75,  bty = "n",
       legend = levels(factor(PAG_clust_var_cutreeDynamic)))
dev.off()

pdf(file = str_c(path_for_figures, date, "_hierarchical_dendrogram_cutreeDynamic_cv2.pdf"),
    width = 8, height = 6,
    family = "Arial", bg = "transparent")
labels_colors(PAG_dend_cv2) <- cluster_colours_20[PAG_clust_cv2_cutreeDynamic][order.dendrogram(PAG_dend_cv2)]
plot(PAG_dend_cv2, main = "Dendrogram from hierarchical clustering (CV2)", sub = "Dynamic Tree Cut", ylab = "Height", las = 1)
legend("topright", col = cluster_colours_20, pch = 19, cex = 0.75,  bty = "n",
       legend = levels(factor(PAG_clust_cv2_cutreeDynamic)))
dev.off()
```

We can compare this to the `cutree()` function, using either a set number of `k` or cutting the tree at a specific height after looking at the dendrogram:
```{r}
# From var scenario using k
PAG_clust_var_cutree_k <- cutree(PAG_tree_var, # Use either "k" or "h"
                                 k = 8) # number of clusters the tree should be cut into
                                 #h = 290) # height where the tree should be cut
table(PAG_clust_var_cutree_k)
labels_colors(PAG_dend_var) <- cluster_colours_10[PAG_clust_var_cutree_k][order.dendrogram(PAG_dend_var)]
plot(PAG_dend_var, main = "Dendrogram from hierarchical clustering (Var)", sub = "Tree Cut using k = 8", ylab = "Height", las = 1)
abline(h = 290, col = "red")
legend("topright", col = cluster_colours_10, pch = 19, cex = 0.75,  bty = "n",
       legend = levels(factor(PAG_clust_var_cutree_k)))

# From var scenario using h
PAG_clust_var_cutree_h <- cutree(PAG_tree_var, # Use either "k" or "h"
                                 #k = 8) # number of clusters the tree should be cut into
                                 h = 290) # height where the tree should be cut
table(PAG_clust_var_cutree_h)
labels_colors(PAG_dend_var) <- cluster_colours_10[PAG_clust_var_cutree_h][order.dendrogram(PAG_dend_var)]
plot(PAG_dend_var, main = "Dendrogram from hierarchical clustering (Var)", sub = "Tree Cut using h=290", ylab = "Height", las = 1)
abline(h = 290, col = "red")
legend("topright", col = cluster_colours_10, pch = 19, cex = 0.75,  bty = "n",
       legend = levels(factor(PAG_clust_var_cutree_h)))

# From cv2 scenario using k
PAG_clust_cv2_cutree_k <- cutree(PAG_tree_cv2, # Use either "k" or "h"
                                 k = 10) # number of clusters the tree should be cut into
                                 #h = 230) # height where the tree should be cut
table(PAG_clust_cv2_cutree_k)
labels_colors(PAG_dend_cv2) <- cluster_colours_10[PAG_clust_cv2_cutree_k][order.dendrogram(PAG_dend_cv2)]
plot(PAG_dend_cv2, main = "Dendrogram from hierarchical clustering (CV2)", sub = "Tree Cut using k = 10", ylab = "Height", las = 1)
abline(h = 225, col = "red")
legend("topright", col = cluster_colours_10, pch = 19, cex = 0.75,  bty = "n",
       legend = levels(factor(PAG_clust_cv2_cutree_k)))

# From cv2 scenario using h
PAG_clust_cv2_cutree_h <- cutree(PAG_tree_cv2, # Use either "k" or "h"
                                 #k = 10) # number of clusters the tree should be cut into
                                 h = 225) # height where the tree should be cut
table(PAG_clust_cv2_cutree_h)
labels_colors(PAG_dend_cv2) <- cluster_colours_10[PAG_clust_cv2_cutree_h][order.dendrogram(PAG_dend_cv2)]
plot(PAG_dend_cv2, main = "Dendrogram from hierarchical clustering (CV2)", sub = "Tree Cut using h = 225", ylab = "Height", las = 1)
abline(h = 225, col = "red")
legend("topright", col = cluster_colours_10, pch = 19, cex = 0.75,  bty = "n",
       legend = levels(factor(PAG_clust_cv2_cutree_h)))

## Save plots
pdf(file = str_c(path_for_figures, date, "_hierarchical_dendrogram_cutree_k_var.pdf"),
    width = 8, height = 6,
    family = "Arial", bg = "transparent")
labels_colors(PAG_dend_var) <- cluster_colours_10[PAG_clust_var_cutree_k][order.dendrogram(PAG_dend_var)]
plot(PAG_dend_var, main = "Dendrogram from hierarchical clustering (Var)", sub = "Tree Cut using k = 8", ylab = "Height", las = 1)
abline(h = 290, col = "red")
legend("topright", col = cluster_colours_10, pch = 19, cex = 0.75,  bty = "n",
       legend = levels(factor(PAG_clust_var_cutree_k)))
dev.off()

pdf(file = str_c(path_for_figures, date, "_hierarchical_dendrogram_cutree_h_var.pdf"),
    width = 8, height = 6,
    family = "Arial", bg = "transparent")
labels_colors(PAG_dend_var) <- cluster_colours_10[PAG_clust_var_cutree_h][order.dendrogram(PAG_dend_var)]
plot(PAG_dend_var, main = "Dendrogram from hierarchical clustering (Var)", sub = "Tree Cut using h = 290", ylab = "Height", las = 1)
abline(h = 290, col = "red")
legend("topright", col = cluster_colours_10, pch = 19, cex = 0.75,  bty = "n",
       legend = levels(factor(PAG_clust_var_cutree_h)))
dev.off()

pdf(file = str_c(path_for_figures, date, "_hierarchical_dendrogram_cutree_k_cv2.pdf"),
    width = 8, height = 6,
    family = "Arial", bg = "transparent")
labels_colors(PAG_dend_cv2) <- cluster_colours_10[PAG_clust_cv2_cutree_k][order.dendrogram(PAG_dend_cv2)]
plot(PAG_dend_cv2, main = "Dendrogram from hierarchical clustering (CV2)", sub = "Tree Cut using k = 10", ylab = "Height", las = 1)
abline(h = 225, col = "red")
legend("topright", col = cluster_colours_10, pch = 19, cex = 0.75,  bty = "n",
       legend = levels(factor(PAG_clust_cv2_cutree_k)))
dev.off()

pdf(file = str_c(path_for_figures, date, "_hierarchical_dendrogram_cutree_h_cv2.pdf"),
    width = 8, height = 6,
    family = "Arial", bg = "transparent")
labels_colors(PAG_dend_cv2) <- cluster_colours_10[PAG_clust_cv2_cutree_h][order.dendrogram(PAG_dend_cv2)]
plot(PAG_dend_cv2, main = "Dendrogram from hierarchical clustering (CV2)", sub = "Tree Cut using h = 225", ylab = "Height", las = 1)
abline(h = 225, col = "red")
legend("topright", col = cluster_colours_10, pch = 19, cex = 0.75,  bty = "n",
       legend = levels(factor(PAG_clust_cv2_cutree_h)))
dev.off()
```

### 6.3.3 | Visualizing and storing the results
We first store the cluster assignments to the `SingleCellExperiment` object:
```{r}
# From Dynamic Tree Cut
PAG_sceset_qc_norm_filt_corr$cutreedynamic_clusters_var <- factor(PAG_clust_var_cutreeDynamic)
PAG_sceset_qc_norm_filt_corr$cutreedynamic_clusters_cv2 <- factor(PAG_clust_cv2_cutreeDynamic)

# From Cut Tree with K
PAG_sceset_qc_norm_filt_corr$cutree_clusters_var_k <- factor(PAG_clust_var_cutree_k)
PAG_sceset_qc_norm_filt_corr$cutree_clusters_cv2_k <- factor(PAG_clust_cv2_cutree_k)

# From Cut Tree with H
PAG_sceset_qc_norm_filt_corr$cutree_clusters_var_h <- factor(PAG_clust_var_cutree_h)
PAG_sceset_qc_norm_filt_corr$cutree_clusters_cv2_h <- factor(PAG_clust_cv2_cutree_h)
```

We can now visualize the cluster assignments for all cells on any of the `reducedDim` slots we previously computed (e.g. tSNE or UMAP). Adjacent cells are generally assigned to the same cluster, and the clustering results generally correspond well to the grouping of cells on a t-SNE or UMAP plot.
```{r}
# Set theme parameters
theme_args_hierarchical <- theme(plot.title = element_text(size = 11, face = "bold"),
                                 axis.title = element_text(size = 11, face = "plain"),
                                 axis.text = element_text(size = 10, face = "plain"), 
                                 legend.text = element_text(size = 9, face = "plain"), 
                                 strip.text = element_text(size = 10, face = "plain"))

# UMAP using PCA from HVG_var_logcounts
UMAP_var_PAGsubdivisions <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
                                           dimred = "UMAP_var_corrected_15_neighbors_0.01_min_dist",
                                           colour_by = "PAG.area", shape_by = "cell.type", 
                                           point_alpha = 0.6, point_size = 2, theme_size = 11
                                           ) + labs(title = "PAG subdivisions", x = "UMAP 1", y = "UMAP 2"
                                                    ) + theme_args_hierarchical

UMAP_var_cutreedynamic <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
                                         dimred = "UMAP_var_corrected_15_neighbors_0.01_min_dist",
                                         colour_by = "cutreedynamic_clusters_var", shape_by = "cell.type", text_by = "cutreedynamic_clusters_var",
                                         point_alpha = 0.6, point_size = 2, theme_size = 11
                                         ) + labs(title = "Dynamic Tree Cut", x = "UMAP 1", y = "UMAP 2") + theme_args_hierarchical

UMAP_var_cutree_k <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
                                    dimred = "UMAP_var_corrected_15_neighbors_0.01_min_dist",
                                    colour_by = "cutree_clusters_var_k", shape_by = "cell.type", text_by = "cutree_clusters_var_k",
                                    point_alpha = 0.6, point_size = 2, theme_size = 11
                                    ) + labs(title = "Tree Cut (k = 8)", x = "UMAP 1", y = "UMAP 2") + theme_args_hierarchical

UMAP_var_cutree_h <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
                                    dimred = "UMAP_var_corrected_15_neighbors_0.01_min_dist",
                                    colour_by = "cutree_clusters_var_h", shape_by = "cell.type", text_by = "cutree_clusters_var_h",
                                    point_alpha = 0.6, point_size = 2, theme_size = 11
                                    ) + labs(title = "Tree Cut (h = 290)", x = "UMAP 1", y = "UMAP 2") + theme_args_hierarchical


# UMAP using PCA from HVG_cv2_logcounts
UMAP_cv2_PAGsubdivisions <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
                                           dimred = "UMAP_cv2_corrected_15_neighbors_0.01_min_dist",
                                           colour_by = "PAG.area", shape_by = "cell.type", 
                                           point_alpha = 0.6, point_size = 2, theme_size = 11
                                           ) + labs(title = "PAG subdivisions", x = "UMAP 1", y = "UMAP 2"
                                                    ) + theme_args_hierarchical

UMAP_cv2_cutreedynamic <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
                                         dimred = "UMAP_cv2_corrected_15_neighbors_0.01_min_dist",
                                         colour_by = "cutreedynamic_clusters_cv2", shape_by = "cell.type", text_by = "cutreedynamic_clusters_cv2", 
                                         point_alpha = 0.6, point_size = 2, theme_size = 11
                                         )  + labs(title = "Dynamic Tree Cut", x = "UMAP 1", y = "UMAP 2") + theme_args_hierarchical

UMAP_cv2_cutree_k <- plotReducedDim(PAG_sceset_qc_norm_filt_corr,
                                    dimred = "UMAP_cv2_corrected_15_neighbors_0.01_min_dist",
                                    colour_by = "cutree_clusters_cv2_k", shape_by = "cell.type", text_by = "cutree_clusters_cv2_k", 
                                    point_alpha = 0.6, point_size = 2, theme_size = 11
                                    )  + labs(title = "Tree Cut (k = 10)", x = "UMAP 1", y = "UMAP 2") + theme_args_hierarchical

UMAP_cv2_cutree_h <- plotReducedDim(PAG_sceset_qc_norm_filt_corr,
                                    dimred = "UMAP_cv2_corrected_15_neighbors_0.01_min_dist",
                                    colour_by = "cutree_clusters_cv2_h", shape_by = "cell.type", text_by = "cutree_clusters_cv2_h", 
                                    point_alpha = 0.6, point_size = 2, theme_size = 11
                                    )  + labs(title = "Tree Cut (h = 235)", x = "UMAP 1", y = "UMAP 2") + theme_args_hierarchical

# Prepare composed plots
library(patchwork)
UMAP_hierarchical_var_composed <- (UMAP_var_PAGsubdivisions + UMAP_var_cutreedynamic + UMAP_var_cutree_k + UMAP_var_cutree_h + plot_spacer() + plot_spacer()) +
  plot_annotation(title = "Hierarchical clustering on UMAP (Var)", tag_levels = "A", 
                  theme = theme(plot.title = element_text(size = 12, face = "bold"), plot.tag = element_text(size = 11))) + 
  plot_layout(ncol = 2, guides = "collect")

UMAP_hierarchical_cv2_composed <- (UMAP_cv2_PAGsubdivisions + UMAP_cv2_cutreedynamic + UMAP_cv2_cutree_k + UMAP_cv2_cutree_h + plot_spacer() + plot_spacer()) +
  plot_annotation(title = "Hierarchical clustering on UMAP (CV2)", tag_levels = "A", 
                  theme = theme(plot.title = element_text(size = 12, face = "bold"), plot.tag = element_text(size = 11))) + 
  plot_layout(ncol = 2, guides = "collect")

# Plot Var dendrograms
par(mfrow = c(2,1))
labels_colors(PAG_dend_var) <- cluster_colours_10[PAG_clust_var_cutreeDynamic][order.dendrogram(PAG_dend_var)]
plot(PAG_dend_var, main = "Dendrogram from hierarchical clustering (Var)", sub = "Dynamic Tree Cut", ylab = "Height", las = 1)
legend("topright", col = cluster_colours_10, pch = 19, cex = 0.75,  bty = "n",
       legend = levels(factor(PAG_clust_var_cutreeDynamic)))
labels_colors(PAG_dend_var) <- cluster_colours_10[PAG_clust_var_cutree_k][order.dendrogram(PAG_dend_var)]
plot(PAG_dend_var, main = "Dendrogram from hierarchical clustering (Var)", sub = "Tree Cut using k = 8", ylab = "Height", las = 1)
abline(h = 290, col = "red")
legend("topright", col = cluster_colours_10, pch = 19, cex = 0.75,  bty = "n",
       legend = levels(factor(PAG_clust_var_cutree_k)))

# Plot CV2 dendrograms
par(mfrow = c(2,1))
labels_colors(PAG_dend_cv2) <- cluster_colours_20[PAG_clust_cv2_cutreeDynamic][order.dendrogram(PAG_dend_cv2)]
plot(PAG_dend_cv2, main = "Dendrogram from hierarchical clustering (CV2)", sub = "Dynamic Tree Cut", ylab = "Height", las = 1)
legend("topright", col = cluster_colours_20, pch = 19, cex = 0.75,  bty = "n",
       legend = levels(factor(PAG_clust_cv2_cutreeDynamic)))
labels_colors(PAG_dend_cv2) <- cluster_colours_10[PAG_clust_cv2_cutree_k][order.dendrogram(PAG_dend_cv2)]
plot(PAG_dend_cv2, main = "Dendrogram from hierarchical clustering (CV2)", sub = "Tree Cut using k = 10", ylab = "Height", las = 1)
abline(h = 225, col = "red")
legend("topright", col = cluster_colours_10, pch = 19, cex = 0.75,  bty = "n",
       legend = levels(factor(PAG_clust_cv2_cutree_k)))

# Plot Composed UMAPs
UMAP_hierarchical_var_composed
UMAP_hierarchical_cv2_composed

# Save them
ggsave(filename = str_c(date, "_hierarchical_UMAP_var_clusters_composed.pdf"),
       plot = UMAP_hierarchical_var_composed,
       device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
       path = path_for_figures,
       width = 8, height = 9, units = "in", dpi = 300,
       family = "Arial", bg = "transparent"
       )

ggsave(filename = str_c(date, "_hierarchical_UMAP_cv2_clusters_composed.pdf"),
       plot = UMAP_hierarchical_cv2_composed,
       device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
       path = path_for_figures,
       width = 8, height = 9, units = "in", dpi = 300,
       family = "Arial", bg = "transparent"
       )

pdf(file = str_c(path_for_figures, date, "_hierarchical_dendrogram_composed_var.pdf"),
    width = 5, height = 8,
    family = "Arial", bg = "transparent")
par(mfrow = c(2,1))
labels_colors(PAG_dend_var) <- cluster_colours_10[PAG_clust_var_cutreeDynamic][order.dendrogram(PAG_dend_var)]
plot(PAG_dend_var, main = "Dendrogram from hierarchical clustering (Var)", sub = "Dynamic Tree Cut", ylab = "Height", las = 1)
legend("topright", col = cluster_colours_10, pch = 19, cex = 0.75,  bty = "n",
       legend = levels(factor(PAG_clust_var_cutreeDynamic)))
labels_colors(PAG_dend_var) <- cluster_colours_10[PAG_clust_var_cutree_k][order.dendrogram(PAG_dend_var)]
plot(PAG_dend_var, main = "Dendrogram from hierarchical clustering (Var)", sub = "Tree Cut using k = 8", ylab = "Height", las = 1)
abline(h = 290, col = "red")
legend("topright", col = cluster_colours_10, pch = 19, cex = 0.75,  bty = "n",
       legend = levels(factor(PAG_clust_var_cutree_k)))

pdf(file = str_c(path_for_figures, date, "_hierarchical_dendrogram_composed_cv2.pdf"),
    width = 5, height = 8,
    family = "Arial", bg = "transparent")
par(mfrow = c(2,1))
labels_colors(PAG_dend_cv2) <- cluster_colours_20[PAG_clust_cv2_cutreeDynamic][order.dendrogram(PAG_dend_cv2)]
plot(PAG_dend_cv2, main = "Dendrogram from hierarchical clustering (CV2)", sub = "Dynamic Tree Cut", ylab = "Height", las = 1)
legend("topright", col = cluster_colours_20, pch = 19, cex = 0.75,  bty = "n",
       legend = levels(factor(PAG_clust_cv2_cutreeDynamic)))
labels_colors(PAG_dend_cv2) <- cluster_colours_10[PAG_clust_cv2_cutree_k][order.dendrogram(PAG_dend_cv2)]
plot(PAG_dend_cv2, main = "Dendrogram from hierarchical clustering (CV2)", sub = "Tree Cut using k = 10", ylab = "Height", las = 1)
abline(h = 225, col = "red")
legend("topright", col = cluster_colours_10, pch = 19, cex = 0.75,  bty = "n",
       legend = levels(factor(PAG_clust_cv2_cutree_k)))
dev.off()
```

We can examine the distribution of cells in each cluster with respect to known factors using `table`. For instance, we can compare the cluster identities to batch to check the clustering is not driven by batch effects. We can also compare to any other interesting metadata to see what can be driving the clusters such as `cell.type` or `PAG.area`.
```{r}
# HVG_var
table(Cluster = PAG_sceset_qc_norm_filt_corr$cutree_clusters_var_k, Batch = PAG_sceset_qc_norm_filt_corr$batch.processing)
table(Cluster = PAG_sceset_qc_norm_filt_corr$cutree_clusters_var_k, Mouse = PAG_sceset_qc_norm_filt_corr$mouse.id)
table(Cluster = PAG_sceset_qc_norm_filt_corr$cutree_clusters_var_k, Cell_Type = PAG_sceset_qc_norm_filt_corr$cell.type)
table(Cluster = PAG_sceset_qc_norm_filt_corr$cutree_clusters_var_k, celltype_PAGarea = PAG_sceset_qc_norm_filt_corr$celltype_PAGarea)

# HVG_cv2
table(Cluster = PAG_sceset_qc_norm_filt_corr$cutree_clusters_cv2_k, Batch = PAG_sceset_qc_norm_filt_corr$batch.processing)
table(Cluster = PAG_sceset_qc_norm_filt_corr$cutree_clusters_cv2_k, Mouse = PAG_sceset_qc_norm_filt_corr$mouse.id)
table(Cluster = PAG_sceset_qc_norm_filt_corr$cutree_clusters_cv2_k, Cell_Type = PAG_sceset_qc_norm_filt_corr$cell.type)
table(Cluster = PAG_sceset_qc_norm_filt_corr$cutree_clusters_cv2_k, celltype_PAGarea = PAG_sceset_qc_norm_filt_corr$celltype_PAGarea)
```

We can also use a heatmap to visualize the expression profiles of the top 100 genes with the largest biological components. If there is structure, we should see "blocks" in expression that correspond nicely to known sample features. We possibly could have subclustered further, in which case we would subset and repeat the above process.
```{r}
library(pheatmap)
plotHeatmap(PAG_sceset_qc_norm_filt_corr, 
            features = metadata(PAG_sceset_qc_norm_filt_corr)$hvg_var_out_no_spikes_block_filt[1:200],
            cluster_cols = PAG_tree_var, colour_columns_by = c("cutree_clusters_var_k", "PAG.area", "cell.type"),
            cluster_rows = FALSE, center = TRUE, symmetric = TRUE,
            main = "Heatmap (Var) - Tree Cut")

plotHeatmap(PAG_sceset_qc_norm_filt_corr, 
            features = metadata(PAG_sceset_qc_norm_filt_corr)$hvg_cv2_out_no_spikes_filt[1:200],
            cluster_cols = PAG_tree_cv2, colour_columns_by = c("cutree_clusters_cv2_k", "PAG.area", "cell.type"),
            cluster_rows = FALSE, center = TRUE, symmetric = TRUE,
            main = "Heatmap (CV2) - Tree Cut")
```

Looking at the heatmap from the HVG_cv2 scenario we can see that one of the clusters is very highly enriched with genes corresponding to immune cells. These cells might actually be a group of cells contaminated with platelets or macrophages and are also picked up by the other clustering approaches and clearly visible in both t-SNE and UMAP plots. Marker genes for macrophages include Ctss, C1qa, CD14, CD16, CD64, CD68, CD71 and CCR5.

We can also notice that in the HVG_var scenario, the dendrogram first splits away a subset of VGluT2 cells, and only the second split is between VGAT and the remaining VGluT2 cells. This does not happen with the HVG_cv2 scenario, where the first split is actually VGAT and VGluT2. This is yet another reason (together with the results from t-SNE and UMAP, and the other clustering approaches) to select HVGs using the mean-cv2 trend instead of the mean-var trend.

### 6.3.4 | Assessing cluster separation
We can check the separation of the clusters by using the silhouette width. For each cell, we compute the average distance to cells in each other cluster. We then compute the minimum of these average distances across all clusters, as well as the average distance to cells in the same cluster. The silhouette width for each cell is defined as the difference between these two values divided by their maximum. Cells with large positive silhouette widths are closer to other cells in the same cluster than to cells in different clusters. Conversely, cells with negative widths are closer to other clusters than to other cells in the cluster to which it was assigned.

Each cluster would ideally contain large positive silhouette widths, indicating that it is well-separated from other clusters. Smaller widths can arise from the presence of internal subclusters, which inflates the within-cluster distance; or overclustering, where cells at the boundary of a partition are closer to the neighboring cluster than their own cluster.
```{r}
library(cluster)

# DynamicTreeCut
sil_var_cutreeDynamic <- silhouette(PAG_clust_var_cutreeDynamic, dist = PAG_dist_var)
sil_cols_var_cutreeDynamic <- cluster_colours_10[ifelse(sil_var_cutreeDynamic[,3] > 0, sil_var_cutreeDynamic[,1], sil_var_cutreeDynamic[,2])]
sil_cols_var_cutreeDynamic <- sil_cols_var_cutreeDynamic[order(-sil_var_cutreeDynamic[,1], sil_var_cutreeDynamic[,3])]
plot(sil_var_cutreeDynamic, main = paste("Silhouette from Hierarchical (Dynamic Tree Cut - Var):", length(unique(PAG_clust_var_cutreeDynamic)), "clusters"),
     border = sil_cols_var_cutreeDynamic, col = sil_cols_var_cutreeDynamic, do.col.sort = FALSE)

sil_cv2_cutreeDynamic <- silhouette(PAG_clust_cv2_cutreeDynamic, dist = PAG_dist_cv2)
sil_cols_cv2_cutreeDynamic <- cluster_colours_20[ifelse(sil_cv2_cutreeDynamic[,3] > 0, sil_cv2_cutreeDynamic[,1], sil_cv2_cutreeDynamic[,2])]
sil_cols_cv2_cutreeDynamic <- sil_cols_cv2_cutreeDynamic[order(-sil_cv2_cutreeDynamic[,1], sil_cv2_cutreeDynamic[,3])]
plot(sil_cv2_cutreeDynamic, main = paste("Silhouette from Hierarchical (Dynamic Tree Cut - CV2):", length(unique(PAG_clust_cv2_cutreeDynamic)), "clusters"),
     border = sil_cols_cv2_cutreeDynamic, col = sil_cols_cv2_cutreeDynamic, do.col.sort = FALSE)

# Cutree
sil_var_cutree <- silhouette(PAG_clust_var_cutree_k, dist = PAG_dist_var)
sil_cols_var_cutree <- cluster_colours_10[ifelse(sil_var_cutree[,3] > 0, sil_var_cutree[,1], sil_var_cutree[,2])]
sil_cols_var_cutree <- sil_cols_var_cutree[order(-sil_var_cutree[,1], sil_var_cutree[,3])]
plot(sil_var_cutree, main = paste("Silhouette from Hierarchical (Cutree - Var):", length(unique(PAG_clust_var_cutree_k)), "clusters"),
     border = sil_cols_var_cutree, col = sil_cols_var_cutree, do.col.sort = FALSE)

sil_cv2_cutree <- silhouette(PAG_clust_cv2_cutree_k, dist = PAG_dist_cv2)
sil_cols_cv2_cutree <- cluster_colours_10[ifelse(sil_cv2_cutree[,3] > 0, sil_cv2_cutree[,1], sil_cv2_cutree[,2])]
sil_cols_cv2_cutree <- sil_cols_cv2_cutree[order(-sil_cv2_cutree[,1], sil_cv2_cutree[,3])]
plot(sil_cv2_cutree, main = paste("Silhouette from Hierarchical (Cutree - CV2):", length(unique(PAG_clust_cv2_cutree_k)), "clusters"),
     border = sil_cols_cv2_cutree, col = sil_cols_cv2_cutree, do.col.sort = FALSE)

# Save plots:
pdf(file = str_c(path_for_figures, date, "_hierarchical_silhouettes_cutreeDynamic.pdf"),
    width = 8, height = 11,
    family = "Arial", bg = "transparent")
par(mfrow = c(2,1))
plot(sil_var_cutreeDynamic, main = paste("Silhouette from Hierarchical (Dynamic Tree Cut - Var):", length(unique(PAG_clust_var_cutreeDynamic)), "clusters"),
     border = sil_cols_var_cutreeDynamic, col = sil_cols_var_cutreeDynamic, do.col.sort = FALSE)
plot(sil_cv2_cutreeDynamic, main = paste("Silhouette from Hierarchical (Dynamic Tree Cut - CV2):", length(unique(PAG_clust_cv2_cutreeDynamic)), "clusters"),
     border = sil_cols_cv2_cutreeDynamic, col = sil_cols_cv2_cutreeDynamic, do.col.sort = FALSE)
dev.off()

pdf(file = str_c(path_for_figures, date, "_hierarchical_silhouettes_cutree.pdf"),
    width = 8, height = 11,
    family = "Arial", bg = "transparent")
par(mfrow = c(2,1))
plot(sil_var_cutree, main = paste("Silhouette from Hierarchical (Cutree - Var):", length(unique(PAG_clust_var_cutree_k)), "clusters"),
     border = sil_cols_var_cutree, col = sil_cols_var_cutree, do.col.sort = FALSE)
plot(sil_cv2_cutree, main = paste("Silhouette from Hierarchical (Cutree - CV2):", length(unique(PAG_clust_cv2_cutree_k)), "clusters"),
     border = sil_cols_cv2_cutree, col = sil_cols_cv2_cutree, do.col.sort = FALSE)
dev.off()
```

For a more detailed examination, we identify the closest neighboring cluster for cells with negative widths. This provides a perspective on the relationships between clusters that is closer to the raw data than the dendrogram.
```{r}
neg_widths_var_cutreeDynamic <- sil_var_cutreeDynamic[,3] < 0
table(Cluster = sil_var_cutreeDynamic[neg_widths_var_cutreeDynamic, 1], Neighbor = sil_var_cutreeDynamic[neg_widths_var_cutreeDynamic, 2])

neg_widths_cv2_cutreeDynamic <- sil_cv2_cutreeDynamic[,3] < 0
table(Cluster = sil_cv2_cutreeDynamic[neg_widths_cv2_cutreeDynamic, 1], Neighbor = sil_cv2_cutreeDynamic[neg_widths_cv2_cutreeDynamic, 2])

neg_widths_var_cutree <- sil_var_cutree[,3] < 0
table(Cluster = sil_var_cutree[neg_widths_var_cutree, 1], Neighbor = sil_var_cutree[neg_widths_var_cutree, 2])

neg_widths_cv2_cutree <- sil_cv2_cutree[,3] < 0
table(Cluster = sil_cv2_cutree[neg_widths_cv2_cutree, 1], Neighbor = sil_cv2_cutree[neg_widths_cv2_cutree, 2])
```

The average silhouette width can be used to determine the parameter values that maximize the separation between clusters. For example, we could vary the cut height or splitting depth in `cutreeDynamic` to maximize the average silhouette width across all cells. This usually provides a satisfactory initial clustering for further examination. However, the granularity of clustering is much like the magnification on a microscope. Different views of the data can be obtained with different granularities, some of which may be suboptimal on measures of separation. Users should not fixate on the clustering with the greatest separation if it does not provide the desired granularity for a particular biological question. Small silhouette positive widths indicate that the separation between clusters is weak. This may be symptomatic of over-clustering where clusters that are clearly defined are further split into subsets that are less well separated. 

The average silhouette width across all cells could also be used to choose clustering parameters. If the aim is to maximize the average silhouette width in order to obtain well-separated clusters, we can iterate through different values for `k` and decide on a “reasonable” clustering:
```{r}
library(cluster)
cluster_colors <- scater:::.get_palette("tableau10medium") # hidden scater colours

for (k in 2:15) { 
    example_clusters <- cutree(PAG_tree_var, k = k)
    if (k<=10){cluster_colors <- scater:::.get_palette("tableau10medium")} else{cluster_colors <- scater:::.get_palette("tableau20")}
    sil <- silhouette(example_clusters, dist = PAG_dist_var)
    sil_cols_var <- cluster_colors[ifelse(sil[,3] > 0, sil[,1], sil[,2])]
    sil_cols_var <- sil_cols_var[order(-sil[,1], sil[,3])]
    plot(sil, main = paste(length(unique(example_clusters)), "Clusters (Var)"), border = sil_cols_var, col = sil_cols_var, do.col.sort = FALSE)
}

for (k in 2:15) { 
    example_clusters <- cutree(PAG_tree_cv2, k = k)
    if (k<=10){cluster_colors <- scater:::.get_palette("tableau10medium")} else{cluster_colors <- scater:::.get_palette("tableau20")}
    sil <- silhouette(example_clusters, dist = PAG_dist_cv2)
    sil_cols_cv2 <- cluster_colors[ifelse(sil[,3] > 0, sil[,1], sil[,2])]
    sil_cols_cv2 <- sil_cols_cv2[order(-sil[,1], sil[,3])]
    plot(sil, main = paste(length(unique(example_clusters)), "Clusters (CV2)"), border = sil_cols_cv2, col = sil_cols_cv2, do.col.sort = FALSE)
}
```

We can see that the values of `k` we selected are already quite good and, again, that following the CV2 scenario provides better results for the clustering.

## Step 6.4 | Consensus clustering with SC3
Single-Cell Consensus Clustering (SC3) is a tool for unsupervised clustering of scRNA-seq data. SC3 achieves high accuracy and robustness by consistently integrating different clustering solutions through a consensus approach. An interactive graphical implementation makes SC3 accessible to a wide audience of users. In addition, SC3 also aids biological interpretation by identifying marker genes, differentially expressed genes and outlier cells. A manuscript describing  SC3 in details is published in Nature Methods (Kiselev et. al., Nature Methods 2017).

The advantage of the SC3 is that it can directly ingest a `SingleCellExperiment` object, and it has a function that can estimate a number of clusters for us. SC3 is a purely clustering tool and it does not provide functions for the sequencing quality control (QC) or normalisation. On the contrary, it is expected that these pre-processing steps are performed by a user in advance. SC3 requires both `counts` and `logcounts` slots to exist in the input `SingleCellExperiment` object. The `counts` slot is used for gene filtering, which is based on gene dropout rates. The `logcounts` slot, which is supposed to contain both normalised and log-transformed expression matrix, is used in the main clustering algorithm. Additionally, if spike-ins are defined via `isSpike function`, SC3 will automatically remove them before doing clustering.

### 6.4.1 | Prepare SingleCellExperiment object for SC3
SC3 requires a `feature_symbol` column of the `rowData` slot of the input `SingleCellExperiment` object to contain preferable feature names (genes/transcript) which will be used in the future visualisations. 
```{r}
rowData(PAG_sceset_qc_norm_filt_corr)$feature_symbol <- rownames(PAG_sceset_qc_norm_filt_corr)
```

We can next run `sc3_prepare`. This method our `SingleCellExperiment` object for `SC3` clustering, defining all parameters needed for clustering and storing them in the `sc3` slot. The parameters have their own defaults but can be manually changed (see `?sc3_prepare` for more details). 
```{r}
PAG_sceset_qc_norm_filt_corr <- sc3_prepare(PAG_sceset_qc_norm_filt_corr,
                                            gene_filter = TRUE, # Choose "FALSE" to set your own filter by changing the sc3_gene_filter slot
                                            pct_dropout_min	= 10, # if gene_filter = TRUE, genes with % dropouts < pct_dropout_min are filtered out before clustering
                                            pct_dropout_max	= 90, # if gene_filter = TRUE, genes with % dropouts > pct_dropout_mAX are filtered out before clustering
                                            n_cores = NULL, # If not set, 'SC3' will use all but one cores of your machine.
                                            rand_seed = 1991) # SC3 is stochastic, we need to make sure we have set a seed before running it.

str(metadata(PAG_sceset_qc_norm_filt_corr)$sc3)
```

As we can see above, `SC3` applies a gene filter to remove genes very lowly expressed in all samples and also the ones that are expressed everywhere, so that these genes do not contribute to the clustering (see `$sc3_gene_filter`). However, we have already filtered genes in previous steps and selected highly variable genes, which we could use for it. If we so desire, We can manually define a list of genes that we want to use for clustering by setting the `sc3_gene_filter` column of the `rowData` slot:
```{r}
# Check which lists of genes you have available to use from loaded metadata or calculated highly variable genes:
names(metadata(PAG_sceset_qc_norm_filt_corr))

# Use Highly Variable Genes from Variance:
#rowData(PAG_sceset_qc_norm_filt_corr)$sc3_gene_filter <- rownames(PAG_sceset_qc_norm_filt_corr) %in% metadata(PAG_sceset_qc_norm_filt_corr)$hvg_var_out_no_spikes_block_filt

# Use Highly Variable Genes from CV2:
#rowData(PAG_sceset_qc_norm_filt_corr)$sc3_gene_filter <- rownames(PAG_sceset_qc_norm_filt_corr) %in% metadata(PAG_sceset_qc_norm_filt_corr)$hvg_cv2_out_no_spikes_filt

# Use Ion Channel Genes:
#rowData(PAG_sceset_qc_norm_filt_corr)$sc3_gene_filter <- rownames(PAG_sceset_qc_norm_filt_corr) %in% metadata(PAG_sceset_qc_norm_filt_corr)$genes.ionchannels

# Use Neuropeptides and Neuromodulators Genes:
#rowData(PAG_sceset_qc_norm_filt_corr)$sc3_gene_filter <- rownames(PAG_sceset_qc_norm_filt_corr) %in% metadata(PAG_sceset_qc_norm_filt_corr)$genes.NeuromodulatorsPeptides

# Use Neuropeptides and Neuromodulators Genes:
#rowData(PAG_sceset_qc_norm_filt_corr)$sc3_gene_filter <- rownames(PAG_sceset_qc_norm_filt_corr) %in% metadata(PAG_sceset_qc_norm_filt_corr)$genes.Transcriptionfactors
```

### 6.4.2 | Estimate k
Once the `SingleCellExperiment` object is prepared for clustering, `SC3` has a method to estimate the optimal number of cluster `k` for a scRNA-seq expression matrix, which uses Tracy-Widom theory on random matrices to estimate the optimal number of clusters `k`.
```{r}
PAG_sceset_qc_norm_filt_corr <- sc3_estimate_k(PAG_sceset_qc_norm_filt_corr)
metadata(PAG_sceset_qc_norm_filt_corr)$sc3$k_estimation 
# k=9 for default SC3 filtering, k=8 for hvg_var_out_no_spikes_block_filt, k=10 for hvg_cv2_out_no_spikes_filt, k=3 for genes.ionchannels, k=4 for genes.NeuromodulatorsPeptides, k=3 for genes.Transcriptionfactors
str(metadata(PAG_sceset_qc_norm_filt_corr)$sc3)
```

### 6.4.3 | Calculate distances and transformations
We are now ready to perform the clustering itself. The method `sc3_calc_dists` calculates distances between the cells and creates and populates the `distances` slot, which contains a list of distance matrices corresponding to Euclidean, Pearson and Spearman distances.
```{r}
PAG_sceset_qc_norm_filt_corr <- sc3_calc_dists(PAG_sceset_qc_norm_filt_corr)
names(metadata(PAG_sceset_qc_norm_filt_corr)$sc3$distances) # names of the distances calculated
```

Next, the method `sc3_calc_transfs` calculates the transformations of the distance matrices contained in the distances item of the `sc3` slot, and creates and populates the `transformations` slot, which contains a list of transformations of the distance matrices corresponding to PCA and graph Laplacian transformations. It also removes the previously calculated `distances` item from the `sc3` slot:
```{r}
PAG_sceset_qc_norm_filt_corr <- sc3_calc_transfs(PAG_sceset_qc_norm_filt_corr)
names(metadata(PAG_sceset_qc_norm_filt_corr)$sc3$transformations) # names of the transformations calculated
metadata(PAG_sceset_qc_norm_filt_corr)$sc3$distances # distances should have been removed
```

### 6.4.4 | K-means
We use the `sce_kmeans` method to perform k-means on the transformed distance matrices contained in the `transformations` item of the `sc3` slot. The method `sc3_kmeans` also creates and populates the `kmeans` item, which contains a list of kmeans clusterings. Given that we need to define the ks at the beginning, we can choose to set a range of ks around the estimated value obtained from `sc3_estimate` to try and compare different solutions. Everything will be stored in the `SingleCellExperiment` object, so we can choose the appropriate solution later on after inspecting the results:
```{r}
start_time <- Sys.time() # Takes around 5 min
PAG_sceset_qc_norm_filt_corr <- sc3_kmeans(PAG_sceset_qc_norm_filt_corr, ks = 2:15)
head(names(metadata(PAG_sceset_qc_norm_filt_corr)$sc3$kmeans)) # calculates k-means for each type of distance transformation and each choice of k
tail(names(metadata(PAG_sceset_qc_norm_filt_corr)$sc3$kmeans))
end_time <- Sys.time()
end_time - start_time
```

### 6.4.5 | Calculate consensus
In this step `SC3` provides a clustering solution. When calculating consensus for each value of `k`, `SC3` averages the clustering results of `kmeans` using a consensus approach. The method `sc3_calc_consens` calculates consensus matrices based on the clustering solutions contained in the `kmeans` item of the `sc3` slot, and it then creates and populates the `consensus` item, which for each value of `k` it contains a consensus matrix, an `hclust` object corresponding to hierarchical clustering of the consensus matrix, and the Silhouette indices of the clusters. It also removes the previously calculated `kmeans` item from the `sc3` slot.
```{r}
PAG_sceset_qc_norm_filt_corr <- sc3_calc_consens(PAG_sceset_qc_norm_filt_corr)
names(metadata(PAG_sceset_qc_norm_filt_corr)$sc3$consensus) # check all the consensus slots (should be one per k)
names(metadata(PAG_sceset_qc_norm_filt_corr)$sc3$consensus$`5`) # check what is in one of the consensus slots for a particular k
metadata(PAG_sceset_qc_norm_filt_corr)$sc3$kmeans # this should be empty now
```

### 6.4.6 | Calculate biology
`SC3` can also calculate DE genes, marker genes, and cell outliers based on the calculated consensus clusterings. Similary to the clustering solutions, the method `sc3_calc_biology` writes the results for the cell outliers (cell-related information) to the `colData` slot of the `SingleCellExperiment` object. In contrast, DE and marker genes results (gene-related information) are written to the `rowData` slot.
```{r}
PAG_sceset_qc_norm_filt_corr <- sc3_calc_biology(PAG_sceset_qc_norm_filt_corr, ks = 2:15)
```

### 6.4.7 | Running SC3 with the wrapper function [OPTIONAL ALTERNATIVE]
Alternatively, we can run SC3 with the wrapper function and ask it to calculate biological properties of the clusters as well. This should do the same steps as we just did in the same order. However, make sure you have at least prepared the `SingleCellExperiment` object and have estimated ks beforehand.
```{r}
# rowData(PAG_sceset_qc_norm_filt_corr)$feature_symbol <- rownames(PAG_sceset_qc_norm_filt_corr)
# 
# start_time <- Sys.time() # Takes around 35 min
# PAG_sceset_qc_norm_filt_corr <- sc3(PAG_sceset_qc_norm_filt_corr,
#                                     ks = 2:15,
#                                     gene_filter = TRUE, # Set to FALSE if you want to determine a list of genes to be used instead
#                                     biology = TRUE, 
#                                     n_cores = NULL, # If not set, 'SC3' will use all but one cores of your machine
#                                     rand_seed = 1991)
# end_time <- Sys.time()
# end_time - start_time
```

### 6.4.8 | Explore the results
To run an interactive `Shiny` session (which will open a website to explore our results), we can do the following: 
```{r}
#sc3_interactive(PAG_sceset_qc_norm_filt_corr)
```

SC3 writes all its results obtained for cells to the `colData` slot of the `SingleCellExperiment` object by adding additional columns to it, and all its results obtained for features (genes/transcripts) to the `rowData` slot. This slot also contains all other cell features calculated by the scater package either automatically during the `SingleCellExperiment` object creation or during the `calculateQCMetrics` call. We can identify and access the SC3 results using the "sc3_" prefix. We can use these results from the clustering to highlight the clusters in any PCA/tSNE/UMAP plot, as we have done before:
```{r}
# Set theme parameters
theme_args_sc3 <- theme(plot.title = element_text(size = 11, face = "bold"),
                        axis.title = element_text(size = 11, face = "plain"),
                        axis.text = element_text(size = 10, face = "plain"), 
                        legend.text = element_text(size = 9, face = "plain"), 
                        strip.text = element_text(size = 10, face = "plain"))

# UMAP using PCA from HVG_cv2_logcounts
UMAP_cv2_10neighbors_PAGsubdivisions <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
                                                       dimred = "UMAP_cv2_corrected_10_neighbors_0.01_min_dist",
                                                       colour_by = "PAG.area", shape_by = "cell.type", 
                                                       point_alpha = 0.6, point_size = 2, theme_size = 11
                                                       ) + labs(title = "PAG subdivisions", x = "UMAP 1", y = "UMAP 2"
                                                                ) + theme_args_sc3

UMAP_cv2_15neighbors_PAGsubdivisions <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
                                                       dimred = "UMAP_cv2_corrected_15_neighbors_0.01_min_dist",
                                                       colour_by = "PAG.area", shape_by = "cell.type", 
                                                       point_alpha = 0.6, point_size = 2, theme_size = 11
                                                       ) + labs(title = "PAG subdivisions", x = "UMAP 1", y = "UMAP 2"
                                                                ) + theme_args_sc3

# Generate and color a UMAP plot for each solution of K
library(patchwork)
range_of_k <- 2:15

for(chosen_k in range_of_k) {
  UMAP_cv2_10neighbours_sc3 <- plotReducedDim(PAG_sceset_qc_norm_filt_corr,
                                              dimred = "UMAP_cv2_corrected_10_neighbors_0.01_min_dist",
                                              colour_by = paste0("sc3_", chosen_k, "_clusters"), shape_by = "cell.type", text_by = paste0("sc3_", chosen_k, "_clusters"),
                                              point_alpha = 0.6, point_size = 2, theme_size = 11
                                              )  + labs(title = sprintf("SC3 (k = %s)", chosen_k), x = "UMAP 1", y = "UMAP 2") + theme_args_sc3
  
  UMAP_cv2_15_neighbors_sc3 <- plotReducedDim(PAG_sceset_qc_norm_filt_corr,
                                              dimred = "UMAP_cv2_corrected_15_neighbors_0.01_min_dist",
                                              colour_by = paste0("sc3_", chosen_k, "_clusters"), shape_by = "cell.type", text_by = paste0("sc3_", chosen_k, "_clusters"),
                                              point_alpha = 0.6, point_size = 2, theme_size = 11
                                              )  + labs(title = sprintf("SC3 (k = %s)", chosen_k), x = "UMAP 1", y = "UMAP 2") + theme_args_sc3
  
  # Prepare composed plots
  UMAP_sc3_range_k <- ((UMAP_cv2_10neighbors_PAGsubdivisions + UMAP_cv2_10neighbours_sc3) /
                       (UMAP_cv2_15neighbors_PAGsubdivisions + UMAP_cv2_15_neighbors_sc3)) +
    plot_annotation(title = sprintf("SC3 clustering (k = %s) on UMAP (CV2)", chosen_k), tag_levels = "A", 
                    theme = theme(plot.title = element_text(size = 12, face = "bold"), plot.tag = element_text(size = 11))) + 
    plot_layout(guides = "collect")

  # Plot them
  plot(UMAP_sc3_range_k)
}
```

After we have explored the results for the different range of `k`, we can then replicate the relevant plots to summarise our results. 

* `k=2` correctly separates excitatory and inhibitory cells. The next cluster to appear is the vlPAG inhibitory cells (`k=3`), followed by the lPAG & vlPAG excitatory cells (`k=4`).

* `k=5:8` start further subdividing excitatory cells and the Cd68+ cluster, although these clusters are not very well defined.

* `k=9`, which was the suggested `k` by SC3, does offer the best clustering of excitatory cells and captures the Cd68+ cluster, and finds 4 inhibitory clusters, although they are a bit too close to each other in the UMAP. 

* `k=10` misses the Cd68+ cluster, but splits excitatory and inhibitory cells into better defined clusters.

* Most of `k=11:15` again miss the Cd68+ cluster or seem to overcluster either excitatory or inhibitory neurons.

From the UMAP embeddings above we can conclude that `k=2:4` or `k=9` seem to be best, or at least can provide some information about clusters we can identify in the UMAP.
```{r}
# Set theme parameters
theme_args_sc3 <- theme(plot.title = element_text(size = 11, face = "bold"),
                        axis.title = element_text(size = 11, face = "plain"),
                        axis.text = element_text(size = 10, face = "plain"), 
                        legend.text = element_text(size = 9, face = "plain"), 
                        strip.text = element_text(size = 10, face = "plain"))

# UMAP using PCA from HVG_cv2_logcounts
UMAP_cv2_PAGsubdivisions <- plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
                                           dimred = "UMAP_cv2_corrected_15_neighbors_0.01_min_dist",
                                           colour_by = "PAG.area", shape_by = "cell.type", 
                                           point_alpha = 0.6, point_size = 2, theme_size = 11
                                           ) + labs(title = "PAG subdivisions", x = "UMAP 1", y = "UMAP 2"
                                                    ) + theme_args_sc3

# SC3 Clusters (k = 2:4 and k = 9)
UMAP_cv2_sc3_k2 <- plotReducedDim(PAG_sceset_qc_norm_filt_corr,
                                  dimred = "UMAP_cv2_corrected_15_neighbors_0.01_min_dist",
                                  colour_by = "sc3_2_clusters", shape_by = "cell.type", text_by = "sc3_2_clusters",
                                  point_alpha = 0.6, point_size = 2, theme_size = 11
                                  )  + labs(title = "SC3 (k = 2)", x = "UMAP 1", y = "UMAP 2") + theme_args_sc3

UMAP_cv2_sc3_k3 <- plotReducedDim(PAG_sceset_qc_norm_filt_corr,
                                  dimred = "UMAP_cv2_corrected_15_neighbors_0.01_min_dist",
                                  colour_by = "sc3_3_clusters", shape_by = "cell.type", text_by = "sc3_3_clusters",
                                  point_alpha = 0.6, point_size = 2, theme_size = 11
                                  )  + labs(title = "SC3 (k = 3)", x = "UMAP 1", y = "UMAP 2") + theme_args_sc3

UMAP_cv2_sc3_k4 <- plotReducedDim(PAG_sceset_qc_norm_filt_corr,
                                  dimred = "UMAP_cv2_corrected_15_neighbors_0.01_min_dist",
                                  colour_by = "sc3_4_clusters", shape_by = "cell.type", text_by = "sc3_4_clusters",
                                  point_alpha = 0.6, point_size = 2, theme_size = 11
                                  )  + labs(title = "SC3 (k = 4)", x = "UMAP 1", y = "UMAP 2") + theme_args_sc3

UMAP_cv2_sc3_k9 <- plotReducedDim(PAG_sceset_qc_norm_filt_corr,
                                  dimred = "UMAP_cv2_corrected_15_neighbors_0.01_min_dist",
                                  colour_by = "sc3_9_clusters", shape_by = "cell.type", text_by = "sc3_9_clusters",
                                  point_alpha = 0.6, point_size = 2, theme_size = 11
                                  )  + labs(title = "SC3 (k = 9)", x = "UMAP 1", y = "UMAP 2") + theme_args_sc3
  
# Prepare composed plot
library(patchwork)
UMAP_sc3_clusters <- ((UMAP_cv2_PAGsubdivisions + UMAP_cv2_sc3_k2) /
                      (UMAP_cv2_sc3_k3 + UMAP_cv2_sc3_k4) /
                      (UMAP_cv2_sc3_k9 + UMAP_cv2_PAGsubdivisions)) +
  plot_annotation(title = "SC3 clustering on UMAP (CV2)", tag_levels = "A", 
                  theme = theme(plot.title = element_text(size = 12, face = "bold"), plot.tag = element_text(size = 11))) + 
  plot_layout(guides = "collect")

# Plot
UMAP_sc3_clusters

# Save
ggsave(filename = str_c(date, "_sc3_UMAP_clusters_composed.pdf"),
       plot = UMAP_sc3_clusters,
       device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
       path = path_for_figures,
       width = 8, height = 10, units = "in", dpi = 300,
       family = "Arial", bg = "transparent"
       )
```

In addition to the UMAP embeddings, we can use the following SC3 output plots to explore our results in a bit more depth:

* The _Consensus Matrix_ is a NxN matrix, where N is the number of cells. It represents similarity between the cells based on the averaging of clustering results from all combinations of clustering parameters. A similarity of 0 (blue) means that the two cells are always assigned to different clusters. In contrast, a similarity 1 (red) means that the two cells are always assigned to the same cluster. The consensus matrix is clustered by hierarchical clustering and has a diagonal-block structure. Intuitively, the perfect clustering is achieved when all diagonal blocks are completely red and all off-diagonal elements are completely blue.

* The _Silhouette_ is a quantitative measure of the diagonality of the consensus matrix. An average silhouette width (shown at the bottom left of the silhouette plot) varies from 0 to 1, where 1 represents a perfectly block-diagonal consensus matrix and 0 represents a situation where there is no block-diagonal structure. The best clustering is achieved when the average silhouette width is close to 1.

* The _Stability Index_ shows how stable each cluster is accross the selected range of `k`. The stability index varies between 0 and 1, where 1 means that the same cluster appears in every solution for different `k`.

* A _heatmap of expression_ represents the original input expression matrix (cells in columns and genes in rows) after cell and gene filters. Genes are clustered by k-means with `k = 100` (dendrogram on the left) and the heatmap represents the expression levels of the gene cluster centers after log2-scaling. It is also possible to annotate cells (columns of the expression matrix) with any column of the `colData` slot of the `SingleCellExperiment` object.

* A heatmap of _DE genes_: Differential expression is calculated using the non-parametric Kruskal-Wallis test. A significant p-value indicates that gene expression in at least one cluster stochastically dominates one other cluster. SC3 provides a list of all differentially expressed genes with adjusted p-values < 0.01 and plots gene expression profiles of the 50 genes with the lowest p-values. Note that the calculation of differential expression after clustering can introduce a bias in the distribution of p-values, and thus we advise to use the p-values for ranking the genes only.

* A list of _Marker genes_: To find marker genes, for each gene a binary classifier is constructed based on the mean cluster expression values. The classifier prediction is then calculated using the gene expression ranks. The area under the receiver operating characteristic (ROC) curve is used to quantify the accuracy of the prediction. A p-value is assigned to each gene by using the Wilcoxon signed rank test. The genes with the area under the ROC curve (AUROC) > 0.85 and with the p-value < 0.01 are defined as marker genes and the top 10 marker genes of each cluster are visualized in this panel. The AUROC and the p-value thresholds can be changed using the slider and radio buttons below.
```{r}
# Save the plots adjusting their size so they don't get cropped and fit in an A4 page
best_k <- list(2, 3, 4, 9) # Set the chosen K for the following plots
for(chosen_k in best_k) {
  # Consensus Matrix
  consensus <- sc3_plot_consensus(PAG_sceset_qc_norm_filt_corr, k = chosen_k,
                                  show_pdata = c("cell.type", "PAG.area", paste0("sc3_", chosen_k, "_clusters")))
  consensus
  ggsave(filename = str_c(date, "_sc3_consensus_k", chosen_k, ".pdf"), 
         plot = consensus,
         device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
         path = path_for_figures,
         width = 8, height = 6, units = "in", dpi = 300,
         family = "Arial", bg = "transparent"
         )
  
  # # Silhouette plot # does not seem to work
  # silhouette <- sc3_plot_silhouette(PAG_sceset_qc_norm_filt_corr, k = chosen_k)
  # silhouette
  # ggsave(filename = str_c(date, "_sc3_silhouette_k", chosen_k, ".pdf"), 
  #        plot = silhouette,
  #        device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
  #        path = path_for_figures,
  #        width = 7, height = 5, units = "in", dpi = 300,
  #        family = "Arial", bg = "transparent"
  #        )
  
  # Stability index
  cluster_stability <- sc3_plot_cluster_stability(PAG_sceset_qc_norm_filt_corr, k = chosen_k)
  cluster_stability
  ggsave(filename = str_c(date, "_sc3_stability_k", chosen_k, ".pdf"), 
         plot = cluster_stability,
         device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
         path = path_for_figures,
         width = 7, height = 5, units = "in", dpi = 300,
         family = "Arial", bg = "transparent"
         )

  # Expression panel
  expression_panel <- sc3_plot_expression(PAG_sceset_qc_norm_filt_corr, k = chosen_k,
                                          show_pdata = c("cell.type", "PAG.area", paste0("sc3_", chosen_k, "_clusters")))
  expression_panel
  ggsave(filename = str_c(date, "_sc3_expression_k", chosen_k, ".pdf"), 
         plot = expression_panel,
         device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
         path = path_for_figures,
         width = 8, height = 10, units = "in", dpi = 300,
         family = "Arial", bg = "transparent"
         )

  # DE Genes
  DE_genes <- sc3_plot_de_genes(PAG_sceset_qc_norm_filt_corr, k = chosen_k,
                                p.val = 0.001,
                                show_pdata = c("cell.type", "PAG.area", paste0("sc3_", chosen_k, "_clusters")))
  DE_genes
  ggsave(filename = str_c(date, "_sc3_DEgenes_k", chosen_k, ".pdf"), 
         plot = DE_genes,
         device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
         path = path_for_figures,
         width = 8, height = 10, units = "in", dpi = 300,
         family = "Arial", bg = "transparent"
         )

  # Marker Genes
  markers <- sc3_plot_markers(PAG_sceset_qc_norm_filt_corr, k = chosen_k,
                              auroc = 0.8, p.val = 0.01,
                              show_pdata = c("cell.type", "PAG.area", paste0("sc3_", chosen_k, "_clusters")))
  markers
  ggsave(filename = str_c(date, "_sc3_markers_k", chosen_k, ".pdf"), 
         plot = markers,
         device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
         path = path_for_figures,
         width = 8, height = 10, units = "in", dpi = 300,
         family = "Arial", bg = "transparent"
         )
}
```

### 6.4.9 | Export the results
SC3 allows us to export the results into an Excel file:
```{r}
#sc3_export_results_xls(PAG_sceset_qc_norm_filt_corr, filename = "PAG_sceset_qc_norm_filt_corr_clust")
```

## Step 6.5 | Compare clustering results and choose approach
As a final step, we can plot the chosen clustering solutions side by side so we can compare them and make a final decision regarding which cluster IDs to use for differential expression analysis. The following code assumes all the previous sections in this notebook have been run:
```{r}
## UMAP colored by PAG subdivision
UMAP_cv2_15_001_PAGsubdivisions


## Graph-based Clustering
# UMAP_cv2_15_001_RankWalktrap_k7
# UMAP_cv2_15_001_RankWalktrap_k12
# UMAP_cv2_15_001_JaccardLouvain_k5
# UMAP_cv2_15_001_JaccardLouvain_k8
# UMAP_cv2_15_001_JaccardLouvain_k9
# UMAP_cv2_15_001_JaccardLouvain_k13
UMAP_cv2_15_001_SNN_clusters_RankWalktrap # composed plots
UMAP_cv2_15_001_SNN_clusters_JaccardLouvain # composed plots


## K-means Clustering
# UMAP embeddings
# UMAP_var_PAGsubdivisions
# UMAP_var_kmeans
# UMAP_cv2_PAGsubdivisions
# UMAP_cv2_kmeans
UMAP_kmeans_clusters # composed plots

# Dendrograms
par(mfrow = c(2,1))
plot(cent_tree_cluster_kmeans_var, main = "K-means Dendrogram (Var)", xlab = "k = 8", ylab = "Height", sub = "", las = 1)
plot(cent_tree_cluster_kmeans_cv2, main = "K-means Dendrogram (CV2)", xlab = "k = 10", ylab = "Height", sub = "", las = 1)


## Hierarchical Clustering
# Dendrograms (cell type)
par(mfrow = c(2,1))
labels_colors(PAG_dend_var) <- colours_celltype_PAGarea[PAG_sceset_qc_norm_filt_corr$celltype_PAGarea][order.dendrogram(PAG_dend_var)]
plot(PAG_dend_var, main = "Dendrogram from hierarchical clustering (Var)", ylab = "Height", las = 1)
legend("topright", col = colours_celltype_PAGarea, pch = 19, cex = 0.75,  bty = "n",
       legend = levels(PAG_sceset_qc_norm_filt_corr$celltype_PAGarea))
labels_colors(PAG_dend_cv2) <- colours_celltype_PAGarea[PAG_sceset_qc_norm_filt_corr$celltype_PAGarea][order.dendrogram(PAG_dend_cv2)]
plot(PAG_dend_cv2, main = "Dendrogram from hierarchical clustering (CV2)", ylab = "Height", las = 1)
legend("topright", col = colours_celltype_PAGarea, pch = 19, cex = 0.75,  bty = "n",
       legend = levels(PAG_sceset_qc_norm_filt_corr$celltype_PAGarea))

# Dendrograms (Var)
par(mfrow = c(2,1))
labels_colors(PAG_dend_var) <- cluster_colours_10[PAG_clust_var_cutreeDynamic][order.dendrogram(PAG_dend_var)]
plot(PAG_dend_var, main = "Dendrogram from hierarchical clustering (Var)", sub = "Dynamic Tree Cut", ylab = "Height", las = 1)
legend("topright", col = cluster_colours_10, pch = 19, cex = 0.75,  bty = "n",
       legend = levels(factor(PAG_clust_var_cutreeDynamic)))
labels_colors(PAG_dend_var) <- cluster_colours_10[PAG_clust_var_cutree_k][order.dendrogram(PAG_dend_var)]
plot(PAG_dend_var, main = "Dendrogram from hierarchical clustering (Var)", sub = "Tree Cut using k = 8", ylab = "Height", las = 1)
abline(h = 290, col = "red")
legend("topright", col = cluster_colours_10, pch = 19, cex = 0.75,  bty = "n",
       legend = levels(factor(PAG_clust_var_cutree_k)))

# Dendrograms (CV2)
par(mfrow = c(2,1))
labels_colors(PAG_dend_cv2) <- cluster_colours_20[PAG_clust_cv2_cutreeDynamic][order.dendrogram(PAG_dend_cv2)]
plot(PAG_dend_cv2, main = "Dendrogram from hierarchical clustering (CV2)", sub = "Dynamic Tree Cut", ylab = "Height", las = 1)
legend("topright", col = cluster_colours_20, pch = 19, cex = 0.75,  bty = "n",
       legend = levels(factor(PAG_clust_cv2_cutreeDynamic)))
labels_colors(PAG_dend_cv2) <- cluster_colours_10[PAG_clust_cv2_cutree_k][order.dendrogram(PAG_dend_cv2)]
plot(PAG_dend_cv2, main = "Dendrogram from hierarchical clustering (CV2)", sub = "Tree Cut using k = 10", ylab = "Height", las = 1)
abline(h = 225, col = "red")
legend("topright", col = cluster_colours_10, pch = 19, cex = 0.75,  bty = "n",
       legend = levels(factor(PAG_clust_cv2_cutree_k)))

UMAP_hierarchical_var_composed <- (UMAP_var_PAGsubdivisions + UMAP_var_cutreedynamic + UMAP_var_cutree_k + UMAP_var_cutree_h + plot_spacer() + plot_spacer()) +
  plot_annotation(title = "Hierarchical clustering on UMAP (Var)", tag_levels = "A", 
                  theme = theme(plot.title = element_text(size = 12, face = "bold"), plot.tag = element_text(size = 11))) + 
  plot_layout(ncol = 2, guides = "collect")

UMAP_hierarchical_cv2_composed <- (UMAP_cv2_PAGsubdivisions + UMAP_cv2_cutreedynamic + UMAP_cv2_cutree_k + UMAP_cv2_cutree_h + plot_spacer() + plot_spacer()) +
  plot_annotation(title = "Hierarchical clustering on UMAP (CV2)", tag_levels = "A", 
                  theme = theme(plot.title = element_text(size = 12, face = "bold"), plot.tag = element_text(size = 11))) + 
  plot_layout(ncol = 2, guides = "collect")

# UMAPs and t-SNE embeddings
# UMAP_var_PAGsubdivisions
# UMAP_var_cutreedynamic
# UMAP_var_cutree_k
# UMAP_var_cutree_h
# UMAP_cv2_PAGsubdivisions
# UMAP_cv2_cutreedynamic
# UMAP_cv2_cutree_k
# UMAP_cv2_cutree_h
UMAP_hierarchical_var_composed # composed plots
UMAP_hierarchical_cv2_composed # composed plots


## SC3 Consensus Clustering
# UMAP_cv2_PAGsubdivisions
# UMAP_cv2_sc3_k2
# UMAP_cv2_sc3_k3
# UMAP_cv2_sc3_k4
# UMAP_cv2_sc3_k9
UMAP_sc3_clusters # composed plots
```

After looking at all the outcomes side by side, we can see that following the path from mean-cv2 modelling provides better resolution than following the path from mean-variance modelling. This is very clear if we look at the results from (1) Graph-based clustering, where we get 2 subclusters of inhibitory neurons in UMAP-var, whereas we get 4 subclusters of inhibitory neurons in the UMAP-cv2, from (2) k-means clustering, where the first split of the dendrogram for HVG-Var is a subcluster of excitatory neurons (and only the second split separates the remaining excitatory and inhibitory neurons), whereas the first split for HVG-CV2 is the Cd68+ cluster, and then correctly separates excitatory and inhibitory neurons, and from (3) hierarchical clustering, where the first split of the dendrogram for HVG-Var is a subcluster of excitatory neurons (and only the second split separates the remaining excitatory and inhibitory neurons), whereas the first split of the dendrogram for HVG-CV2 successfully separates excitatory and inhibitory neurons. Thus, we can conclude that the best analysis path stems from using the results from mean-cv2 modelling.

Another informative exercise to compare our clustering results would be to use the Macrophage-enriched cluster to see how well do the different clustering approaches pick it up. If we look at the UMAP plot and magnify the region where that cluster falls, we can count 12 cells, so in theory, any good clustering solution for our dataset should correctly identify the right amount of cells.
```{r}
# Localise and zoom in on the macrophage-enriched cluster
UMAP_cv2_15_001_PAGsubdivisions
plotReducedDim(PAG_sceset_qc_norm_filt_corr, 
               dimred = "UMAP_cv2_corrected_15_neighbors_0.01_min_dist",
               colour_by = "Cd68", text_by = "SNN_clusters_cv2_jaccard_k8", shape_by = "cell.type"
               ) + labs(title = "UMAP (CV2) - Jaccard-Louvain (k = 8)", x = "UMAP 1", y = "UMAP 2")
UMAP_cv2_15_001_PAGsubdivisions + xlim(-6.17,-5.95) + ylim(9.05,9.3) # Zoom in, there should be 12 cells
```

For each clustering approach, we can plot only the Cd68+ cluster and see how many cells appear:
```{r}
# For each clustering approach, plot only the cells assigned to the macrophage-enriched cluster:
# Graph-based
plotReducedDim(PAG_sceset_qc_norm_filt_corr[, PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_rank_k7==8], 
               dimred = "UMAP_cv2_corrected_15_neighbors_0.01_min_dist",
               colour_by = "Cd68", shape_by = "cell.type"
               ) + labs(title = "UMAP (CV2) - Rank-Walktrap (k = 7)", x = "UMAP 1", y = "UMAP 2")
plotReducedDim(PAG_sceset_qc_norm_filt_corr[, PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_rank_k12==7], 
               dimred = "UMAP_cv2_corrected_15_neighbors_0.01_min_dist",
               colour_by = "Cd68", shape_by = "cell.type"
               ) + labs(title = "UMAP (CV2) - Rank-Walktrap (k = 12)", x = "UMAP 1", y = "UMAP 2")
plotReducedDim(PAG_sceset_qc_norm_filt_corr[, PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_jaccard_k5==10], 
               dimred = "UMAP_cv2_corrected_15_neighbors_0.01_min_dist",
               colour_by = "Cd68", shape_by = "cell.type"
               ) + labs(title = "UMAP (CV2) - Jaccard-Louvain (k = 5)", x = "UMAP 1", y = "UMAP 2")
plotReducedDim(PAG_sceset_qc_norm_filt_corr[, PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_jaccard_k8==1], 
               dimred = "UMAP_cv2_corrected_15_neighbors_0.01_min_dist",
               colour_by = "Cd68", shape_by = "cell.type"
               ) + labs(title = "UMAP (CV2) - Jaccard-Louvain (k = 8)", x = "UMAP 1", y = "UMAP 2")
plotReducedDim(PAG_sceset_qc_norm_filt_corr[, PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_jaccard_k9==3], 
               dimred = "UMAP_cv2_corrected_15_neighbors_0.01_min_dist",
               colour_by = "Cd68", shape_by = "cell.type"
               ) + labs(title = "UMAP (CV2) - Jaccard-Louvain (k = 9)", x = "UMAP 1", y = "UMAP 2")
plotReducedDim(PAG_sceset_qc_norm_filt_corr[, PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_jaccard_k13==7], 
               dimred = "UMAP_cv2_corrected_15_neighbors_0.01_min_dist",
               colour_by = "Cd68", shape_by = "cell.type"
               ) + labs(title = "UMAP (CV2) - Jaccard-Louvain (k = 13)", x = "UMAP 1", y = "UMAP 2")

# K-means
plotReducedDim(PAG_sceset_qc_norm_filt_corr[, PAG_sceset_qc_norm_filt_corr$kmeans_clusters_var==8], 
               dimred = "UMAP_var_corrected_15_neighbors_0.01_min_dist",
               colour_by = "Cd68", shape_by = "cell.type"
               ) + labs(title = "UMAP (Var) - K-means (center = 8)", x = "UMAP 1", y = "UMAP 2")
plotReducedDim(PAG_sceset_qc_norm_filt_corr[, PAG_sceset_qc_norm_filt_corr$kmeans_clusters_cv2==9], 
               dimred = "UMAP_cv2_corrected_15_neighbors_0.01_min_dist",
               colour_by = "Cd68", shape_by = "cell.type"
               ) + labs(title = "UMAP (CV2) - K-means (centers = 10)", x = "UMAP 1", y = "UMAP 2")

# Hierarchical
plotReducedDim(PAG_sceset_qc_norm_filt_corr[, PAG_sceset_qc_norm_filt_corr$cutreedynamic_clusters_var==9], 
               dimred = "UMAP_var_corrected_15_neighbors_0.01_min_dist",
               colour_by = "Cd68", shape_by = "cell.type"
               ) + labs(title = "UMAP (Var) - Dynamic Tree Cut", x = "UMAP 1", y = "UMAP 2")
plotReducedDim(PAG_sceset_qc_norm_filt_corr[, PAG_sceset_qc_norm_filt_corr$cutree_clusters_var_k==2], 
               dimred = "UMAP_var_corrected_15_neighbors_0.01_min_dist",
               colour_by = "Cd68", shape_by = "cell.type"
               ) + labs(title = "UMAP (Var) - Tree Cut (k = 8)", x = "UMAP 1", y = "UMAP 2")
plotReducedDim(PAG_sceset_qc_norm_filt_corr[, PAG_sceset_qc_norm_filt_corr$cutree_clusters_cv2_k==5], 
               dimred = "UMAP_cv2_corrected_15_neighbors_0.01_min_dist",
               colour_by = "Cd68", shape_by = "cell.type"
               ) + labs(title = "UMAP (CV2) - Tree Cut (k = 10)", x = "UMAP 1", y = "UMAP 2")

# SC3
plotReducedDim(PAG_sceset_qc_norm_filt_corr[, PAG_sceset_qc_norm_filt_corr$sc3_9_clusters==5], 
               dimred = "UMAP_cv2_corrected_15_neighbors_0.01_min_dist",
               colour_by = "Cd68", shape_by = "cell.type"
               ) + labs(title = "UMAP (CV2) - SC3 (k = 9)", x = "UMAP 1", y = "UMAP 2")
```

We can count the number of cells each clustering approach assigns to the macrophage-enriched cluster ID (check that the cluster ID is indeed the correct one by looking at the UMAP plots above):
```{r}
# Graph-based
paste0("Macrophage cluster has ", sum(PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_rank_k7==8), " cells in SNN_var_rank_k7 method")
paste0("Macrophage cluster has ", sum(PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_rank_k12==7), " cells in SNN_var_rank_k12 method")
paste0("Macrophage cluster has ", sum(PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_jaccard_k5==10), " cells in SNN_cv2_jaccard_k5 method")
paste0("Macrophage cluster has ", sum(PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_jaccard_k8==1), " cells in SNN_cv2_jaccard_k8 method")
paste0("Macrophage cluster has ", sum(PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_jaccard_k9==3), " cells in SNN_cv2_jaccard_k9 method")
paste0("Macrophage cluster has ", sum(PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_jaccard_k13==7), " cells in SNN_cv2_jaccard_k13 method")
# K-means
paste0("Macrophage cluster has ", sum(PAG_sceset_qc_norm_filt_corr$kmeans_clusters_var==8), " cells in kmeans_var_k8 method")
paste0("Macrophage cluster has ", sum(PAG_sceset_qc_norm_filt_corr$kmeans_clusters_cv2==9), " cells in kmeans_cv2_k10 method")
# Hierarchical
paste0("Macrophage cluster has ", sum(PAG_sceset_qc_norm_filt_corr$cutreedynamic_clusters_var==9), " cells in hierarchical cutreedynamic_clusters_var method")
paste0("Macrophage cluster has ", sum(PAG_sceset_qc_norm_filt_corr$cutreedynamic_clusters_cv2==0), " cells in hierarchical cutreedynamic_clusters_cv2 method") # does not find Cd68+ cluster
paste0("Macrophage cluster has ", sum(PAG_sceset_qc_norm_filt_corr$cutree_clusters_var_k==2), " cells in hierarchical cutree_clusters_var_k method")
paste0("Macrophage cluster has ", sum(PAG_sceset_qc_norm_filt_corr$cutree_clusters_cv2_k==5), " cells in hierarchical cutree_clusters_cv2_k method")
# SC3
paste0("Macrophage cluster has ", sum(PAG_sceset_qc_norm_filt_corr$sc3_9_clusters==5), " cells in SC3_k9 method")
```

We can also use the `which()` function to get the indices of the cells assigned to the macrophage-enriched cluster:
```{r}
# Graph-based
which(PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_rank_k7==8)
which(PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_rank_k12==7)
which(PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_jaccard_k5==10)
which(PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_jaccard_k8==1)
which(PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_jaccard_k9==3)
which(PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_jaccard_k13==7)
# K-means
which(PAG_sceset_qc_norm_filt_corr$kmeans_clusters_var==8)
which(PAG_sceset_qc_norm_filt_corr$kmeans_clusters_cv2==9)
# Hierarchical
which(PAG_sceset_qc_norm_filt_corr$cutreedynamic_clusters_var==9)
which(PAG_sceset_qc_norm_filt_corr$cutreedynamic_clusters_cv2==0)
which(PAG_sceset_qc_norm_filt_corr$cutree_clusters_var_k==2)
which(PAG_sceset_qc_norm_filt_corr$cutree_clusters_cv2_k==5)
# SC3
which(PAG_sceset_qc_norm_filt_corr$sc3_9_clusters==5)
```

We can see that our choice of Graph-based clustering approaches successfully assign the right number of cells to this cluster. From the k-means approaches, only the one using HVG-CV2 achieves this, with the HVG-Var approach assigning too many cells to it. Using hierarchical clustering gives different results, with Dynamic Tree Cut failing to identify the cluster either with HVG-Var or HVG-CV2, and with Cut Tree successfully capturing the cluster only in the HVG-CV2 scenario. Finally, SC3 also fails to correctly classify the right number of cells to this cluster. From this we can conclude that K-means clustering doesn't do as good job as Graph-based or Hierarchical clustering for our dataset.

As a last check, we can visually inspect the degree of agreement between the clustering assignments and the UMAP embedding of the cluster IDs.
```{r}
library(patchwork)

# Graph-based clustering
UMAP_SNN_RankWalktrap_k7_final_composed <- (UMAP_cv2_15_001_PAGsubdivisions + UMAP_cv2_15_001_RankWalktrap_k7) +
  plot_annotation(title = "Graph-based clustering on UMAP (CV2)", tag_levels = "A", 
                  theme = theme(plot.title = element_text(size = 12, face = "bold"), plot.tag = element_text(size = 11))) + 
  plot_layout(ncol = 2) + theme(legend.position="none")
UMAP_SNN_RankWalktrap_k7_final_composed

UMAP_SNN_RankWalktrap_k12_final_composed <- (UMAP_cv2_15_001_PAGsubdivisions + UMAP_cv2_15_001_RankWalktrap_k12) +
  plot_annotation(title = "Graph-based clustering on UMAP (CV2)", tag_levels = "A", 
                  theme = theme(plot.title = element_text(size = 12, face = "bold"), plot.tag = element_text(size = 11))) + 
  plot_layout(ncol = 2) + theme(legend.position="none")
UMAP_SNN_RankWalktrap_k12_final_composed

UMAP_SNN_JaccardLouvain_k5_final_composed <- (UMAP_cv2_15_001_PAGsubdivisions + UMAP_cv2_15_001_JaccardLouvain_k5) +
  plot_annotation(title = "Graph-based clustering on UMAP (CV2)", tag_levels = "A", 
                  theme = theme(plot.title = element_text(size = 12, face = "bold"), plot.tag = element_text(size = 11))) + 
  plot_layout(ncol = 2) + theme(legend.position="none")
UMAP_SNN_JaccardLouvain_k5_final_composed

UMAP_SNN_JaccardLouvain_k8_final_composed <- (UMAP_cv2_15_001_PAGsubdivisions + UMAP_cv2_15_001_JaccardLouvain_k8) +
  plot_annotation(title = "Graph-based clustering on UMAP (CV2)", tag_levels = "A", 
                  theme = theme(plot.title = element_text(size = 12, face = "bold"), plot.tag = element_text(size = 11))) + 
  plot_layout(ncol = 2) + theme(legend.position="none")
UMAP_SNN_JaccardLouvain_k8_final_composed

UMAP_SNN_JaccardLouvain_k9_final_composed <- (UMAP_cv2_15_001_PAGsubdivisions + UMAP_cv2_15_001_JaccardLouvain_k9) +
  plot_annotation(title = "Graph-based clustering on UMAP (CV2)", tag_levels = "A", 
                  theme = theme(plot.title = element_text(size = 12, face = "bold"), plot.tag = element_text(size = 11))) + 
  plot_layout(ncol = 2) + theme(legend.position="none")
UMAP_SNN_JaccardLouvain_k9_final_composed

UMAP_SNN_JaccardLouvain_k13_final_composed <- (UMAP_cv2_15_001_PAGsubdivisions + UMAP_cv2_15_001_JaccardLouvain_k13) +
  plot_annotation(title = "Graph-based clustering on UMAP (CV2)", tag_levels = "A", 
                  theme = theme(plot.title = element_text(size = 12, face = "bold"), plot.tag = element_text(size = 11))) + 
  plot_layout(ncol = 2) + theme(legend.position="none")
UMAP_SNN_JaccardLouvain_k13_final_composed


# K-means clustering
UMAP_kmeans_final_composed <- (UMAP_cv2_15_001_PAGsubdivisions + UMAP_cv2_kmeans) +
  plot_annotation(title = "K-means clustering on UMAP (CV2)", tag_levels = "A", 
                  theme = theme(plot.title = element_text(size = 12, face = "bold"), plot.tag = element_text(size = 11))) + 
  plot_layout(ncol = 2) + theme(legend.position="none")
UMAP_kmeans_final_composed


# Hierarchical clustering
UMAP_hierarchical_final_composed <- (UMAP_cv2_15_001_PAGsubdivisions + UMAP_cv2_cutree_k) +
  plot_annotation(title = "Hierarchical clustering on UMAP (CV2)", tag_levels = "A", 
                  theme = theme(plot.title = element_text(size = 12, face = "bold"), plot.tag = element_text(size = 11))) + 
  plot_layout(ncol = 2) + theme(legend.position="none")
UMAP_hierarchical_final_composed
```

In the plots above, we can see that the best representation is the one obtained from Graph-based clustering with the Jaccard-Louvain (`k = 9`) approach, as it is apparent from the cleanest separation of inhibitory subclusters and the main excitatory subclusters. The clusters obtained with both the K-means and the hierarchical clustering approach do not match well with the UMAP representation of the data. Although this could just be due to working with different metrics, the graph-based clustering approach has consistently generated good results at different parameters, whereas the rest have been erratic and inconsistent. Thus, we will focus on the results obtained from Graph-based clustering with the Jaccard-Louvain approach for our Differential Expression analysis. We will still keep different values of `k`, as this will allow us to ask questions and investigate the structure of our dataset at different resolution.

## Step 6.6 | Save the SingleCellExperiment object
```{r}
saveRDS(PAG_sceset_qc_norm_filt_corr, file = "PAG_sceset_qc_norm_filt_corr_clust.rds")
print("Part 6 - Done!")
```

```{r}
sessionInfo()
```
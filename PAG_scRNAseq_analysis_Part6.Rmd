---
title: "Topographic, single-cell gene expression profiling of Periaqueductal Gray neurons"
subtitle: "Part VI: clustering"
author:
  - name: "Oriol Pavon Arocas, Sarah F. Olesen, and Tiago Branco"
    affiliation: "Sainsbury Wellcome Centre for Neural Circuits and Behaviour, University College London, UK"
    email: "oriol.pavon.16@ucl.ac.uk"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_notebook:
    highlight: pygments
    number_sections: FALSE
    theme: lumen
    toc: TRUE
    toc_float: TRUE

#output: rmdformats::readthedown:
  #highlight: pygments
---

***

This is a pipeline to analyse single-cell RNA sequencing data from Periaqueductal Gray neurons (1) isolated from acute midbrain slices of transgenic mice using visually guided aspiration via patch pipettes and (2) processed using SMART-seq2 (Picelli et al., Nature Protocols 2014). 

This pipeline has been generated after attending the [EMBL-EBI RNA-Sequence Analysis Course](https://www.ebi.ac.uk/training/events/2019/rna-sequence-analysis) and [attending](https://training.csx.cam.ac.uk/bioinformatics/event/2823386) and following the online course on [Analysis of single cell RNA-seq data](https://github.com/hemberg-lab/scRNA.seq.course) by the [Hemberg Lab](https://www.sanger.ac.uk/science/groups/hemberg-group). Many other resources have been used, including the [Orchestrating Single-Cell Analysis with Bioconductor book](https://osca.bioconductor.org/) by Robert Amezquita and Stephanie Hicks, the [simpleSingleCell workflow in Bioconductor](https://bioconductor.org/packages/3.9/workflows/html/simpleSingleCell.html) maintained by Aaron Lun, the [rnaseqGene workflow](https://bioconductor.org/packages/3.10/workflows/html/rnaseqGene.html) maintained by Michael Love, the [RNAseq123 workflow](https://bioconductor.org/packages/3.10/workflows/html/RNAseq123.html) maintained by Matthew Ritchie, and the [EGSEA123 workflow](https://bioconductor.org/packages/3.10/workflows/html/EGSEA123.html) maintained by Matthew Ritchie.

Other key resources include [Bioconductor](http://www.bioconductor.org/) (Huber et al., Nature Methods 2015), [scRNA-tools](https://www.scrna-tools.org/), `scater` (McCarthy et al., Bioinformatics 2017), `scran` (Lun et al., F1000Res 2016), `SC3` (Kiselev et al., Nature Methods 2017), `Seurat` (Butler et al., Nature Biotechnology 2018), `clusterExperiment` (Risso et al., PLOS Computational Biology 2018), `limma` (Ritchie et al., Nucleic Acids Research 2015), `DESeq2` (Love et al., Genome Biology 2014), `edgeR` (Robinson et al., Bioinformatics 2010), `MAST` (Finak, McDavid, Yajima et al., Genome Biology 2015), `iSEE` (Rue-Albrecht & Marini et al., F1000Research 2018), `t-SNE` (van der Maaten & Hinton, Journal of Machine Learning Research 2008), `UMAP` (McInnes et al., arXiv 2018), and the [Mathematical Statistics and Machine Learning for Life Sciences](https://towardsdatascience.com/tagged/stats-ml-life-sciences) column by Nikolay Oskolkov.

***

# STEP 6 | Clustering
Once we have normalized the data, identified highly variable genes, and corrected confounding factors we can carry out analyses that are relevant to the biological questions at hand.

scRNA-seq data allow de novo discovery and annotation of cell-types based on transcription profiles. Computationally, we need to identify groups of cells based on the similarities of the transcriptomes without any prior knowledge of the labels, nor the number of clusters we will end up with. This is very challenging due to the high level of noise (both technical and biological) and the large number of dimensions (i.e. genes).

Clustering is an unsupervised learning procedure that is used in scRNA-seq data analysis to empirically define groups of cells with similar expression profiles. This allows us to describe population heterogeneity in terms of discrete labels that are easily understood, rather than attempting to comprehend the high-dimensional manifold on which the cells truly reside. After annotation based on marker genes, the clusters can be treated as proxies for more abstract biological concepts such as cell types or states. Clustering is thus a critical step for extracting biological insights from scRNA-seq data. Some of the most popular approaches are __hierarchical clustering__, __k-means clustering__ and __graph-based clustering__.

At this point, it is worth stressing the distinction between clusters and cell types. The former is an empirical construct while the latter is a biological truth (albeit a vaguely defined one). For this reason, questions like “what is the true number of clusters?” are usually meaningless. We can define as many clusters as we like, with whatever algorithm we like - each clustering will represent its own partitioning of the high-dimensional expression space, and is as “real” as any other clustering. A more relevant question is “how well do the clusters approximate the cell types?”. Unfortunately, this is difficult to answer given the context-dependent interpretation of biological truth. Some analysts will be satisfied with resolution of the major cell types; other analysts may want resolution of subtypes; and others still may require resolution of different states (e.g., metabolic activity, stress) within those subtypes. Moreover, two clusterings can be highly inconsistent yet both valid, simply partitioning the cells based on different aspects of biology.

We continue using the `PAG_sceset_qc_norm_filt_corr` after normalization, filtering, and batch correction. We should thus have a `corrected` slot in `assays`:
```{r}
set.seed(1991)
library(SC3)
library(scater)
library(scran)
library(SingleCellExperiment)
library(pheatmap)
library(mclust) # contains adjustedRandIndex function to compare clustering results

PAG_sceset_qc_norm_filt_corr <- readRDS("PAG_sceset_qc_norm_filt_corr.rds") # Contains filtered cells and genes, and normalized data
assayNames(PAG_sceset_qc_norm_filt_corr)
reducedDimNames(PAG_sceset_qc_norm_filt_corr)
PAG_sceset_qc_norm_filt_corr
```

## Step 6.1 | Consensus clustering with SC3
Single-Cell Consensus Clustering (SC3) is a tool for unsupervised clustering of scRNA-seq data. SC3 achieves high accuracy and robustness by consistently integrating different clustering solutions through a consensus approach. An interactive graphical implementation makes SC3 accessible to a wide audience of users. In addition, SC3 also aids biological interpretation by identifying marker genes, differentially expressed genes and outlier cells. A manuscript describing  SC3 in details is published in Nature Methods.

The advantage of the SC3 is that it can directly ingest a `SingleCellExperiment` object, and it has a function that can estimate a number of clusters for us. SC3 is a purely clustering tool and it does not provide functions for the sequencing quality control (QC) or normalisation. On the contrary, it is expected that these preprocessing steps are performed by a user in advance. SC3 requires both `counts` and `logcounts` slots to exist in the input `SingleCellExperiment` object. The `counts` slot is used for gene filtering, which is based on gene dropout rates. The `logcounts` slot, which is supposed to contain both normalised and log-transformed expression matrix, is used in the main clustering algorithm.  Additionally, if spike-ins are defined via `isSpike function`, SC3 will automatically remove them before doing clustering.

### 6.1.1 | Prepare SingleCellExperiment object for SC3
SC3 requires a `feature_symbol` column of the `rowData` slot of the input `SingleCellExperiment` object to contain preferable feature names (genes/transcript) which will be used in the future visualisations. 
```{r}
rowData(PAG_sceset_qc_norm_filt_corr)$feature_symbol <- rownames(PAG_sceset_qc_norm_filt_corr)
```

We can next run `sc3_prepare`. This method prepares an object of `SCE` class for `SC3` clustering, defining all parameters needed for clustering and storing them in the `sc3` slot. The parameters have their own defaults but can be manually changed (see `?sc3_prepare` for more details). 
```{r}
PAG_sceset_qc_norm_filt_corr <- sc3_prepare(PAG_sceset_qc_norm_filt_corr,
                                            gene_filter = TRUE, # Choose "FALSE" to set your own filter by changing the sc3_gene_filter slot
                                            n_cores = 10,
                                            rand_seed = 1991) 
# SC3 is stochastic, if we run it different times we will get different results, so we need to make sure we have set a seed before running it.

str(metadata(PAG_sceset_qc_norm_filt_corr)$sc3)
```

As we can see above, `SC3` applies a gene filter to remove genes very lowly expressed in all samples and also the ones that are expressed everywhere, so that these genes do not contribute to the clustering (see `$sc3_gene_filter`). However, we have already filtered genes in previous steps and selected highly variable genes, which we could use for it. We can manually define a list of genes that we want to use for clustering by setting the `sc3_gene_filter` column of the `rowData` slot:
```{r}
# Check which lists of genes you have available to use from loaded metadata or calculated highly variable genes:
names(metadata(PAG_sceset_qc_norm_filt_corr))

# Use Highly Variable Genes from Variance:
#rowData(PAG_sceset_qc_norm_filt_corr)$sc3_gene_filter <- rownames(PAG_sceset_qc_norm_filt_corr) %in% metadata(PAG_sceset_qc_norm_filt_corr)$hvg_var_out_no_spikes_block_filt

# Use Highly Variable Genes from CV2:
#rowData(PAG_sceset_qc_norm_filt_corr)$sc3_gene_filter <- rownames(PAG_sceset_qc_norm_filt_corr) %in% metadata(PAG_sceset_qc_norm_filt_corr)$hvg_cv2_out_no_spikes_filt

# Use Ion Channel Genes:
#rowData(PAG_sceset_qc_norm_filt_corr)$sc3_gene_filter <- rownames(PAG_sceset_qc_norm_filt_corr) %in% metadata(PAG_sceset_qc_norm_filt_corr)$genes.ionchannels

# Use Neuropeptides and Neuromodulators Genes:
#rowData(PAG_sceset_qc_norm_filt_corr)$sc3_gene_filter <- rownames(PAG_sceset_qc_norm_filt_corr) %in% metadata(PAG_sceset_qc_norm_filt_corr)$genes.NeuromodulatorsPeptides

# Use Neuropeptides and Neuromodulators Genes:
#rowData(PAG_sceset_qc_norm_filt_corr)$sc3_gene_filter <- rownames(PAG_sceset_qc_norm_filt_corr) %in% metadata(PAG_sceset_qc_norm_filt_corr)$genes.Transcriptionfactors
```

### 6.1.2 | Estimate k
Once the `SCE` object is prepared for clustering, `Sc3` has a method to estimate the optimal number of cluster `k` for a scRNA-seq expression matrix, which uses Tracy-Widom theory on random matrices to estimate the optimal number of clusters k.
```{r}
PAG_sceset_qc_norm_filt_corr <- sc3_estimate_k(PAG_sceset_qc_norm_filt_corr)
metadata(PAG_sceset_qc_norm_filt_corr)$sc3$k_estimation
str(metadata(PAG_sceset_qc_norm_filt_corr)$sc3)
```

### 6.1.3 | Calculate distances and transformations
We are now ready to perform the clustering itself. The method `sc3_calc_dists` calculates distances between the cells and creates and populates the `distances` slot, which contains a list of distance matrices corresponding to Euclidean, Pearson and Spearman distances.
```{r}
PAG_sceset_qc_norm_filt_corr <- sc3_calc_dists(PAG_sceset_qc_norm_filt_corr)
names(metadata(PAG_sceset_qc_norm_filt_corr)$sc3$distances)
```

Next, the method `sc3_calc_transfs` calculates the transformations of the distance matrices contained in the distances item of the `sc3` slot, and creates and populates the `transformations` slot, which contains a list of transformations of the distance matrices corresponding to PCA and graph Laplacian transformations. It also removes the previously calculated `distances` item from the `sc3` slot:
```{r}
PAG_sceset_qc_norm_filt_corr <- sc3_calc_transfs(PAG_sceset_qc_norm_filt_corr)
names(metadata(PAG_sceset_qc_norm_filt_corr)$sc3$transformations)
metadata(PAG_sceset_qc_norm_filt_corr)$sc3$distances
```

### 6.1.4 | K-means
We use the `sce_kmeans` method to perform k-means on the transformed distance matrices contained in the `transformations` item of the `sc3` slot. The method `sc3_kmeans` also creates and populates the `kmeans` item, which contains a list of kmeans clusterings. Given that we need to define the ks at the beginning, it is best to set a range of ks around the estimated value obtained from `sc3_estimate` to try and compare different solutions.
```{r}
start_time <- Sys.time() # Takes around 5 min
PAG_sceset_qc_norm_filt_corr <- sc3_kmeans(PAG_sceset_qc_norm_filt_corr,
                                           ks = 2:12)
names(metadata(PAG_sceset_qc_norm_filt_corr)$sc3$kmeans)
end_time <- Sys.time()
end_time - start_time
```

### 6.1.5 | Calculate consensus
In this step `SC3` provides a clustering solution. When calculating consensus for each value of `k`, `SC3` averages the clustering results of `kmeans` using a consensus approach. The method `sc3_calc_consens` calculates consensus matrices based on the clustering solutions contained in the `kmeans` item of the `sc3` slot, and it then creates and populates the `consensus` item, which for each value of k it contains a consensus matrix, an `hclust` object corresponding to hierarchical clustering of the consensus matrix, and the Silhouette indices of the clusters. It also removes the previously calculated `kmeans` item from the `sc3` slot.
```{r}
PAG_sceset_qc_norm_filt_corr <- sc3_calc_consens(PAG_sceset_qc_norm_filt_corr)
names(metadata(PAG_sceset_qc_norm_filt_corr)$sc3$consensus)
names(metadata(PAG_sceset_qc_norm_filt_corr)$sc3$consensus$`1`)
metadata(PAG_sceset_qc_norm_filt_corr)$sc3$kmeans
```

### 6.1.6 | Calculate biology
`SC3` can also calculate DE genes, marker genes, and cell outliers based on the calculated consensus clusterings. Similary to the clustering solutions, the method `sc3_calc_biology` writes the results for the cell outliers (cell-related information) to the `colData` slot of the `SCE` object. In contrast, DE and marker genes results (gene-related information) are written to the `rowData` slot.
```{r}
PAG_sceset_qc_norm_filt_corr <- sc3_calc_biology(PAG_sceset_qc_norm_filt_corr, 
                                                 ks = 2:12)
```

### 6.1.7 | Running SC3 with the wrapper function [OPTIONAL ALTERNATIVE]
Alternatively, we can run SC3 with the wrapper function and ask it to calculate biological properties of the clusters as well. This should do the same steps as we just did in the same order. However, make sure you have at least prepared the `SCE` object and have estimated ks beforehand.
```{r}
rowData(PAG_sceset_qc_norm_filt_corr)$feature_symbol <- rownames(PAG_sceset_qc_norm_filt_corr)

start_time <- Sys.time() # Takes around 35 min
PAG_sceset_qc_norm_filt_corr <- sc3(PAG_sceset_qc_norm_filt_corr,
                                    ks = 2:12,
                                    gene_filter = TRUE, # Set to FALSE if you want to determine a list of genes to be used instead
                                    biology = TRUE, 
                                    n_cores = 4,
                                    rand_seed = 1991)
end_time <- Sys.time()
end_time - start_time
```

### 6.1.8 | Explore the results
To run the interactive `Shiny` session, we can do the following: 
```{r}
sc3_interactive(PAG_sceset_qc_norm_filt_corr)
```

SC3 writes all its results obtained for cells to the `colData` slot of the `SCE` object by adding additional columns to it, and all its results obtained for features (genes/transcripts) to the `rowData` slot. This slot also contains all other cell features calculated by the scater package either automatically during the `SCE` object creation or during the `calculateQCMetrics` call. One can identify the SC3 results using the "sc3_" prefix. We can use these results as highlights when plotting.
```{r}
# Consensus Matrix
sc3_plot_consensus(PAG_sceset_qc_norm_filt_corr, 
                   k = 4, 
                   show_pdata = c("cell.type", "PAG.arearegistration"))

# DE Genes
sc3_plot_de_genes(PAG_sceset_qc_norm_filt_corr, 
                  k = 4,
                  p.val = 0.001,
                  show_pdata = c("cell.type", "PAG.arearegistration"))

# Marker Genes
sc3_plot_markers(PAG_sceset_qc_norm_filt_corr,
                 k = 4,
                 auroc = 0.7,
                 p.val = 0.01,
                 show_pdata = c("cell.type", "PAG.arearegistration"))
```

We can also use the results from the clustering to highlight the clusters in any PCA/tSNE/UMAP plot:
```{r}
plotPCA(PAG_sceset_qc_norm_filt_corr, colour_by = "sc3_8_clusters")
```

#### Consensus matrix
The consensus matrix is a NxN matrix, where N is the number of cells. It represents similarity between the cells based on the averaging of clustering results from all combinations of clustering parameters. Similarity 0 (blue) means that the two cells are always assigned to different clusters. In contrast, similarity 1 (red) means that the two cells are always assigned to the same cluster. The consensus matrix is clustered by hierarchical clustering and has a diagonal-block structure. Intuitively, the perfect clustering is achieved when all diagonal blocks are completely red and all off-diagonal elements are completely blue. 
```{r}
sc3_plot_consensus(PAG_sceset_qc_norm_filt_corr, 
                   k = 3, 
                   show_pdata = c("cell.type",
                                  "PAG.areacollection",
                                  "sc3_3_clusters"
                                  )
                   )
```

#### Silhouette plot and stability index
A silhouette is a quantitative measure of the diagonality of the consensus matrix. An average silhouette width (shown at the bottom left of the silhouette plot) varies from 0 to 1, where 1 represents a perfectly block-diagonal consensus matrix and 0 represents a situation where there is no block-diagonal structure. The best clustering is achieved when the average silhouette width is close to 1.
```{r}
sc3_plot_silhouette(PAG_sceset_qc_norm_filt_corr, 
                    k = 5
                    )
```

The Stability Index shows how stable each cluster is accross the selected range of ks. The stability index varies between 0 and 1, where 1 means that the same cluster appears in every solution for different k.
```{r}
sc3_plot_cluster_stability(PAG_sceset_qc_norm_filt_corr, 
                           k = 3
                           )
```

#### Heatmap of the expression matrix
The expression panel represents the original input expression matrix (cells in columns and genes in rows) after cell and gene filters. Genes are clustered by k-means with k = 100 (dendrogram on the left) and the heatmap represents the expression levels of the gene cluster centers after log2-scaling. It is also possible to annotate cells (columns of the expression matrix) with any column of the `colData` slot of the `SCE` object.
```{r}
sc3_plot_expression(PAG_sceset_qc_norm_filt_corr, 
                    k = 3, 
                    show_pdata = c("cell.type",
                                   "PAG.areacollection",
                                   "sc3_3_clusters"
                                   )
                    )
```

#### Differentially expressed and Marker genes
Differential expression is calculated using the non-parametric Kruskal-Wallis test. A significant p-value indicates that gene expression in at least one cluster stochastically dominates one other cluster. SC3 provides a list of all differentially expressed genes with adjusted p-values < 0.01 and plots gene expression profiles of the 50 genes with the lowest p-values. Note that the calculation of differential expression after clustering can introduce a bias in the distribution of p-values, and thus we advise to use the p-values for ranking the genes only.
```{r}
sc3_plot_de_genes(PAG_sceset_qc_norm_filt_corr, 
                  k = 3,
                  p.val = 0.001,
                  show_pdata = c("cell.type",
                                 "PAG.areacollection",
                                 "sc3_3_clusters"
                                 )
                  )
```

To find marker genes, for each gene a binary classifier is constructed based on the mean cluster expression values. The classifier prediction is then calculated using the gene expression ranks. The area under the receiver operating characteristic (ROC) curve is used to quantify the accuracy of the prediction. A p-value is assigned to each gene by using the Wilcoxon signed rank test. The genes with the area under the ROC curve (AUROC) > 0.85 and with the p-value < 0.01 are defined as marker genes and the top 10 marker genes of each cluster are visualized in this panel. The AUROC and the p-value thresholds can be changed using the slider and radio buttons below.
```{r}
sc3_plot_markers(PAG_sceset_qc_norm_filt_corr, 
                 k = 3,
                 auroc = 0.65,
                 p.val = 0.01,
                 show_pdata = c("cell.type",
                                "PAG.areacollection",
                                "sc3_3_clusters"
                                )
                 )
```

### 6.1.9 | Export the results
SC3 allows us to export the results into an Excel file:
```{r}
sc3_export_results_xls(PAG_sceset_qc_norm_filt_corr, filename = "PAG_sceset_qc_norm_filt_corr_clust")
```

## Step 6.2 | Graph-based clustering
Graph-based clustering is a flexible and scalable technique for clustering large scRNA-seq datasets. We first build a graph where each node is a cell that is connected to its nearest neighbours in the high-dimensional space. Edges are weighted based on the similarity between the cells involved, with higher weight given to cells that are more closely related. We then apply algorithms to identify “communities” of cells that are more connected to cells in the same community than they are to cells of different communities. Each community represents a cluster that we can use for downstream interpretation.

The major advantage of graph-based clustering lies in its scalability. It only requires a k-nearest neighbor search that can be done in log-linear time on average, in contrast to hierachical clustering methods with runtimes that are quadratic with respect to the number of cells. Graph construction avoids making strong assumptions about the shape of the clusters or the distribution of cells within each cluster, compared to other methods like k-means (that favor spherical clusters) or Gaussian mixture models (that require normality). From a practical perspective, each cell is forcibly connected to a minimum number of neighboring cells, which reduces the risk of generating many uninformative clusters consisting of one or two outlier cells.

The main drawback of graph-based methods is that, after graph construction, no information is retained about relationships beyond the neighbouring cells. This has some practical consequences in datasets that exhibit differences in cell density, as more steps through the graph are required to move the same distance through a region of higher cell density. From the perspective of community detection algorithms, this effect “inflates” the high-density regions such that any internal substructure or noise is more likely to cause formation of subclusters. The resolution of clustering thus becomes dependent on the density of cells, which can occasionally be misleading if it overstates the heterogeneity in the data.

`scran` provides several graph construction methods based on shared nearest neighbors (Xu and Su 2015) through the `buildSNNGraph()` function. This is most commonly generated from the selected PCs, after which methods from the `igraph` package can be used to identify clusters.

### 6.2.1 | Implementation of graph-based clustering
There are several considerations in the practical execution of a graph-based clustering method: (1) How many neighbors are considered when constructing the graph, (2) What scheme is used to weight the edges, and (3) Which community detection algorithm is used to define the clusters. 

For example, we could use a code that uses the 10 nearest neighbors of each cell to construct a shared nearest neighbor graph. Two cells are connected by an edge if any of their nearest neighbors are shared, with the edge weight defined from the highest average rank of the shared neighbors (Xu and Su 2015). The `Walktrap` method from the `igraph` package can then be used to identify communities. An alternative can be performed by changing the edge weighting scheme during graph construction. Setting `type = "number"` will weight edges based on the number of nearest neighbors that are shared between two cells. Similarly, `type = "jaccard"` will weight edges according to the Jaccard index of the two sets of neighbors. We can also disable weighting altogether by using `buildKNNGraph()`, which is occasionally useful for downstream graph operations that do not support weights. Pipelines involving `scran` default to rank-based weights followed by Walktrap clustering. In contrast, `Seurat` uses Jaccard-based weights followed by Louvain clustering. Both of these strategies work well.

One of the most important parameters is `k`, the number of nearest neighbors used to construct the graph. This controls the resolution of the clustering where higher `k` yields a more inter-connected graph and broader clusters. Users can exploit this by experimenting with different values of `k` to obtain a satisfactory resolution. The choice of `k` controls the connectivity of the graph and the resolution of community detection algorithms. Smaller values of `k` will generally yield smaller, finer clusters, while increasing `k` will increase the connectivity of the graph and make it more difficult to resolve different communities. The value of `k` can be roughly interpreted as the anticipated size of the smallest subpopulation.
```{r}
library(scran)
# Using HVG from Var with rank-based weights
graph_var_rank <- buildSNNGraph(PAG_sceset_qc_norm_filt_corr,
                                k = 8, # An integer scalar specifying the number of nearest neighbors to consider during graph construction.
                                #d = 50, # An integer scalar specifying the number of dimensions to use for the search.
                                type = "rank", # A string specifying the type of weighting scheme to use for shared neighbors. Try "rank" or "jaccard"
                                subset.row = metadata(PAG_sceset_qc_norm_filt_corr)$hvg_var_out_no_spikes_block_filt,
                                assay.type = "logcounts",
                                use.dimred = "PCA_HVG_var_corrected")
clusters_var_rank <- igraph::cluster_walktrap(graph_var_rank)$membership # Use `cluster_louvain` if using `type = "jaccard"`, and `cluster_walktrap` if using `type = "rank"`
PAG_sceset_qc_norm_filt_corr$SNN_clusters_var_rank <- factor(clusters_var_rank)
table(PAG_sceset_qc_norm_filt_corr$SNN_clusters_var_rank)

# Using HVG from Var with jaccard-based weights
graph_var_jaccard <- buildSNNGraph(PAG_sceset_qc_norm_filt_corr,
                                   k = 8, # An integer scalar specifying the number of nearest neighbors to consider during graph construction.
                                   #d = 50, # An integer scalar specifying the number of dimensions to use for the search.
                                   type = "jaccard", # A string specifying the type of weighting scheme to use for shared neighbors. Try "rank" or "jaccard"
                                   subset.row = metadata(PAG_sceset_qc_norm_filt_corr)$hvg_var_out_no_spikes_block_filt,
                                   assay.type = "logcounts",
                                   use.dimred = "PCA_HVG_var_corrected")
clusters_var_jaccard <- igraph::cluster_louvain(graph_var_jaccard)$membership # Use `cluster_louvain` if using `type = "jaccard"`, and `cluster_walktrap` if using `type = "rank"`
PAG_sceset_qc_norm_filt_corr$SNN_clusters_var_jaccard <- factor(clusters_var_jaccard)
table(PAG_sceset_qc_norm_filt_corr$SNN_clusters_var_jaccard)
 
# Using HVG from CV2 with rank-based weights
graph_cv2_rank <- buildSNNGraph(PAG_sceset_qc_norm_filt_corr,
                                k = 8, # An integer scalar specifying the number of nearest neighbors to consider during graph construction.
                                #d = 50, # An integer scalar specifying the number of dimensions to use for the search.
                                type = "rank", # A string specifying the type of weighting scheme to use for shared neighbors.
                                subset.row = metadata(PAG_sceset_qc_norm_filt_corr)$hvg_cv2_out_no_spikes_filt,
                                assay.type = "logcounts",
                                use.dimred = "PCA_HVG_cv2_corrected")

clusters_cv2_rank <- igraph::cluster_walktrap(graph_cv2_rank)$membership
PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_rank <- factor(clusters_cv2_rank)
table(PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_rank)

# Using HVG from CV2 with jaccard-based weights
graph_cv2_jaccard <- buildSNNGraph(PAG_sceset_qc_norm_filt_corr,
                                   k = 8, # An integer scalar specifying the number of nearest neighbors to consider during graph construction.
                                   #d = 50, # An integer scalar specifying the number of dimensions to use for the search.
                                   type = "jaccard", # A string specifying the type of weighting scheme to use for shared neighbors.
                                   subset.row = metadata(PAG_sceset_qc_norm_filt_corr)$hvg_cv2_out_no_spikes_filt,
                                   assay.type = "logcounts",
                                   use.dimred = "PCA_HVG_cv2_corrected")

clusters_cv2_jaccard <- igraph::cluster_louvain(graph_cv2_jaccard)$membership
PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_jaccard <- factor(clusters_cv2_jaccard)
table(PAG_sceset_qc_norm_filt_corr$SNN_clusters_cv2_jaccard)
```

We can then assign the cluster assignments back into our `SingleCellExperiment` object as a factor in the column metadata. This allows us to conveniently visualize the distribution of clusters in a t-SNE or UMAP plot:
```{r}
plotReducedDim(PAG_sceset_qc_norm_filt_corr, dimred = "UMAP_var_corrected_10_neighbors_0.05_min_dist",
               colour_by = "PAG.arearegistration", shape_by = "cell.type") + ggtitle("UMAP_var_corrected_10_neighbors_0.05_min_dist")

# Using HVG from Var with rank-based weights
plotReducedDim(PAG_sceset_qc_norm_filt_corr, dimred = "UMAP_var_corrected_10_neighbors_0.05_min_dist",
               colour_by = "SNN_clusters_var_rank", shape_by = "cell.type", text_by = "SNN_clusters_var_rank") + ggtitle("UMAP_var_corrected_10_neighbors_0.05_min_dist")

# Using HVG from Var with jaccard-based weights
plotReducedDim(PAG_sceset_qc_norm_filt_corr, dimred = "UMAP_var_corrected_10_neighbors_0.05_min_dist",
               colour_by = "SNN_clusters_var_jaccard", shape_by = "cell.type", text_by = "SNN_clusters_var_jaccard") + ggtitle("UMAP_var_corrected_10_neighbors_0.05_min_dist")


plotReducedDim(PAG_sceset_qc_norm_filt_corr, dimred = "UMAP_var_corrected_10_neighbors_0.05_min_dist",
               colour_by = "PAG.arearegistration", shape_by = "cell.type") + ggtitle("UMAP_var_corrected_10_neighbors_0.05_min_dist")

# Using HVG from CV2 with rank-based weights
plotReducedDim(PAG_sceset_qc_norm_filt_corr, dimred = "UMAP_var_corrected_10_neighbors_0.05_min_dist",
               colour_by = "SNN_clusters_cv2_rank", shape_by = "cell.type", text_by = "SNN_clusters_cv2_rank") + ggtitle("UMAP_var_corrected_10_neighbors_0.05_min_dist")

# Using HVG from CV2 with jaccard-based weights
plotReducedDim(PAG_sceset_qc_norm_filt_corr, dimred = "UMAP_var_corrected_10_neighbors_0.05_min_dist",
               colour_by = "SNN_clusters_cv2_jaccard", shape_by = "cell.type", text_by = "SNN_clusters_cv2_jaccard") + ggtitle("UMAP_var_corrected_10_neighbors_0.05_min_dist")
```

### 6.2.2 | Assessing cluster separation
When dealing with graphs, the modularity is a natural metric for evaluating the separation between communities/clusters. This is defined as the (scaled) difference between the observed total weight of edges between nodes in the same cluster and the expected total weight if edge weights were randomly distributed across all pairs of nodes. Larger modularity values indicate that there most edges occur within clusters, suggesting that the clusters are sufficiently well separated to avoid edges forming between neighboring cells in different clusters.

The standard approach is to report a single modularity value for a clustering on a given graph. This is useful for comparing different clusterings on the same graph - and indeed, some community detection algorithms are designed with the aim of maximizing the modularity - but it is less helpful for interpreting a given we use the ratio instead of the difference as the former is less dependent on the number of cells in each cluster. We would usually expect to see high observed weights between cells in the same cluster with minimal weights between clusters, indicating that the clusters are well-separated. Off-diagonal entries indicate that some clusters are closely related, which is useful to know for checking that they are annotated consistently.
```{r}
ratio_var_rank <- clusterModularity(graph_var_rank, clusters_var_rank, as.ratio = TRUE)
ratio_var_rank

ratio_var_jaccard <- clusterModularity(graph_var_jaccard,clusters_var_jaccard, as.ratio = TRUE)
ratio_var_jaccard

ratio_cv2_rank <- clusterModularity(graph_cv2_rank,clusters_cv2_rank, as.ratio = TRUE)
ratio_cv2_rank

ratio_cv2_jaccard <- clusterModularity(graph_cv2_jaccard, clusters_cv2_jaccard, as.ratio = TRUE)
ratio_cv2_jaccard
```

In each matrix, each row/column corresponds to a cluster, and each entry of the matrix contains the ratio of the observed to total weight of edges between cells in the respective clusters. A dataset containing well-separated clusters should contain most of the observed total weight on the diagonal entries, i.e., most edges occur between cells in the same cluster. Concentration of the weight on the diagonal of indicates that most of the clusters are well-separated, while some modest off-diagonal entries represent closely related clusters with more inter-connecting edges.
```{r}
library(pheatmap)
pheatmap(log2(ratio_var_rank + 1), 
         cluster_cols = FALSE, cluster_rows = FALSE,
         color = colorRampPalette(c("white", "blue"))(100))
         #col = rev(heat.colors(100)))

pheatmap(log2(ratio_var_jaccard + 1), 
         cluster_cols = FALSE, cluster_rows = FALSE,
         color = colorRampPalette(c("white", "blue"))(100))
         #col = rev(heat.colors(100)))

pheatmap(log2(ratio_cv2_rank + 1), 
         cluster_cols = FALSE, cluster_rows = FALSE,
         color = colorRampPalette(c("white", "blue"))(100))
         #col = rev(heat.colors(100)))

pheatmap(log2(ratio_cv2_jaccard + 1), 
         cluster_cols = FALSE, cluster_rows = FALSE,
         color = colorRampPalette(c("white", "blue"))(100))
         #col = rev(heat.colors(100)))
```

## Step 6.2b | Cell-type specific Graph-based clustering
We can repeat the same but subsetting the `SingleCellExperiment` object:
```{r}
PAG_sceset_qc_norm_filt_corr_VGAT <- PAG_sceset_qc_norm_filt_corr[, PAG_sceset_qc_norm_filt_corr$cell.type=="VGAT"]
PAG_sceset_qc_norm_filt_corr_VGluT2 <- PAG_sceset_qc_norm_filt_corr[, PAG_sceset_qc_norm_filt_corr$cell.type=="VGluT2"]
```

### 6.2b.1 | Implementation of graph-based clustering
```{r}
library(scran)
# Using HVG from Var with rank-based weights
graph_var_rank_VGAT <- buildSNNGraph(PAG_sceset_qc_norm_filt_corr_VGAT,
                                     k = 10, # An integer scalar specifying the number of nearest neighbors to consider during graph construction.
                                     #d = 50, # An integer scalar specifying the number of dimensions to use for the search.
                                     type = "rank", # A string specifying the type of weighting scheme to use for shared neighbors. Try "rank" or "jaccard"
                                     subset.row = metadata(PAG_sceset_qc_norm_filt_corr)$hvg_var_out_no_spikes_block_filt,
                                     assay.type = "logcounts",
                                     use.dimred = "PCA_HVG_var_logcounts")
clusters_var_rank_VGAT <- igraph::cluster_walktrap(graph_var_rank_VGAT)$membership
PAG_sceset_qc_norm_filt_corr_VGAT$SNN_clusters_var_rank_VGAT <- factor(clusters_var_rank_VGAT)
table(PAG_sceset_qc_norm_filt_corr_VGAT$SNN_clusters_var_rank_VGAT)

graph_var_rank_VGluT2 <- buildSNNGraph(PAG_sceset_qc_norm_filt_corr_VGluT2,
                                       k = 10, # An integer scalar specifying the number of nearest neighbors to consider during graph construction.
                                       #d = 50, # An integer scalar specifying the number of dimensions to use for the search.
                                       type = "rank", # A string specifying the type of weighting scheme to use for shared neighbors. Try "rank" or "jaccard"
                                       subset.row = metadata(PAG_sceset_qc_norm_filt_corr)$hvg_var_out_no_spikes_block_filt,
                                       assay.type = "logcounts",
                                       use.dimred = "PCA_HVG_var_logcounts")
clusters_var_rank_VGluT2 <- igraph::cluster_walktrap(graph_var_rank_VGluT2)$membership
PAG_sceset_qc_norm_filt_corr_VGluT2$SNN_clusters_var_rank_VGluT2 <- factor(clusters_var_rank_VGluT2)
table(PAG_sceset_qc_norm_filt_corr_VGluT2$SNN_clusters_var_rank_VGluT2)

# Using HVG from Var with jaccard-based weights
graph_var_jaccard_VGAT <- buildSNNGraph(PAG_sceset_qc_norm_filt_corr_VGAT,
                                        k = 10, # An integer scalar specifying the number of nearest neighbors to consider during graph construction.
                                        #d = 50, # An integer scalar specifying the number of dimensions to use for the search.
                                        type = "jaccard", # A string specifying the type of weighting scheme to use for shared neighbors. Try "rank" or "jaccard"
                                        subset.row = metadata(PAG_sceset_qc_norm_filt_corr)$hvg_var_out_no_spikes_block_filt,
                                        assay.type = "logcounts",
                                        use.dimred = "PCA_HVG_var_logcounts")
clusters_var_jaccard_VGAT <- igraph::cluster_louvain(graph_var_jaccard_VGAT)$membership
PAG_sceset_qc_norm_filt_corr_VGAT$SNN_clusters_var_jaccard_VGAT <- factor(clusters_var_jaccard_VGAT)
table(PAG_sceset_qc_norm_filt_corr_VGAT$SNN_clusters_var_jaccard_VGAT)

graph_var_jaccard_VGluT2 <- buildSNNGraph(PAG_sceset_qc_norm_filt_corr_VGluT2,
                                          k = 10, # An integer scalar specifying the number of nearest neighbors to consider during graph construction.
                                          #d = 50, # An integer scalar specifying the number of dimensions to use for the search.
                                          type = "jaccard", # A string specifying the type of weighting scheme to use for shared neighbors. Try "rank" or "jaccard"
                                          subset.row = metadata(PAG_sceset_qc_norm_filt_corr)$hvg_var_out_no_spikes_block_filt,
                                          assay.type = "logcounts",
                                          use.dimred = "PCA_HVG_var_logcounts")
clusters_var_jaccard_VGluT2 <- igraph::cluster_louvain(graph_var_jaccard_VGluT2)$membership
PAG_sceset_qc_norm_filt_corr_VGluT2$SNN_clusters_var_jaccard_VGluT2 <- factor(clusters_var_jaccard_VGluT2)
table(PAG_sceset_qc_norm_filt_corr_VGluT2$SNN_clusters_var_jaccard_VGluT2)
 
# Using HVG from CV2 with rank-based weights
graph_cv2_rank_VGAT <- buildSNNGraph(PAG_sceset_qc_norm_filt_corr_VGAT,
                                     k = 10, # An integer scalar specifying the number of nearest neighbors to consider during graph construction.
                                     #d = 50, # An integer scalar specifying the number of dimensions to use for the search.
                                     type = "rank", # A string specifying the type of weighting scheme to use for shared neighbors. Try "rank" or "jaccard"
                                     subset.row = metadata(PAG_sceset_qc_norm_filt_corr)$hvg_cv2_out_no_spikes_filt,
                                     assay.type = "logcounts",
                                     use.dimred = "PCA_HVG_cv2_logcounts")
clusters_cv2_rank_VGAT <- igraph::cluster_walktrap(graph_cv2_rank_VGAT)$membership
PAG_sceset_qc_norm_filt_corr_VGAT$SNN_clusters_cv2_rank_VGAT <- factor(clusters_cv2_rank_VGAT)
table(PAG_sceset_qc_norm_filt_corr_VGAT$SNN_clusters_cv2_rank_VGAT)

graph_cv2_rank_VGluT2 <- buildSNNGraph(PAG_sceset_qc_norm_filt_corr_VGluT2,
                                       k = 10, # An integer scalar specifying the number of nearest neighbors to consider during graph construction.
                                       #d = 50, # An integer scalar specifying the number of dimensions to use for the search.
                                       type = "rank", # A string specifying the type of weighting scheme to use for shared neighbors. Try "rank" or "jaccard"
                                       subset.row = metadata(PAG_sceset_qc_norm_filt_corr)$hvg_cv2_out_no_spikes_filt,
                                       assay.type = "logcounts",
                                       use.dimred = "PCA_HVG_cv2_logcounts")
clusters_cv2_rank_VGluT2 <- igraph::cluster_walktrap(graph_cv2_rank_VGluT2)$membership
PAG_sceset_qc_norm_filt_corr_VGluT2$SNN_clusters_cv2_rank_VGluT2 <- factor(clusters_cv2_rank_VGluT2)
table(PAG_sceset_qc_norm_filt_corr_VGluT2$SNN_clusters_cv2_rank_VGluT2)

# Using HVG from CV2 with jaccard-based weights
graph_cv2_jaccard_VGAT <- buildSNNGraph(PAG_sceset_qc_norm_filt_corr_VGAT,
                                        k = 10, # An integer scalar specifying the number of nearest neighbors to consider during graph construction.
                                        #d = 50, # An integer scalar specifying the number of dimensions to use for the search.
                                        type = "jaccard", # A string specifying the type of weighting scheme to use for shared neighbors. Try "rank" or "jaccard"
                                        subset.row = metadata(PAG_sceset_qc_norm_filt_corr)$hvg_cv2_out_no_spikes_filt,
                                        assay.type = "logcounts",
                                        use.dimred = "PCA_HVG_cv2_logcounts")
clusters_cv2_jaccard_VGAT <- igraph::cluster_louvain(graph_cv2_jaccard_VGAT)$membership
PAG_sceset_qc_norm_filt_corr_VGAT$SNN_clusters_cv2_jaccard_VGAT <- factor(clusters_cv2_jaccard_VGAT)
table(PAG_sceset_qc_norm_filt_corr_VGAT$SNN_clusters_cv2_jaccard_VGAT)

graph_cv2_jaccard_VGluT2 <- buildSNNGraph(PAG_sceset_qc_norm_filt_corr_VGluT2,
                                          k = 10, # An integer scalar specifying the number of nearest neighbors to consider during graph construction.
                                          #d = 50, # An integer scalar specifying the number of dimensions to use for the search.
                                          type = "jaccard", # A string specifying the type of weighting scheme to use for shared neighbors. Try "rank" or "jaccard"
                                          subset.row = metadata(PAG_sceset_qc_norm_filt_corr)$hvg_cv2_out_no_spikes_filt,
                                          assay.type = "logcounts",
                                          use.dimred = "PCA_HVG_cv2_logcounts")
clusters_cv2_jaccard_VGluT2 <- igraph::cluster_louvain(graph_cv2_jaccard_VGluT2)$membership
PAG_sceset_qc_norm_filt_corr_VGluT2$SNN_clusters_cv2_jaccard_VGluT2 <- factor(clusters_cv2_jaccard_VGluT2)
table(PAG_sceset_qc_norm_filt_corr_VGluT2$SNN_clusters_cv2_jaccard_VGluT2)
```

```{r}
# VGAT cells
plotReducedDim(PAG_sceset_qc_norm_filt_corr_VGAT, dimred = "UMAP_var_logcounts_10_neighbors_0.05_min_dist",
               colour_by = "PAG.arearegistration", shape_by = "VGAT_VGluT2_expression") + ggtitle("UMAP_var_logcounts_10_neighbors_0.05_min_dist")
## Using HVG from Var with rank-based weights
plotReducedDim(PAG_sceset_qc_norm_filt_corr_VGAT, dimred = "UMAP_var_logcounts_10_neighbors_0.05_min_dist",
               colour_by = "SNN_clusters_var_rank_VGAT", text_by = "SNN_clusters_var_rank_VGAT") + ggtitle("UMAP_var_logcounts_10_neighbors_0.05_min_dist")
## Using HVG from Var with jaccard-based weights
plotReducedDim(PAG_sceset_qc_norm_filt_corr_VGAT, dimred = "UMAP_var_logcounts_10_neighbors_0.05_min_dist",
               colour_by = "SNN_clusters_var_jaccard_VGAT", text_by = "SNN_clusters_var_jaccard_VGAT") + ggtitle("UMAP_var_logcounts_10_neighbors_0.05_min_dist")
## Using HVG from CV2 with rank-based weights
plotReducedDim(PAG_sceset_qc_norm_filt_corr_VGAT, dimred = "UMAP_var_logcounts_10_neighbors_0.05_min_dist",
               colour_by = "SNN_clusters_cv2_rank_VGAT", text_by = "SNN_clusters_cv2_rank_VGAT") + ggtitle("UMAP_var_logcounts_10_neighbors_0.05_min_dist")
## Using HVG from CV2 with jaccard-based weights
plotReducedDim(PAG_sceset_qc_norm_filt_corr_VGAT, dimred = "UMAP_var_logcounts_10_neighbors_0.05_min_dist",
               colour_by = "SNN_clusters_cv2_jaccard_VGAT", text_by = "SNN_clusters_cv2_jaccard_VGAT") + ggtitle("UMAP_var_logcounts_10_neighbors_0.05_min_dist")

# VGluT2 cells
plotReducedDim(PAG_sceset_qc_norm_filt_corr_VGluT2, dimred = "UMAP_var_logcounts_10_neighbors_0.05_min_dist",
               colour_by = "PAG.arearegistration", shape_by = "VGAT_VGluT2_expression") + ggtitle("UMAP_var_logcounts_10_neighbors_0.05_min_dist")
## Using HVG from Var with rank-based weights
plotReducedDim(PAG_sceset_qc_norm_filt_corr_VGluT2, dimred = "UMAP_var_logcounts_10_neighbors_0.05_min_dist",
               colour_by = "SNN_clusters_var_rank_VGluT2", text_by = "SNN_clusters_var_rank_VGluT2") + ggtitle("UMAP_var_logcounts_10_neighbors_0.05_min_dist")
## Using HVG from Var with jaccard-based weights
plotReducedDim(PAG_sceset_qc_norm_filt_corr_VGluT2, dimred = "UMAP_var_logcounts_10_neighbors_0.05_min_dist",
               colour_by = "SNN_clusters_var_jaccard_VGluT2", text_by = "SNN_clusters_var_jaccard_VGluT2") + ggtitle("UMAP_var_logcounts_10_neighbors_0.05_min_dist")
## Using HVG from CV2 with rank-based weights
plotReducedDim(PAG_sceset_qc_norm_filt_corr_VGluT2, dimred = "UMAP_var_logcounts_10_neighbors_0.05_min_dist",
               colour_by = "SNN_clusters_cv2_rank_VGluT2", text_by = "SNN_clusters_cv2_rank_VGluT2") + ggtitle("UMAP_var_logcounts_10_neighbors_0.05_min_dist")
## Using HVG from CV2 with jaccard-based weights
plotReducedDim(PAG_sceset_qc_norm_filt_corr_VGluT2, dimred = "UMAP_var_logcounts_10_neighbors_0.05_min_dist",
               colour_by = "SNN_clusters_cv2_jaccard_VGluT2", text_by = "SNN_clusters_cv2_jaccard_VGluT2") + ggtitle("UMAP_var_logcounts_10_neighbors_0.05_min_dist")
```

### 6.2b.2 | Assessing cluster separation
```{r}
# VGAT
ratio_var_rank_VGAT <- clusterModularity(graph_var_rank_VGAT, clusters_var_rank_VGAT, as.ratio = TRUE)
ratio_var_rank_VGAT

ratio_var_jaccard_VGAT <- clusterModularity(graph_var_jaccard_VGAT, clusters_var_jaccard_VGAT, as.ratio = TRUE)
ratio_var_jaccard_VGAT

ratio_cv2_rank_VGAT <- clusterModularity(graph_cv2_rank_VGAT, clusters_cv2_rank_VGAT, as.ratio = TRUE)
ratio_cv2_rank_VGAT

ratio_cv2_jaccard_VGAT <- clusterModularity(graph_cv2_jaccard_VGAT, clusters_cv2_jaccard_VGAT, as.ratio = TRUE)
ratio_cv2_jaccard_VGAT

# VGluT2
ratio_var_rank_VGluT2 <- clusterModularity(graph_var_rank_VGluT2, clusters_var_rank_VGluT2, as.ratio = TRUE)
ratio_var_rank_VGluT2

ratio_var_jaccard_VGluT2 <- clusterModularity(graph_var_jaccard_VGluT2, clusters_var_jaccard_VGluT2, as.ratio = TRUE)
ratio_var_jaccard_VGluT2

ratio_cv2_rank_VGluT2 <- clusterModularity(graph_cv2_rank_VGluT2, clusters_cv2_rank_VGluT2, as.ratio = TRUE)
ratio_cv2_rank_VGluT2

ratio_cv2_jaccard_VGluT2 <- clusterModularity(graph_cv2_jaccard_VGluT2, clusters_cv2_jaccard_VGluT2, as.ratio = TRUE)
ratio_cv2_jaccard_VGluT2
```

```{r}
library(pheatmap)
# VGAT
pheatmap(log2(ratio_var_rank_VGAT + 1), 
         cluster_cols = FALSE, cluster_rows = FALSE,
         color = colorRampPalette(c("white", "blue"))(100))
         #col = rev(heat.colors(100)))

pheatmap(log2(ratio_var_jaccard_VGAT + 1), 
         cluster_cols = FALSE, cluster_rows = FALSE,
         color = colorRampPalette(c("white", "blue"))(100))
         #col = rev(heat.colors(100)))

pheatmap(log2(ratio_cv2_rank_VGAT + 1), 
         cluster_cols = FALSE, cluster_rows = FALSE,
         color = colorRampPalette(c("white", "blue"))(100))
         #col = rev(heat.colors(100)))

pheatmap(log2(ratio_cv2_jaccard_VGAT + 1), 
         cluster_cols = FALSE, cluster_rows = FALSE,
         color = colorRampPalette(c("white", "blue"))(100))
         #col = rev(heat.colors(100)))

# VGluT2
pheatmap(log2(ratio_var_rank_VGluT2 + 1), 
         cluster_cols = FALSE, cluster_rows = FALSE,
         color = colorRampPalette(c("white", "blue"))(100))
         #col = rev(heat.colors(100)))

pheatmap(log2(ratio_var_jaccard_VGluT2 + 1), 
         cluster_cols = FALSE, cluster_rows = FALSE,
         color = colorRampPalette(c("white", "blue"))(100))
         #col = rev(heat.colors(100)))

pheatmap(log2(ratio_cv2_rank_VGluT2 + 1), 
         cluster_cols = FALSE, cluster_rows = FALSE,
         color = colorRampPalette(c("white", "blue"))(100))
         #col = rev(heat.colors(100)))

pheatmap(log2(ratio_cv2_jaccard_VGluT2 + 1), 
         cluster_cols = FALSE, cluster_rows = FALSE,
         color = colorRampPalette(c("white", "blue"))(100))
         #col = rev(heat.colors(100)))
```

## Step 6.3 | k-means clustering
k-means clustering is a classic technique that aims to partition cells into k clusters. Each cell is assigned to the cluster with the closest centroid, which is done by minimizing the within-cluster sum of squares using a *random* starting configuration for the k centroids. The main advantage of this approach lies in its speed, given the simplicity and ease of implementation of the algorithm. However, it suffers from a number of serious shortcomings that reduce its appeal for obtaining interpretable clusters:

* It implicitly favours spherical clusters of equal radius. This can lead to unintuitive partitionings on real datasets that contain groupings with irregular sizes and shapes.

* The number of clusters k must be specified beforehand and represents a hard cap on the resolution of the clustering. For example, setting k to be below the number of cell types will always lead to co-clustering of two cell types, regardless of how well separated they are. In contrast, other methods like graph-based clustering will respect strong separation even if the relevant resolution parameter is set to a low value.

* It is dependent on the randomly chosen initial coordinates. This requires multiple runs to verify that the clustering is stable. 

That said, k-means clustering is still one of the best approaches for sample-based data compression. In this application, we set k to a large value such as the square root of the number of cells to obtain fine-grained clusters. These are not meant to be interpreted directly, but rather, the centroids are treated as “samples” for further analyses. The idea here is to obtain a single representative of each region of the expression space, reducing the number of samples and computational work in later steps like, e.g., trajectory reconstruction (Ji and Ji 2016). This approach will also eliminate differences in cell density across the expression space, ensuring that the most abundant cell type does not dominate downstream results.

### 6.3.1 | Implementation of k-means clustering
Base R provides the `kmeans()` function that does as its name suggests. We call this on our top PCs to obtain a clustering for a specified number of clusters in the `centers=` argument, after setting the random seed to ensure that the results are reproducible. In general, the k-means clusters correspond to the visual clusters on a previously obtained t-SNE plot.
```{r}
set.seed(1991)

plotReducedDim(PAG_sceset_qc_norm_filt_corr, dimred = "UMAP_var_logcounts_10_neighbors_0.05_min_dist",
               colour_by = "PAG.arearegistration", shape_by = "cell.type") + ggtitle("UMAP_var_logcounts_10_neighbors_0.05_min_dist")

# Using PCA from HVG_var_logcounts
cluster_kmeans_var <- kmeans(reducedDim(PAG_sceset_qc_norm_filt_corr, "PCA_HVG_var_logcounts"), centers = 7)
PAG_sceset_qc_norm_filt_corr$cluster_kmeans_var <- factor(cluster_kmeans_var$cluster)
plotReducedDim(PAG_sceset_qc_norm_filt_corr, "UMAP_var_logcounts_10_neighbors_0.05_min_dist", 
               colour_by = "cluster_kmeans_var", text_by = "cluster_kmeans_var") + ggtitle("UMAP_var_logcounts_10_neighbors_0.05_min_dist")

# Using PCA from HVG_cv2_logcounts
cluster_kmeans_cv2 <- kmeans(reducedDim(PAG_sceset_qc_norm_filt_corr, "PCA_HVG_cv2_logcounts"), centers = 7)
PAG_sceset_qc_norm_filt_corr$cluster_kmeans_cv2 <- factor(cluster_kmeans_cv2$cluster)
plotReducedDim(PAG_sceset_qc_norm_filt_corr, "UMAP_var_logcounts_10_neighbors_0.05_min_dist", 
               colour_by = "cluster_kmeans_cv2", text_by = "cluster_kmeans_cv2") + ggtitle("UMAP_var_logcounts_10_neighbors_0.05_min_dist")

table(cluster_kmeans_cv2$cluster)
table(cluster_kmeans_var$cluster)
```

### 6.3.2 | Choosing a reasonable "k"
We could obtain a “reasonable” choice of k by computing the gap statistic using methods from the `cluster` package. This is the log-ratio of the expected to observed within-cluster sum of squares, where the expected value is computed by randomly distributing cells within the minimum bounding box of the original data. A larger gap statistic represents a lower observed sum of squares - and thus better clustering - compared to a population with no structure. Ideally, we would choose the k that maximizes the gap statistic, but this is often unhelpful as the tendency of k-means to favour spherical clusters drives a large k to capture different cluster shapes. Instead, we choose the most parsimonious k beyond which the increases in the gap statistic are considered insignificant.
```{r}
library(cluster)
set.seed(1991)

# Using PCA from HVG_var_logcounts
gaps_var <- clusGap(reducedDim(PAG_sceset_qc_norm_filt_corr, "PCA_HVG_var_logcounts"), kmeans, K.max = 20)
best_k_var <- maxSE(gaps_var$Tab[,"gap"], gaps_var$Tab[,"SE.sim"])
best_k_var

plot(gaps_var$Tab[,"gap"], xlab = "Number of clusters", ylab = "Gap statistic")
abline(v = best_k_var, col = "red")

# Using PCA from HVG_cv2_logcounts
gaps_cv2 <- clusGap(reducedDim(PAG_sceset_qc_norm_filt_corr, "PCA_HVG_cv2_logcounts"), kmeans, K.max = 20)
best_k_cv2 <- maxSE(gaps_cv2$Tab[,"gap"], gaps_cv2$Tab[,"SE.sim"])
best_k_cv2

plot(gaps_cv2$Tab[,"gap"], xlab = "Number of clusters", ylab = "Gap statistic")
abline(v = best_k_cv2, col = "red")
```

### 6.3.3 | Overclustering
A more practical use of k-means is to deliberately set k to a large value to achieve overclustering. This will forcibly partition cells inside broad clusters that do not have well-defined internal structure. For example, we might be interested in the change in expression from one “side” of a cluster to the other, but the lack of any clear separation within the cluster makes it difficult to separate with graph-based methods, even at the highest resolution. k-means has no such problems and will readily split these broad clusters for greater resolution, though obviously one must be prepared for the additional work involved in interpreting a greater number of clusters.
```{r}
set.seed(1991)

plotReducedDim(PAG_sceset_qc_norm_filt_corr, dimred = "UMAP_var_logcounts_10_neighbors_0.05_min_dist",
               colour_by = "PAG.arearegistration", shape_by = "cell.type") + ggtitle("UMAP_var_logcounts_10_neighbors_0.05_min_dist")

# Using PCA from HVG_var_logcounts
overcluster_kmeans_var <- kmeans(reducedDim(PAG_sceset_qc_norm_filt_corr, "PCA_HVG_var_logcounts"), centers = 20)
PAG_sceset_qc_norm_filt_corr$overcluster_kmeans_var <- factor(overcluster_kmeans_var$cluster)
plotReducedDim(PAG_sceset_qc_norm_filt_corr, "UMAP_var_logcounts_10_neighbors_0.05_min_dist", 
               colour_by = "overcluster_kmeans_var", text_by = "overcluster_kmeans_var") + ggtitle("UMAP_var_logcounts_10_neighbors_0.05_min_dist")

# Using PCA from HVG_cv2_logcounts
overcluster_kmeans_cv2 <- kmeans(reducedDim(PAG_sceset_qc_norm_filt_corr, "PCA_HVG_cv2_logcounts"), centers = 20)
PAG_sceset_qc_norm_filt_corr$overcluster_kmeans_cv2 <- factor(overcluster_kmeans_cv2$cluster)
plotReducedDim(PAG_sceset_qc_norm_filt_corr, "UMAP_var_logcounts_10_neighbors_0.05_min_dist", 
               colour_by = "overcluster_kmeans_cv2", text_by = "overcluster_kmeans_cv2") + ggtitle("UMAP_var_logcounts_10_neighbors_0.05_min_dist")

table(overcluster_kmeans_var$cluster)
table(overcluster_kmeans_cv2$cluster)
```

### 6.3.4 | Assessing cluster separation
The within-cluster sum of squares (WCSS) for each cluster is the most relevant diagnostic for k-means, given that the algorithm aims to find a clustering that minimizes the WCSS. Specifically, we use the WCSS to compute the root-mean-squared deviation (RMSD) that represents the spread of cells within each cluster. A cluster is more likely to have a low RMSD if it has no internal structure and is separated from other clusters (such that there are not many cells on the boundaries between clusters, which would result in a higher sum of squares from the centroid).
```{r}
ncells_cluster_kmeans_cv2 <- tabulate(cluster_kmeans_cv2$cluster)
tab_cluster_kmeans_cv2 <- data.frame(wcss = cluster_kmeans_cv2$withinss, ncells = ncells_cluster_kmeans_cv2)
tab_cluster_kmeans_cv2$rms <- sqrt(tab_cluster_kmeans_cv2$wcss/tab_cluster_kmeans_cv2$ncells)
tab_cluster_kmeans_cv2

ncells_cluster_kmeans_var <- tabulate(cluster_kmeans_var$cluster)
tab_cluster_kmeans_var <- data.frame(wcss = cluster_kmeans_var$withinss, ncells = ncells_cluster_kmeans_var)
tab_cluster_kmeans_var$rms <- sqrt(tab_cluster_kmeans_var$wcss/tab_cluster_kmeans_var$ncells)
tab_cluster_kmeans_var

ncells_overcluster_kmeans_var <- tabulate(overcluster_kmeans_var$cluster)
tab_overcluster_kmeans_var <- data.frame(wcss = overcluster_kmeans_var$withinss, ncells = ncells_overcluster_kmeans_var)
tab_overcluster_kmeans_var$rms <- sqrt(tab_overcluster_kmeans_var$wcss/tab_overcluster_kmeans_var$ncells)
tab_overcluster_kmeans_var

ncells_overcluster_kmeans_cv2 <- tabulate(overcluster_kmeans_cv2$cluster)
tab_overcluster_kmeans_cv2 <- data.frame(wcss = overcluster_kmeans_cv2$withinss, ncells = ncells_overcluster_kmeans_cv2)
tab_overcluster_kmeans_cv2$rms <- sqrt(tab_overcluster_kmeans_cv2$wcss/tab_overcluster_kmeans_cv2$ncells)
tab_overcluster_kmeans_cv2
```

To explore the relationships between k-means clusters, a natural approach is to compute distances between their centroids. This directly lends itself to visualization as a tree after hierarchical clustering.
```{r}
cent_tree_cluster_kmeans_cv2 <- hclust(dist(cluster_kmeans_cv2$centers), "ward.D2")
plot(cent_tree_cluster_kmeans_cv2)

cent_tree_cluster_kmeans_var <- hclust(dist(cluster_kmeans_var$centers), "ward.D2")
plot(cent_tree_cluster_kmeans_var)

cent_tree_overcluster_kmeans_var <- hclust(dist(overcluster_kmeans_var$centers), "ward.D2")
plot(cent_tree_overcluster_kmeans_var)

cent_tree_overcluster_kmeans_cv2 <- hclust(dist(overcluster_kmeans_cv2$centers), "ward.D2")
plot(cent_tree_overcluster_kmeans_cv2)
```

## Step 6.4 | Hierarchical clustering
Hierarchical clustering is an ancient technique that aims to generate a dendrogram containing a hierarchy of samples. This is most commonly done by greedily agglomerating samples into clusters, then agglomerating those clusters into larger clusters, and so on until all samples belong to a single cluster. Variants of hierarchical clustering methods primarily differ in how they choose to perform the agglomerations. For example, complete linkage aims to merge clusters with the smallest maximum distance between their elements, while Ward’s method aims to minimize the increase in within-cluster variance.

In the context of scRNA-seq, the main advantage of hierarchical clustering lies in the production of the dendrogram. This is a rich summary that describes the relationships between cells and subpopulations at various resolutions and in a quantitative manner based on the branch lengths. Users can easily “cut” the tree at different heights to define clusters with different granularity, where clusters defined at high resolution are guaranteed to be nested within those defined at a lower resolution. (Guaranteed nesting can be helpful for interpretation.) The dendrogram is also a natural representation of the data in situations where cells have descended from a relatively recent common ancestor.

In practice, hierachical clustering is too slow to be used for anything but the smallest scRNA-seq datasets. Most variants require a cell-cell distance matrix that is prohibitively expensive to compute for many cells. Greedy agglomeration is also likely to result in a quantitatively suboptimal partitioning (as defined by the agglomeration measure) at higher levels of the dendrogram when the number of cells and merge steps is high.

### 6.4.1 | Implementation of hierarchical clustering
We compute a cell-cell distance matrix using the top PCs and we apply hierarchical clustering with Ward’s method. We can then inspect the resulting tree. While both Ward’s method and complete linkage (`hclust()`’s default) yield compact clusters, we prefer the former as it is less affected by differences in variance between clusters. This yields a dendrogram that groups together cells with similar expression patterns across the chosen genes.
```{r}
# Using PCA from HVG_var_logcounts
PAG_dist_var <- dist(reducedDim(PAG_sceset_qc_norm_filt_corr, "PCA_HVG_var_logcounts")) # Making a distance matrix
PAG_tree_var <- hclust(PAG_dist_var, "ward.D2") # Building a tree
plot(PAG_tree_var)

# Making a prettier dendrogram.
library(dendextend)
PAG_tree_var$labels <- seq_along(PAG_tree_var$labels)
PAG_dend_var <- as.dendrogram(PAG_tree_var, hang = 0.1)

combined_fac_var <- paste0(PAG_sceset_qc_norm_filt_corr$PAGarea_celltype)
labels_colors(PAG_dend_var) <- c(`dmpag_VGAT` = "cornflowerblue",
                                 `dlpag_VGAT` = "cyan3",
                                 `lpag_VGAT` = "aquamarine3",
                                 `vlpag_VGAT` = "cadetblue3",
                                 `dmpag_VGluT2` = "red",
                                 `dlpag_VGluT2` = "coral2",
                                 `lpag_VGluT2` = "salmon",
                                 `vlpag_VGluT2` = "darksalmon"
                                 )[combined_fac_var][order.dendrogram(PAG_dend_var)]

plot(PAG_dend_var)

# Using PCA from HVG_cv2_logcounts
PAG_dist_cv2 <- dist(reducedDim(PAG_sceset_qc_norm_filt_corr, "PCA_HVG_cv2_logcounts")) # Making a distance matrix
PAG_tree_cv2 <- hclust(PAG_dist_cv2, "ward.D2") # Building a tree
plot(PAG_tree_cv2)

# Making a prettier dendrogram.
library(dendextend)
PAG_tree_cv2$labels <- seq_along(PAG_tree_cv2$labels)
PAG_dend_cv2 <- as.dendrogram(PAG_tree_cv2, hang = 0.1)

combined_fac_cv2 <- paste0(PAG_sceset_qc_norm_filt_corr$PAGarea_celltype)
labels_colors(PAG_dend_cv2) <- c(`dmpag_VGAT` = "cornflowerblue",
                                 `dlpag_VGAT` = "cyan3",
                                 `lpag_VGAT` = "aquamarine3",
                                 `vlpag_VGAT` = "cadetblue3",
                                 `dmpag_VGluT2` = "red",
                                 `dlpag_VGluT2` = "coral2",
                                 `lpag_VGluT2` = "salmon",
                                 `vlpag_VGluT2` = "darksalmon"
                                 )[combined_fac_cv2][order.dendrogram(PAG_dend_cv2)]

plot(PAG_dend_cv2)
```

### 6.4.2 | Cutting the tree
To obtain explicit clusters, we can “cut” the tree by removing internal branches such that every subtree represents a distinct cluster. This is most simply done by removing internal branches above a certain height of the tree, as performed by the `cutree()` function. We can instead use the `dynamicTreeCut` package, which uses the shape of the branches to obtain a more suitable partitioning for complex dendrograms. Greater control of the empirical clusters can be obtained by manually specifying cutHeight in `cutreeDynamic`. We can also set `minClusterSize` to a lower value than the default of 20, to avoid spurious aggregation of distant small clusters.
```{r}
library(dynamicTreeCut)
PAG_clust_var <- cutreeDynamic(PAG_tree_var, distM = as.matrix(PAG_dist_var),
                               minClusterSize = 10, # minClusterSize needs to be turned down for small datasets.
                               deepSplit = 1) # deepSplit controls the resolution of the partitioning.
table(PAG_clust_var)
labels_colors(PAG_dend_var) <- PAG_clust_var[order.dendrogram(PAG_dend_var)]
plot(PAG_dend_var)

PAG_clust_cv2 <- cutreeDynamic(PAG_tree_cv2, distM = as.matrix(PAG_dist_cv2),
                               minClusterSize = 10, # minClusterSize needs to be turned down for small datasets.
                               deepSplit = 1) # deepSplit controls the resolution of the partitioning.
table(PAG_clust_cv2)
labels_colors(PAG_dend_cv2) <- PAG_clust_cv2[order.dendrogram(PAG_dend_cv2)]
plot(PAG_dend_cv2)
```

We can compare this to the `cutree()` function:
```{r}
PAG_clust_var_cutree <- cutree(PAG_tree_var, h = 300) 
labels_colors(PAG_dend_var) <- PAG_clust_var_cutree[order.dendrogram(PAG_dend_var)]
plot(PAG_dend_var)
table(PAG_clust_var_cutree, PAG_sceset_qc_norm_filt_corr$PAGarea_celltype)

PAG_clust_cv2_cutree <- cutree(PAG_tree_cv2, h = 300) 
labels_colors(PAG_dend_cv2) <- PAG_clust_cv2_cutree[order.dendrogram(PAG_dend_cv2)]
plot(PAG_dend_cv2)
table(PAG_clust_cv2_cutree, PAG_sceset_qc_norm_filt_corr$PAGarea_celltype)
```

We can now visualize the cluster assignments for all cells on any of the `ReducedDim` slots we previously computed (e.g. tSNE or UMAP). Adjacent cells are generally assigned to the same cluster, and the clustering results generally corresponds well to the grouping of cells on a t-SNE or UMAP plot.
```{r}
plotReducedDim(PAG_sceset_qc_norm_filt_corr, "UMAP_var_logcounts_10_neighbors_0.05_min_dist", colour_by = "PAGarea_celltype")

PAG_sceset_qc_norm_filt_corr$clusters_var_cutree <- factor(PAG_clust_var_cutree)
plotReducedDim(PAG_sceset_qc_norm_filt_corr, "UMAP_var_logcounts_10_neighbors_0.05_min_dist", colour_by = "clusters_var_cutree")

PAG_sceset_qc_norm_filt_corr$clusters_cv2_cutree <- factor(PAG_clust_cv2_cutree)
plotReducedDim(PAG_sceset_qc_norm_filt_corr, "UMAP_var_logcounts_10_neighbors_0.05_min_dist", colour_by = "clusters_cv2_cutree")
```

We can examine the distribution of cells in each cluster with respect to known factors. For instance, we can compare the cluster identities to batch to check the clustering is not driven by batch effects. We can also compare to any other interesting metadata to see what can be driving the clusters such as `cell.type` or `PAG.area`.
```{r}
table(Cluster = PAG_sceset_qc_norm_filt_corr$clusters_cv2_cutree, Batch = PAG_sceset_qc_norm_filt_corr$batch.processing)
table(Cluster = PAG_sceset_qc_norm_filt_corr$clusters_cv2_cutree, Mouse = PAG_sceset_qc_norm_filt_corr$mouse.id)
```

We next use a heatmap to visualize the expression profiles of the top 100 genes with the largest biological components. If there is structure, we should see "blocks" in expression that correspond nicely to known sample features. We possibly could have subclustered further, in which case we would subset and repeat the above process.
```{r}
library(pheatmap)
plotHeatmap(PAG_sceset_qc_norm_filt_corr, 
            features = metadata(PAG_sceset_qc_norm_filt_corr)$hvg_var_out_no_spikes_block_filt[1:200],
            cluster_cols = PAG_tree_var, colour_columns_by = c("clusters_var_cutree", "PAG.areacollection", "cell.type"),
            center = TRUE, symmetric = TRUE)

plotHeatmap(PAG_sceset_qc_norm_filt_corr, 
            features = metadata(PAG_sceset_qc_norm_filt_corr)$hvg_cv2_out_no_spikes_filt[1:200],
            cluster_cols = PAG_tree_cv2, colour_columns_by = c("clusters_cv2_cutree", "PAG.areacollection", "cell.type"),
            center = TRUE, symmetric = TRUE)
sum(PAG_sceset_qc_norm_filt_corr$clusters_cv2_cutree==4)
```

Looking at the heatmap we can see that one of the clusters (cluster #4 from `PAG_sceset_qc_norm_filt_corr$clusters_cv2_cutree`) is very highly enriched with genes corresponding to immune cells. These might actually be a group of cells contaminated with platelets or macrophages and should be excluded. Marker genes for macrophages include Ctss, C1qa, CD14, CD16, CD64, CD68, CD71 and CCR5.

### 6.4.3 | Assessing cluster separation
We can check the separation of the clusters by using the silhouette width. For each cell, we compute the average distance to cells in each other cluster. We then compute the minimum of these average distances across all clusters, as well as the average distance to cells in the same cluster. The silhouette width for each cell is defined as the difference between these two values divided by their maximum. Cells with large positive silhouette widths are closer to other cells in the same cluster than to cells in different clusters. Conversely, cells with negative widths are closer to other clusters than to other cells in the cluster to which it was assigned.

Each cluster would ideally contain large positive silhouette widths, indicating that it is well-separated from other clusters. Smaller widths can arise from the presence of internal subclusters, which inflates the within-cluster distance; or overclustering, where cells at the boundary of a partition are closer to the neighboring cluster than their own cluster.
```{r}
library(cluster)
cluster_colors <- scater:::.get_palette("tableau10medium") # hidden scater colours

sil_var <- silhouette(PAG_clust_var_cutree, dist = PAG_dist_var)
sil_cols_var <- cluster_colors[ifelse(sil_var[,3] > 0, sil_var[,1], sil_var[,2])]
sil_cols_var <- sil_cols_var[order(-sil_var[,1], sil_var[,3])]
plot(sil_var, main = paste(length(unique(PAG_clust_var_cutree)), "clusters"), border = sil_cols_var, col = sil_cols_var, do.col.sort = FALSE)

sil_cv2 <- silhouette(PAG_clust_cv2_cutree, dist = PAG_dist_cv2)
sil_cols_cv2 <- cluster_colors[ifelse(sil_cv2[,3] > 0, sil_cv2[,1], sil_cv2[,2])]
sil_cols_cv2 <- sil_cols_cv2[order(-sil_cv2[,1], sil_cv2[,3])]
plot(sil_cv2, main = paste(length(unique(PAG_clust_cv2_cutree)), "clusters"), border = sil_cols_cv2, col = sil_cols_cv2, do.col.sort = FALSE)
```

For a more detailed examination, we identify the closest neighboring cluster for cells with negative widths. This provides a perspective on the relationships between clusters that is closer to the raw data than the dendrogram.
```{r}
neg_widths_var <- sil_var[,3] < 0
table(Cluster = sil_var[neg_widths_var, 1], Neighbor = sil_var[neg_widths_var, 2])

neg_widths_cv2 <- sil_cv2[,3] < 0
table(Cluster = sil_cv2[neg_widths_cv2, 1], Neighbor = sil_cv2[neg_widths_cv2, 2])
```

The silhouette width can be used to determine the parameter values that maximize the separation between clusters. For example, we could vary the cut height or splitting depth in `cutreeDynamic` to maximize the average silhouette width across all cells. This usually provides a satisfactory initial clustering for further examination. However, the granularity of clustering is much like the magnification on a microscope. Different views of the data can be obtained with different granularities, some of which may be suboptimal on measures of separation. Users should not fixate on the clustering with the greatest separation if it does not provide the desired granularity for a particular biological question. Small silhouette positive widths indicate that the separation between clusters is weak. This may be symptomatic of over-clustering where clusters that are clearly defined are further split into subsets that are less well separated. 
```{r}
library(cluster)
cluster_colors <- scater:::.get_palette("tableau10medium") # hidden scater colours

for (k in 2:10) { 
    example_clusters <- cutree(PAG_tree_var, k = k)
    sil <- silhouette(example_clusters, dist = PAG_dist_var)
    sil_cols_var <- cluster_colors[ifelse(sil[,3] > 0, sil[,1], sil[,2])]
    sil_cols_var <- sil_cols_var[order(-sil[,1], sil[,3])]
    plot(sil, main = paste(length(unique(example_clusters)), "clusters"), border = sil_cols_var, col = sil_cols_var, do.col.sort = FALSE)
}

for (k in 2:10) { 
    example_clusters <- cutree(PAG_tree_cv2, k = k)
    sil <- silhouette(example_clusters, dist = PAG_dist_cv2)
    sil_cols_cv2 <- cluster_colors[ifelse(sil[,3] > 0, sil[,1], sil[,2])]
    sil_cols_cv2 <- sil_cols_cv2[order(-sil[,1], sil[,3])]
    plot(sil, main = paste(length(unique(example_clusters)), "clusters"), border = sil_cols_cv2, col = sil_cols_cv2, do.col.sort = FALSE)
}
```

## Step 6.5 | Save the SingleCellExperiment object
```{r}
saveRDS(PAG_sceset_qc_norm_filt_corr, file = "PAG_sceset_qc_norm_filt_corr_clust.rds")
print("Part 6 - Done!")
```

```{r}
sessionInfo()
```
---
title: "Topographic, single-cell gene expression profiling of Periaqueductal Gray neurons"
subtitle: "Part I: from a gene expression matrix to a SingleCellExperiment object"
author:
  - name: "Oriol Pavon Arocas, Sarah F. Olesen, and Tiago Branco"
    affiliation: "Sainsbury Wellcome Centre for Neural Circuits and Behaviour, University College London, UK"
    email: "oriol.pavon.16@ucl.ac.uk"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_notebook:
    highlight: pygments
    number_sections: FALSE
    theme: lumen
    toc: TRUE
    toc_float: TRUE

#output: rmdformats::readthedown:
  #highlight: pygments
---

***
This is a pipeline to analyse single-cell RNA sequencing data from Periaqueductal Gray neurons (1) isolated from acute midbrain slices of transgenic mice using visually guided aspiration via patch pipettes and (2) processed using SMART-seq2 (Picelli et al. Nature Protocols 2014). 

This pipeline has been generated after attending the [EMBL-EBI RNA-Sequence Analysis Course](https://www.ebi.ac.uk/training/events/2019/rna-sequence-analysis) and [attending](https://training.csx.cam.ac.uk/bioinformatics/event/2823386) and following the online course on [Analysis of single cell RNA-seq data](https://github.com/hemberg-lab/scRNA.seq.course) by the [Hemberg Lab](https://www.sanger.ac.uk/science/groups/hemberg-group). Many other resources have been used, including the [Orchestrating Single-Cell Analysis with Bioconductor book](https://osca.bioconductor.org/) by Robert Amezquita and Stephanie Hicks, the [simpleSingleCell workflow in Bioconductor](https://bioconductor.org/packages/3.9/workflows/html/simpleSingleCell.html) maintained by Aaron Lun, the [rnaseqGene workflow](https://bioconductor.org/packages/release/workflows/html/rnaseqGene.html) maintained by Michael Love, the [RNAseq123 workflow](https://bioconductor.org/packages/release/workflows/html/RNAseq123.html) maintained by Matthew Ritchie, and the [EGSEA123 workflow](https://bioconductor.org/packages/release/workflows/html/EGSEA123.html) maintained by Matthew Ritchie.

Other key resources are Bioconductor (Huber et al., Nature Methods 2015), [scRNA-tools](https://www.scrna-tools.org/), `scater` (McCarty et al., Bioinformatics 2017), `scran` (Lun et al. F1000Res 2016), `SC3` (Kiselev et al., Nature Methods 2017), `Seurat` (Butler et al., Nature Biotechnology 2018), `clusterExperiment` (Risso et al., PLOS Computational Biology 2018), `limma` (Ritchie et al., Nucleic Acids Research 2015), `DESeq2` (Love et al., Genome Biology 2014), `iSEE` (Rue-Albrecht & Marini et al., F1000Research 2018), `t-SNE` (van der Maaten & Hinton, Journal of Machine Learning Research 2008).

***

# Before we get Started
## Clean start - Delete user installed packages [optional]
If for whatever reason you need to start over because your packages stopped working, try running the following to delete all user installed packages and then proceed to reinstall everything from scratch (source: [How to remove all user installed packages in R](https://www.r-bloggers.com/how-to-remove-all-user-installed-packages-in-r/)):
```{r, echo=FALSE}
length(installed.packages())

# Create a list of all installed packages:
ip <- as.data.frame(installed.packages())
head(ip)

# If you use MRO, make sure that no packages in this library will be removed:
ip <- subset(ip, !grepl("MRO", ip$LibPath))

# We don't want to remove base or recommended packages either:
ip <- ip[!(ip[,"Priority"] %in% c("base", "recommended")),]

# Determine the library where the packages are installed:
path.lib <- unique(ip$LibPath)

# Create a vector with all the names of the packages you want to remove:
pkgs.to.remove <- ip[,1]
head(pkgs.to.remove)

# Remove the packages:
sapply(pkgs.to.remove, remove.packages, lib = path.lib)

length(installed.packages())
```

## Pre-required installation and necessary packages
To go through this pipeline, you will need to install the following: [R3.6.1](https://cran.r-project.org/) | [RTools35](https://cran.r-project.org/bin/windows/Rtools/) | [RStudio 1.1.463](https://www.rstudio.com/products/rstudio/download/) | [Git](https://git-scm.com/) | [Bioconductor 3.9](https://www.bioconductor.org/install/).

Before installing any packages, check that TLS1.0 is unchecked and both TLS1.1 and TLS1.2 are selected in _InternetOptions>Advanced_, otherwise you will have problems accessing the CRAN mirrors. If you go to Tools/Global Options/Packages, unselect both the "Use secure download method for HTTP" and the "Use Internet Explorer library/proxy for HTTP" options.

Once you have this, start an RStudio session and install the following packages by running the code in the console (not from the notebook chunk). You only need to install a package once, then you can load it using `library()`.
```{r}
# Consider setting stringsAsFactors=FALSE to make R read text as character data instead of factors. This must be done at the start of each R session:
options(stringsAsFactors = FALSE)

# Install packages from CRAN:
install.packages(c("backports", "boot", "blob", "devtools", "ggplot2", "gplots", "HTMLUtils", "hwriter", "metap", "parallel", "Rcpp" , "rmarkdown", "tidyverse"))
install.packages("stringi", configure.vars="ICUDT_DIR=<icudt_dir>")

# Install packages from github:
devtools::install_github("jlmelville/uwot")
devtools::install_github("iaconogi/bigSCale2")
devtools::install_github("tallulandrews/M3Drop")
devtools::install_github("SaskiaFreytag/schex")

# Install Bioconducor:
if (!requireNamespace("BiocManager"))
    install.packages("BiocManager")
library(BiocManager)

# Install packages from Bioconductor:
BiocManager::install(c("AnnotationDbi", "BiocNeighbors", "BiocParallel", "BiocStyle", "BioQC", "beachmat", "clusterExperiment", "DelayedArray", "DESeq2", "destiny", "edgeR", "EGSEA", "EGSEAdata", "gage", "GenomicRanges", "GenomeInfoDb", "ggfortify", "GO.db", "globaltest", "GSVA", "httpuv", "hgu133plus2.db", "hgu133a.db", "igraph", "iSEE", "KEGG.db", "knitr", "limma", "MAST", "matrixStats", "monocle", "MultiAssayExperiment", "mvoutlier", "org.Hs.eg.db", "org.Mm.eg.db", "org.Rn.eg.db", "PADOG", "pathview", "pheatmap", "purrr", "Rhdf5lib", "RSQLite", "Rtsne", "RUVSeq", "safe", "SC3", "scater", "scde", "scfind", "scmap", "SCnorm", "scran", "Seurat", "SingleCellExperiment", "SummarizedExperiment", "sva", "topGO", "TSCAN", "TxDb.Mmusculus.UCSC.mm10.ensGene", "umap", "uwot", "WGCNA"))
```

<!--
Other packages you could install, but I am not using here:
### Install FastQC
http://www.bioinformatics.babraham.ac.uk/projects/fastqc/fastqc_v0.11.5.zip
### Install Kallisto
https://github.com/pachterlab/kallisto/releases/download/v0.43.1/kallisto_linux-v0.43.1.tar.gz
### Install STAR
https://github.com/alexdobin/STAR.git
### Install SAMTools
https://github.com/samtools/samtools/releases/download/1.3.1/samtools-1.3.1.tar.bz2
### Install featureCounts
http://downloads.sourceforge.net/project/subread/subread-1.5.1/subread-1.5.1-Linux-x86_64.tar.gz
### Install cutadapt
pip3 install cutadapt
### Install TrimGalore
https://github.com/FelixKrueger/TrimGalore/archive/0.4.5.zip
### Install bedtools2
https://github.com/arq5x/bedtools2/releases/download/v2.27.1/bedtools-2.27.1.tar.gz
### install MAGIC
https://github.com/KrishnaswamyLab/MAGIC
-->

# STEP 0 | Set working directory
If we have been working in RStudio and want to empty the current workspace we can run `rm(list=ls())`. We can also restart the R Session, and clean the current console by pressing `ctrl+l`.
```{r}
# Set the directory where your data and/or scripts are:
setwd("D:/Dropbox (UCL - SWC)/Project_transcriptomics/analysis/PAG_scRNAseq_analysis")
```

# STEP 1 | Read Data and Metadata 
The first thing we will do is to load the data and metadata from a .txt/csv file, tidy it, and create a `SingleCellExperiment` object.

## Step 1.1 | Load data from .txt file
Our starting point is a gene expression matrix, a .txt/csv file where each column is a cell/sample, and each row a gene with its counts for any given cell. We load our data and inspect it:
```{r}
options(stringsAsFactors = FALSE)

# Load data:
PAG_data <- read.delim("PAG_scRNAseq_data_190704_Raw_Gene_counts.txt", 
                       sep="\t", header=TRUE, row.names=NULL)

# Inspect the data by printing the initial columns and rows:
PAG_data[1:10, 1:12]
```

## Step 1.2 | Load metadata from .csv file
We next load our metadata from a .csv file we have previously created and curated, with any relevant information we might use to identify our samples, assess the quality of the data, and remove sub-optimal cells. In this metadata file, each column should be a variable/piece of information (i.e. cell.id, animal.id, sequencing.batch), and each row a cell and its metadata.
```{r}
options(stringsAsFactors = FALSE)
PAG_metadata <- data.frame(read.table("PAG_scRNAseq_metadata_190704.csv", 
                                      sep=",", header=TRUE, row.names=NULL))
PAG_metadata[1:10,1:10]
```

We can add the `sequencing.id` column within the metadata to the `rownames` so we can later check that the `rownames` of the matadata (sample names) match that of the `colnames` of the data (also sample names, but obtained from the sequencing output):
```{r}
rownames(PAG_metadata) <- PAG_metadata$sequencing.id
PAG_metadata[1:10,1:10]
```

In addition, we can prepare another .csv file containing different lists of genes (i.e. ion channel genes, neuromodulator genes, etc.) we might later use for analysis.
```{r}
PAG_scRNAseq_gene_lists <- data.frame(read.table("PAG_scRNAseq_gene_lists.csv", sep=",", header=TRUE, row.names=NULL))
PAG_scRNAseq_gene_lists[1:10,1:10]
```

### One more thing...
Finally, we want to carefully consider the annotations from the metadata that we will need for our biological analysis. Are they numerical or categorical? Will we use them in downstream statistical modeling? Once we know the key ones, we can add them as a `factor`. For example, `PAG.area` or `cell.type` are clearly important and categorical, so specifically convert them to factors in the `PAG_metadata` object.

A longer discussion on `factors` can be found [here](https://www.stat.berkeley.edu/~s133/factors.html)
```{r}
PAG_metadata$date.collection <- as.factor(PAG_metadata$date.collection)
PAG_metadata$sample.number <- as.factor(PAG_metadata$sample.number)
PAG_metadata$mouse.id <- as.factor(PAG_metadata$mouse.id)
PAG_metadata$mouse.sex <- as.factor(PAG_metadata$mouse.sex)
PAG_metadata$cell.type <- as.factor(PAG_metadata$cell.type)
PAG_metadata$cell.fluorophor <- as.factor(PAG_metadata$cell.fluorophor)
PAG_metadata$slice.number <- as.factor(PAG_metadata$slice.number)
PAG_metadata$PAG.areacollection <- as.factor(PAG_metadata$PAG.areacollection)
PAG_metadata$PAG.hemisphere <- as.factor(PAG_metadata$PAG.hemisphere)
PAG_metadata$PAG.APaxis <- as.factor(PAG_metadata$PAG.APaxis)
PAG_metadata$time.slicing <- as.factor(PAG_metadata$time.slicing)
PAG_metadata$time.sinceslicinghour <- as.factor(PAG_metadata$time.sinceslicinghour)
PAG_metadata$RT.oligo <- as.factor(PAG_metadata$RT.oligo)
PAG_metadata$RT.date <- as.factor(PAG_metadata$RT.date)
PAG_metadata$RT.machine <- as.factor(PAG_metadata$RT.machine)
PAG_metadata$RT.time <- as.factor(PAG_metadata$RT.time)
PAG_metadata$preamp.date <- as.factor(PAG_metadata$preamp.date)
PAG_metadata$preamp.machine <- as.factor(PAG_metadata$preamp.machine)
PAG_metadata$preamp.time <- as.factor(PAG_metadata$preamp.time)
PAG_metadata$date.purification <- as.factor(PAG_metadata$date.purification)
PAG_metadata$date.nanodrop <- as.factor(PAG_metadata$date.nanodrop)
PAG_metadata$date.qubit <- as.factor(PAG_metadata$date.qubit)
PAG_metadata$date.bioanalyzer <- as.factor(PAG_metadata$date.bioanalyzer)
PAG_metadata$batch.sequencing_round <- as.factor(PAG_metadata$batch.sequencing_round)
table(PAG_metadata$mouse.sex)
table(PAG_metadata$cell.type)
```

Some useful functions to examine the metadata:
```{r}
class(PAG_metadata$mouse.sex)
class(PAG_metadata$slice.depth)
class(PAG_metadata$sample.id)

# Useful factor functions:
table(PAG_metadata$PAG.areacollection)
levels(PAG_metadata$mouse.id)
```

## Step 1.3 | Tidy up data
Once we have loaded the data, we have to clean it and tidy it up a bit. We want to assign gene IDs to `rownames` and move any unnecessary columns from data to a separate variable.

We can see that the seventh column in the data table contains the gene ENSEMBL IDs, and that the eleventh column has the first sequenced cell, whereas the previous columns have extra information added by the sequencing facility such as the chromosome each gene belongs to and the type of gene we have.

We first move the gene IDs to the `rownames`:
```{r}
# Add gene IDs to row names:
rownames(PAG_data) <- PAG_data$gene_id

# Inspect what you have done and retrieve the dimensions of the object:
PAG_data[1:10, 1:12]
dim(PAG_data)
```

We next store the initial columns (chromosome, start, stop, gene symbol, etc.) into a new variable so we can assign them to `rowRanges` and `rowData` (just in case we can use them in downstream analysis, we don't want to discard anything yet). We then remove them from the dataset so that we end up with a tidy count matrix:
```{r}
# Copy unnecessary columns:
PAG_gene_information <- PAG_data[,c(1:10)]
rownames(PAG_gene_information) <- rownames(PAG_data)
PAG_data[1:10, 1:12]

# Delete unnecessary columns from data object:
PAG_data <- PAG_data[,-c(1:10)]
PAG_data[1:10, 1:12]
PAG_gene_information[1:10, 1:10]
dim(PAG_data)
```

We also want to fix the current sample names stored in `colnames(PAG_data)`. Initially, each cell has the following id `GC.OP.7836.EBRAligned.sortedByCoord.out`. From this, we only care about the four-letter, four-digit number (ID of the sequencing project added by the facility, `GC.OP.7836`) and the three-letter code (ID of the cell added by us, `EBR`), which should match our `PAG_metadata$cell.id` (something we will check a few steps from now). To clean the current sample names, we can use the `stringr` package to remove the second half of the string. We also assign the cleaner sample names to a separate variable to later check against `PAG_metadata$cell.id`:
```{r}
library(stringr)
colnames(PAG_data) <- lapply(colnames(PAG_data), function(x){str_remove(x, "Aligned.sortedByCoord.out")})

# Save the column names (the cell IDs as given by the sequencing facility) for a later sanity check to confirm that the cell.ids from the .txt file provided by the sequencing facility match those in our metadata file:
sequencing_id_QMUL <- colnames(PAG_data)
PAG_data[1:10, 1:12]
```

We have now moved the gene names to `rownames`, removed unnecessary columns so that we are left with a clean expression matrix, and cleaned the names in `colnames(PAG_data)`. Before we move on, we can calculate the gene lengths (we could potentially use them for normalization purposes, although there are better methods to do this and we will not be using gene lengths here).
```{r}
# Calculate gene length and store in a new column:
PAG_gene_information$gene_length <- PAG_gene_information$Stop - PAG_gene_information$Start
head(PAG_gene_information$gene_length)
```

## Step 1.4 | Tidy up metadata
One thing we want to make sure of is that the order of the metadata actually matches with the expression matrix. One way to enforce ordering is to use the `match()` command to ensure the ordering of metadata rows are the same as the ordering of count columns. `match()` will give us an integer vector with the position in table of the first match if there is a match, otherwise will give us nomatch: If x[i] is found to equal table[j] then the value returned in the i-th position of the return value is j, for the smallest possible j. If no match is found, the value is nomatch.
```{r}
# Data column names and metadata row names should match:
right_order <- match(colnames(PAG_data), rownames(PAG_metadata))

# Check that nothing is missing:
stopifnot(all(!is.na(right_order)))

# Sort the metadata so it matches the data:
PAG_metadata <- PAG_metadata[right_order,]
head(PAG_metadata)
```

Now that we are certain our data and metadata are in the same order, we want to check whether the `sequencing_id_QMUL` we extracted from the original .txt file the sequencing facility provided matches the `cell.id` from our metadata, just to be sure that it is safe to use the `cell.id` from the metadata as `colnames` of the `PAG_data`.

Initially, each cell has the following id `GC.OP.7836.EBRAligned.sortedByCoord.out`, from which we already removed the unnecessary "Aligned.sortedByCoord.out" and assigned to `sequencing_id_QMUL`. From this, we want to extract the four-digit number (ID of the sequencing project added by the facility) and the three-letter code (ID of the cell added by us), which should match our `PAG_metadata$cell.id` and which we want to isolate and assign to `colnames(PAG_metadata)`, instead of the long code from the facility. To do this, we can use the `sequencing_id_QMUL` variable we stored at the beginning, which was extracted from the original `colnames(PAG_data)` in the expression matrix:
```{r}
library(stringr)
# Split the string "GC.OP.7836.EBR" at each dot:
cell_id_QMUL <- strsplit(sequencing_id_QMUL, "\\.") 

# Get the third element "7836" and assign it to the sequencing batch slot in the metadata:
sequencing_QMUL <- lapply(cell_id_QMUL, function(x){x[3]})
batch.sequencing_QMUL <- data.frame(round=matrix(unlist(sequencing_QMUL)))

PAG_metadata$batch.sequencing_QMUL <- batch.sequencing_QMUL$round # Add it to metadata
PAG_metadata$batch.sequencing_QMUL <- as.factor(PAG_metadata$batch.sequencing_QMUL) # Convert to factor

# Get the fourth element "EBR" and keep the only three-letter code that forms the cell.id:
cell_id_QMUL <- lapply(cell_id_QMUL, function(x){x[4]})

# Check that the PAG_metadata$cell.id and the cell.id_QMUL match and are in the same order. If they match and are in the same order, the following should print the a number of TRUE values equal to the number of samples in the dataset:
table(match(cell_id_QMUL, PAG_metadata$cell.id) == 1:length(cell_id_QMUL))
dim(PAG_data)
```

Now that we are certain the Cell IDs we assigned each cell at the collection stage (`PAG_metadata$cell.id`) match the IDs in the expression matrix provided by the sequencing facility (`cell_id_QMUL` and `colnames(PAG_data)`), we can make things a bit more consistent by using them to identify both the `colnames` of the data and the `rownames` of the metadata:
```{r}
# From the metadata, add the three-letter code that identifies each cell (cell.id column) to the column names of the data:
colnames(PAG_data) <- PAG_metadata$cell.id
PAG_data[1:10,1:10]

# Add that same three-letter code that identifies each cell to the row names of the metadata:
rownames(PAG_metadata) <- colnames(PAG_data)
PAG_metadata[1:10,1:10]
```

## Step 1.5 | Add gene-based annotations
We can add gene-based annotation by pulling the annotation from `org.Mm.eg.db` to relate the ENSEMBL identifiers to gene symbols. The `mapIds()` function ensures that only one gene symbol is returned if two symbols map to the same ENSEMBL ID.
```{r}
library(org.Mm.eg.db)
gene_symbols <- mapIds(org.Mm.eg.db, keys=rownames(PAG_data), 
                       keytype ="ENSEMBL", column="SYMBOL")
PAG_gene_annotations <- data.frame(ENSEMBL=rownames(PAG_data), 
                                   gene_symbols=gene_symbols, 
                                   stringsAsFactors=FALSE)
head(PAG_gene_annotations)
```

We can also identify which rows correspond to mitochondrial genes. To do that we need to use extra annotation describing the genomic location of each gene. For ENSEMBL, this involves using the `TxDb.Mmusculus.UCSC.mm10.ensGene` package.
```{r}
library(TxDb.Mmusculus.UCSC.mm10.ensGene)
gene_location <- mapIds(TxDb.Mmusculus.UCSC.mm10.ensGene, keys=rownames(PAG_data), 
                        column="CDSCHROM", keytype="GENEID")
PAG_gene_annotations$Chromosome <- gene_location
```

We can finally add the annotations from the `mapIds()` function to the already existing `PAG_gene_information` variable to have everything in the same place.
```{r}
PAG_gene_information$gene_name_mapids <- PAG_gene_annotations$gene_symbols
PAG_gene_information$gene_chromosome_mapids <- PAG_gene_annotations$Chromosome
head(PAG_gene_information$gene_name_mapids)
```

In our case, however, the information provided by the Genome Centre Sequencing Facility is more complete than what we obtain with `mapIds()` and includes the transgenes we used to label cells and ERCC spike-ins, so we will stick to that one.

## Step 1.6 | Build a SingleCellExperiment object
We have now loaded both the data and the metadata. The next step is to create an object of the `SingleCellExperiment` class for downstream analysis. For an introduction to the `SingleCellExperiment` class see [Orchestrating Single-Cell Analysis with Bioconductor book](https://osca.bioconductor.org/data-infrastructure.html) by Robert Amezquita and Stephanie Hicks.

* The `assays` slot in a `SingleCellExperiment` object contains primary data such as counts in a list, where each entry of the list is in a matrix format, where rows correspond to features (genes) and columns correspond to samples (cells). We can extend the `assays` slot: `counts` are intended to be used for raw counts, but we can also have `logcounts` and other transformed values for normalized data (we will compute them in next steps).

* The `colData` slot is designed for metadata that describe the samples (cells) provided as a `data.frame`, where rows correspond to cells, and columns correspond to the sample (cells) metadata features (e.g. id, batch, date, etc.). Furthermore, `colData` can be used for subsetting (e.g. `PAG_sceset[, PAG_sceset$cell.type==VGAT]` or `PAG_sceset$cell.id`).

* The rows also have their own metadata slot to store information that pertains to the features of the `SingleCellExperiment` object: the `rowData` slot contains data in a `data.frame` format that describes aspects of the data corresponding to the rows of the primary data, whereas the `rowRanges` slot contains data in a `GRangesList` (where each entry is a `GenomicRanges` format) that describes the chromosome, strand, and start/end coordinates of the features (genes, genomic regions).

* The `sizeFactors` slot contains information in a numeric vector regarding the sample/cell normalization factors used to produce a normalized data representation, whereas the `reducedDims` slot contains a list of numeric matrix entries which describe dimensionality reduced representations of the primary data, such that rows represent the columns of the primary data (a.k.a. the samples/cells), and columns represent the dimensions. Just like the `assays` slot, the `reducedDims` slot can hold a list of many entries like a PCA, TSNE, and UMAP representation of a given dataset all within the `reducedDims` slot.

* Some analyses produce results that do not fit into the aforementioned slots. `SingleCellExperiment` has a slot just for this type of messy data that can accommodate any type of data, as long as it is in a named list. This is the `metadata` slot, a named list of entries, where each entry in the list can be anything you want it to be (for instance, a list of favorite genes, such as highly variable genes, that we want to save inside of our `SingleCellExperiment` object for use in our analysis at a later point).
```{r}
# Create a SingleCellExperiment object
library(SingleCellExperiment)
PAG_sceset <- SingleCellExperiment(assays = list(counts = as.matrix(PAG_data)),
                                   colData = PAG_metadata, 
                                   rowData = PAG_gene_information,
                                   metadata = PAG_scRNAseq_gene_lists
                                   )
PAG_sceset
```

```{r}
# Different ways to inspect the object:
#PAG_sceset
#assays(PAG_sceset)
#colData(PAG_sceset)
#rowData(PAG_sceset)
#summary(metadata(PAG_sceset))

# You can get the counts using str() => structure of the object
#str(counts(PAG_sceset))
```

Save the `SingleCellExperiment` object so you don't have to repeat all these steps again:
```{r}
saveRDS(PAG_sceset, file = "PAG_sceset.rds")
print("Part 1 - Done!")
```
---
title: "Topographic, single-cell gene expression profiling of Periaqueductal Gray neurons"
subtitle: "Part I: from a gene expression matrix to a SingleCellExperiment object"
author:
  - name: "Oriol Pavon Arocas, Sarah F. Olesen, and Tiago Branco"
    affiliation: "Sainsbury Wellcome Centre for Neural Circuits and Behaviour, University College London, UK"
    email: "oriol.pavon.16@ucl.ac.uk"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_notebook:
    highlight: pygments
    number_sections: FALSE
    theme: lumen
    toc: TRUE
    toc_float: TRUE

#output: rmdformats::readthedown:
  #highlight: pygments
---

***

This is a pipeline to analyse single-cell RNA sequencing data from Periaqueductal Gray neurons (1) isolated from acute midbrain slices of transgenic mice using visually guided aspiration via patch pipettes and (2) processed using SMART-seq2 (Picelli et al., Nature Protocols 2014). 

This pipeline has been generated after attending the [EMBL-EBI RNA-Sequence Analysis Course](https://www.ebi.ac.uk/training/events/2019/rna-sequence-analysis) and [attending](https://training.csx.cam.ac.uk/bioinformatics/event/2823386) and following the online course on [Analysis of single cell RNA-seq data](https://github.com/hemberg-lab/scRNA.seq.course) by the [Hemberg Lab](https://www.sanger.ac.uk/science/groups/hemberg-group). Many other resources have been used, including the [Orchestrating Single-Cell Analysis with Bioconductor book](https://osca.bioconductor.org/) by Robert Amezquita and Stephanie Hicks, the [simpleSingleCell workflow in Bioconductor](https://bioconductor.org/packages/3.9/workflows/html/simpleSingleCell.html) maintained by Aaron Lun, the [rnaseqGene workflow](https://bioconductor.org/packages/3.10/workflows/html/rnaseqGene.html) maintained by Michael Love, the [RNAseq123 workflow](https://bioconductor.org/packages/3.10/workflows/html/RNAseq123.html) maintained by Matthew Ritchie, and the [EGSEA123 workflow](https://bioconductor.org/packages/3.10/workflows/html/EGSEA123.html) maintained by Matthew Ritchie.

Other key resources include [Bioconductor](http://www.bioconductor.org/) (Huber et al., Nature Methods 2015), [scRNA-tools](https://www.scrna-tools.org/), `scater` (McCarthy et al., Bioinformatics 2017), `scran` (Lun et al., F1000Res 2016), `SC3` (Kiselev et al., Nature Methods 2017), `Seurat` (Butler et al., Nature Biotechnology 2018), `clusterExperiment` (Risso et al., PLOS Computational Biology 2018), `limma` (Ritchie et al., Nucleic Acids Research 2015), `DESeq2` (Love et al., Genome Biology 2014), `edgeR` (Robinson et al., Bioinformatics 2010), `MAST` (Finak, McDavid, Yajima et al., Genome Biology 2015), `iSEE` (Rue-Albrecht & Marini et al., F1000Research 2018), `t-SNE` (van der Maaten & Hinton, Journal of Machine Learning Research 2008), `UMAP` (McInnes et al., arXiv 2018), and the [Mathematical Statistics and Machine Learning for Life Sciences](https://towardsdatascience.com/tagged/stats-ml-life-sciences) column by Nikolay Oskolkov.

***

# Getting started
Consider uncommenting and running the following lines of code if necessary.

## Clean start - Delete user installed packages [optional]
If for whatever reason you need to start over because your packages stopped working, try running the following lines to delete all user installed packages and then proceed to reinstall everything from scratch (source: [How to remove all user installed packages in R](https://www.r-bloggers.com/how-to-remove-all-user-installed-packages-in-r/)).
```{r, echo=FALSE}
# length(installed.packages())
# 
# # Create a list of all installed packages:
# ip <- as.data.frame(installed.packages())
# head(ip)
# 
# # If you use MRO, make sure that no packages in this library will be removed:
# ip <- subset(ip, !grepl("MRO", ip$LibPath))
# 
# # We don't want to remove base or recommended packages either:
# ip <- ip[!(ip[,"Priority"] %in% c("base", "recommended")),]
# 
# # Determine the library where the packages are installed:
# path.lib <- unique(ip$LibPath)
# 
# # Create a vector with all the names of the packages you want to remove:
# pkgs.to.remove <- ip[,1]
# head(pkgs.to.remove)
# 
# # Remove the packages:
# sapply(pkgs.to.remove, remove.packages, lib = path.lib)
# 
# length(installed.packages())
```

## Pre-required installation and necessary packages
To go through this pipeline, you will need to install the following: [R3.6.1](https://cran.r-project.org/) | [RTools35](https://cran.r-project.org/bin/windows/Rtools/) | [RStudio 1.1.463](https://www.rstudio.com/products/rstudio/download/) | [Git](https://git-scm.com/) | [Bioconductor 3.10](https://www.bioconductor.org/install/).

Before installing any packages on Windows, check that TLS1.0 is unchecked and both TLS1.1 and TLS1.2 are selected in _InternetOptions>Advanced_, otherwise you will have problems accessing the CRAN mirrors. If you go to Tools/Global Options/Packages, unselect both the "Use secure download method for HTTP" and the "Use Internet Explorer library/proxy for HTTP" options.

Once you have this, start an RStudio session and install the following packages by *running the code in the console (not from the notebook chunk)*. You only need to install a package once, then you can load it using `library()`.
```{r}
# # Consider setting stringsAsFactors=FALSE to make R read text as character data instead of factors. This must be done at the start of each R session:
# options(stringsAsFactors = FALSE)
# 
# # Install packages from CRAN:
# install.packages(c("backports", "boot", "blob", "dbscan", "devtools", "ggplot2", "gplots", "HTMLUtils", "hwriter", "igraph", "knitr", "metap", "parallel", "Rcpp" , "rmarkdown", "tidyverse", "uwot"))
# install.packages("stringi", configure.vars="ICUDT_DIR=<icudt_dir>")
# 
# # Install Bioconducor:
# install.packages("BiocManager")
# library(BiocManager)
# 
# # Install packages from Bioconductor:
# BiocManager::install(c("AnnotationDbi", "AnnotationHub", "apeglm", "BiocNeighbors", "BiocParallel", "BiocStyle", "BioQC", "beachmat", "clusterExperiment", "DelayedArray", "dendextend", "DESeq2", "destiny", "edgeR", "EGSEA", "EGSEAdata", "ensembldb", "gage", "GenomicRanges", "GenomeInfoDb", "ggfortify", "GO.db", "globaltest", "GSVA", "httpuv", "hgu133plus2.db", "hgu133a.db", "igraph", "iSEE", "KEGG.db", "limma", "M3Drop", "MAST", "matrixStats", "monocle", "MultiAssayExperiment", "mvoutlier", "org.Hs.eg.db", "org.Mm.eg.db", "org.Rn.eg.db", "PADOG", "pathview", "PCAtools", "pheatmap", "purrr", "Rhdf5lib", "RSQLite", "Rtsne", "RUVSeq", "safe", "SC3", "scater", "scde", "scfind", "schex", "scmap", "SCnorm", "scran", "Seurat", "SingleCellExperiment", "SingleR", "SummarizedExperiment", "sva", "topGO", "TSCAN", "TxDb.Mmusculus.UCSC.mm10.ensGene", "umap", "uwot", "WGCNA"))
# 
# # Install packages from github:
# library(devtools)
# devtools::install_github("iaconogi/bigSCale2")
```

<!--
Other packages you could install, but I am not using here:
### Install FastQC
http://www.bioinformatics.babraham.ac.uk/projects/fastqc/fastqc_v0.11.5.zip
### Install Kallisto
https://github.com/pachterlab/kallisto/releases/download/v0.43.1/kallisto_linux-v0.43.1.tar.gz
### Install STAR
https://github.com/alexdobin/STAR.git
### Install SAMTools
https://github.com/samtools/samtools/releases/download/1.3.1/samtools-1.3.1.tar.bz2
### Install featureCounts
http://downloads.sourceforge.net/project/subread/subread-1.5.1/subread-1.5.1-Linux-x86_64.tar.gz
### Install cutadapt
pip3 install cutadapt
### Install TrimGalore
https://github.com/FelixKrueger/TrimGalore/archive/0.4.5.zip
### Install bedtools2
https://github.com/arq5x/bedtools2/releases/download/v2.27.1/bedtools-2.27.1.tar.gz
### install MAGIC
https://github.com/KrishnaswamyLab/MAGIC
-->

# STEP 0 | Set working directory
If we have been working in RStudio and want to empty the current workspace we can run `rm(list=ls())`. We can also restart the R Session, and clean the current console by pressing `ctrl+l`. We start by setting up the directory where the data is:
```{r}
# Set the directory where your data and scripts are:
setwd("D:/Dropbox (UCL - SWC)/Project_transcriptomics/analysis/PAG_scRNAseq_analysis")
```

# STEP 1 | Read Data and Metadata 
The first thing we will do is to load the data and metadata from a .txt/csv file, tidy it, and create a `SingleCellExperiment` object.

## Step 1.1 | Load data from .txt file
Our starting point is a gene expression matrix, a .txt/csv file where each column is a cell/sample, and each row a gene with its counts for any given cell. We load our data and inspect it:
```{r}
options(stringsAsFactors = FALSE)
# Load data:
PAG_data <- read.delim("PAG_scRNAseq_data_190704_Raw_Gene_counts.txt", 
                       sep = "\t", header = TRUE, row.names = NULL)
# Inspect the data by printing the initial columns and rows:
PAG_data[1:10, 1:12]
```

## Step 1.2 | Load metadata from .csv file
We next load our metadata from a .csv file we have previously created and curated, with any relevant information we might use to identify our samples, assess the quality of the data, and remove sub-optimal cells. In this metadata file, each column should be a variable/piece of information (i.e. cell.id, animal.id, sequencing.batch), and each row a cell and its metadata.
```{r}
options(stringsAsFactors = FALSE)
PAG_metadata <- data.frame(read.table("PAG_scRNAseq_metadata_190704.csv", 
                                      sep = ",", header = TRUE, row.names = NULL))
PAG_metadata[1:10,1:10]
```

We can add the `sequencing.id` column within the metadata to the `rownames` so we can later check that the `rownames` of the matadata (sample names) match that of the `colnames` of the data (also sample names, but obtained from the sequencing output):
```{r}
rownames(PAG_metadata) <- PAG_metadata$sequencing.id
PAG_metadata[1:10,1:10]
```

In addition, we can prepare another .csv file containing several manually curated lists of genes (i.e. ion channel genes, neuromodulator genes, etc.) we may later use for analysis.
```{r}
PAG_scRNAseq_gene_lists <- data.frame(read.table("PAG_scRNAseq_gene_lists.csv",
                                                 sep = ",", header = TRUE, row.names = NULL))
PAG_scRNAseq_gene_lists[1:10,1:10]
```

Finally, we want to carefully consider the annotations from the metadata that we will need for our biological analysis. Are they numerical or categorical? Will we use them in downstream statistical modeling? Once we know the key ones and how we will use them, we can add them as a `factor`. For example, `PAG.area` or `cell.type` are clearly important and categorical, so we specifically convert them to factors in the `PAG_metadata` object. We can also establish the order for the factor levels and even create new metadata factors from existing ones.

A longer discussion on `factors` can be found [here](https://www.stat.berkeley.edu/~s133/factors.html).
```{r}
PAG_metadata$date.collection <- as.factor(PAG_metadata$date.collection)
PAG_metadata$sample.number <- as.factor(PAG_metadata$sample.number)
PAG_metadata$mouse.id <- as.factor(PAG_metadata$mouse.id)
PAG_metadata$mouse.sex <- as.factor(PAG_metadata$mouse.sex)
PAG_metadata$mouse.age <- as.factor(PAG_metadata$mouse.age)
PAG_metadata$mouse.singlehousedays <- as.factor(PAG_metadata$mouse.singlehousedays)
PAG_metadata$cell.type <- as.factor(PAG_metadata$cell.type)
PAG_metadata$cell.fluorophor <- as.factor(PAG_metadata$cell.fluorophor)
PAG_metadata$patch.recorded <- as.factor(PAG_metadata$patch.recorded)
PAG_metadata$pipette.RNAseOUT <- as.factor(PAG_metadata$pipette.RNAseOUT)
PAG_metadata$slice.number <- as.factor(PAG_metadata$slice.number)
PAG_metadata$PAG.areacollection <- as.factor(PAG_metadata$PAG.areacollection)
PAG_metadata$PAG.hemisphere <- as.factor(PAG_metadata$PAG.hemisphere)
PAG_metadata$PAG.APaxis <- as.factor(PAG_metadata$PAG.APaxis)
PAG_metadata$PAG.arearegistration <- as.factor(PAG_metadata$PAG.arearegistration)
PAG_metadata$time.slicing <- as.factor(PAG_metadata$time.slicing)
PAG_metadata$time.sinceslicinghour <- as.factor(PAG_metadata$time.sinceslicinghour)
PAG_metadata$batch.processing <- factor(PAG_metadata$batch.processing, 
                                        levels = c("nb1", "nb2", "nb3", "nb4", "nb5", "nb6", "nb7", "nb8", "nb9", "nb10", "nb11",
                                                   "b1", "b2", "b3", "b4", "b5", "b6", "b7", "b8", "b9", "b10", "b11", "b12"))
levels(PAG_metadata$batch.processing)
PAG_metadata$RT.oligo <- as.factor(PAG_metadata$RT.oligo)
PAG_metadata$RT.date <- as.factor(PAG_metadata$RT.date)
PAG_metadata$RT.machine <- as.factor(PAG_metadata$RT.machine)
PAG_metadata$RT.time <- as.factor(PAG_metadata$RT.time)
PAG_metadata$preamp.date <- as.factor(PAG_metadata$preamp.date)
PAG_metadata$preamp.machine <- as.factor(PAG_metadata$preamp.machine)
PAG_metadata$preamp.time <- as.factor(PAG_metadata$preamp.time)
PAG_metadata$date.purification <- as.factor(PAG_metadata$date.purification)
PAG_metadata$date.nanodrop <- as.factor(PAG_metadata$date.nanodrop)
PAG_metadata$date.qubit <- as.factor(PAG_metadata$date.qubit)
PAG_metadata$date.bioanalyzer <- as.factor(PAG_metadata$date.bioanalyzer)
PAG_metadata$batch.sequencing_round <- as.factor(PAG_metadata$batch.sequencing_round)
table(PAG_metadata$mouse.sex)
table(PAG_metadata$cell.type)

# By default, R will choose a reference level for factors based on alphabetical order. We can relevel any metadata factor as follows:
levels(PAG_metadata$PAG.areacollection)
PAG_metadata$PAG.areacollection <- relevel(PAG_metadata$PAG.areacollection, ref = "dmpag")
levels(PAG_metadata$PAG.areacollection)

levels(PAG_metadata$PAG.arearegistration)
PAG_metadata$PAG.arearegistration <- relevel(PAG_metadata$PAG.arearegistration, ref = "dmpag")
levels(PAG_metadata$PAG.arearegistration)

# We will also create an extra metadata factor by combining both cell.type and PAG.arearegistration, which we will use during the differential expression analysis:
PAG_metadata$PAGarea_celltype <- factor(paste0(PAG_metadata$PAG.arearegistration, "_", PAG_metadata$cell.type),
                                        levels = c("dmpag_VGAT", "dlpag_VGAT", "lpag_VGAT", "vlpag_VGAT", "dmpag_VGluT2",  "dlpag_VGluT2", "lpag_VGluT2", "vlpag_VGluT2"))
levels(PAG_metadata$PAGarea_celltype)
table(PAG_metadata$PAGarea_celltype)
```

Some useful functions to examine the metadata:
```{r}
class(PAG_metadata$mouse.sex)
class(PAG_metadata$slice.depth)
class(PAG_metadata$sample.id)

# Useful factor functions:
table(PAG_metadata$PAG.arearegistration)
levels(PAG_metadata$mouse.id)
```

## Step 1.3 | Tidy up data
Once we have loaded the data, we have to clean it and tidy it up a bit. We want to assign gene IDs to `rownames` and move any unnecessary columns from data to a separate variable.

From the previous steps we can see that the seventh column in the data table contains the gene ENSEMBL IDs, and that the eleventh column has the first sequenced cell, whereas the previous columns have extra information added by the sequencing facility such as the chromosome each gene belongs to and the type of gene we have.

We will first move the gene IDs to the `rownames` so we can easily identify which gene belongs to each row. We can stick with the ENSEMBL IDs for now:
```{r}
# Add gene IDs to row names:
rownames(PAG_data) <- PAG_data$gene_id

# Inspect what you have done and retrieve the dimensions of the object:
PAG_data[1:10, 1:12]
dim(PAG_data)
```

We next store the initial columns (chromosome, start, stop, gene symbol, etc.) into a new variable so we can assign them to `rowRanges` and `rowData` (just in case we can use them in downstream analysis, we don't want to discard anything yet). We then remove them from the dataset so that we end up with a tidy count matrix, where the number of columns should now match the number of samples in our dataset:
```{r}
# Copy unnecessary columns:
PAG_gene_information <- PAG_data[,c(1:10)]
rownames(PAG_gene_information) <- rownames(PAG_data)
PAG_data[1:10, 1:12]

# Delete unnecessary columns from data object:
PAG_data <- PAG_data[,-c(1:10)]
PAG_data[1:10, 1:12]
PAG_gene_information[1:10, 1:10]
dim(PAG_data)
```

We also want to fix the current sample names stored in `colnames(PAG_data)`. Initially, each cell has the following id `GC.OP.7836.EBRAligned.sortedByCoord.out`. From this, we only care about the four-letter, four-digit number (the ID of the sequencing project added by the facility, `GC.OP.7836`) and the three-letter code (the ID of the cell assigned by us upon collection, `EBR`), which should match our `PAG_metadata$cell.id` (something we will validate a few steps from now). To clean the current sample names, we can use the `stringr` package to remove the second half of the string. We can also assign the cleaner sample names to a separate variable to do a later sanity check against `PAG_metadata$cell.id`:
```{r}
library(stringr)
colnames(PAG_data) <- lapply(colnames(PAG_data), function(x){str_remove(x, "Aligned.sortedByCoord.out")})

# Save the column names (the cell IDs as given by the sequencing facility) for a later sanity check to confirm that the cell.ids from the .txt file provided by the sequencing facility match those in our metadata file:
sequencing_id_QMUL <- colnames(PAG_data)
PAG_data[1:10, 1:12]
```

We have now moved the gene names to `rownames`, removed unnecessary columns so that we are left with a clean expression matrix, and cleaned the names in `colnames(PAG_data)`. Before we move on, we can calculate the gene lengths (something we could potentially use for normalization purposes, although there are better methods to do this and we will not be using gene lengths here).
```{r}
# Calculate gene length and store in a new column:
PAG_gene_information$gene_length <- PAG_gene_information$Stop - PAG_gene_information$Start
head(PAG_gene_information$gene_length)
```

## Step 1.4 | Tidy up metadata
An extremely important thing we want to make sure of is that the order of the metadata actually matches that of the expression matrix. One way to enforce ordering is to use the `match()` command to ensure the ordering of metadata rows are the same as the ordering of expression matrix columns. `match()` will give us an integer vector with the position in table of the first match if there is a match, otherwise will give us `nomatch`: _If x[i] is found to be equal to table[j] then the value returned in the i-th position of the return value is j, for the smallest possible j. If no match is found, the value is nomatch._
```{r}
# Data column names and metadata row names should match:
right_order <- match(colnames(PAG_data), rownames(PAG_metadata))

# Check that nothing is missing:
stopifnot(all(!is.na(right_order)))

# Sort the metadata so it matches the data:
PAG_metadata <- PAG_metadata[right_order,]
head(PAG_metadata)
```

Now that we are certain our data and metadata are in the same order, we want to check whether the `sequencing_id_QMUL` we extracted from the original .txt file the sequencing facility provided us with matches the `cell.id` from our metadata, just to be sure that it is safe to use the `cell.id` from the metadata as `colnames` of `PAG_data`.

Initially, each cell has the following id `GC.OP.7836.EBRAligned.sortedByCoord.out`, from which we already removed the unnecessary "Aligned.sortedByCoord.out" and assigned the rest to `sequencing_id_QMUL`. From this, we now want to extract the four-digit number (ID of the sequencing project added by the facility) and the three-letter code (ID of the cell added by us), which should match our `PAG_metadata$cell.id`. We want to isolate this three-letter code and assign it to `colnames(PAG_metadata)`, instead of the long code assigned by the sequencing facility. To do this, we can use the `sequencing_id_QMUL` variable we stored at the beginning, which was extracted from the original `colnames(PAG_data)` in the expression matrix:
```{r}
library(stringr)
# Split the string "GC.OP.7836.EBR" at each dot:
cell_id_QMUL <- strsplit(sequencing_id_QMUL, "\\.") 

# Get the third element "7836" and assign it to the sequencing batch slot in the metadata:
sequencing_QMUL <- lapply(cell_id_QMUL, function(x){x[3]})
batch.sequencing_QMUL <- data.frame(round = matrix(unlist(sequencing_QMUL)))

PAG_metadata$batch.sequencing_QMUL <- batch.sequencing_QMUL$round # Add it to metadata
PAG_metadata$batch.sequencing_QMUL <- as.factor(PAG_metadata$batch.sequencing_QMUL) # Convert to factor

# Get the fourth element "EBR" and keep the only three-letter code that forms the cell.id:
cell_id_QMUL <- lapply(cell_id_QMUL, function(x){x[4]})

# Check that the PAG_metadata$cell.id and the cell.id_QMUL match and are in the same order. If they match and are in the same order, the following should print a number of TRUE values equal to the number of samples in the dataset:
table(match(cell_id_QMUL, PAG_metadata$cell.id) == 1:length(cell_id_QMUL))
dim(PAG_data)
```

Now that we are certain the Cell IDs we assigned each cell at the collection stage (`PAG_metadata$cell.id`) match the IDs in the expression matrix provided by the sequencing facility (`cell_id_QMUL` and `colnames(PAG_data)`), we can make things a bit more consistent by using them to identify both the `colnames` of the data and the `rownames` of the metadata:
```{r}
# From the metadata, add the three-letter code that identifies each cell (cell.id column) to the column names of the data:
colnames(PAG_data) <- PAG_metadata$cell.id
PAG_data[1:10,1:10]

# Add that same three-letter code that identifies each cell to the row names of the metadata:
rownames(PAG_metadata) <- colnames(PAG_data)
PAG_metadata[1:10,1:10]
```

## Step 1.5 | Add gene-based annotations
Until now, we have had ENSMBL IDs to identify the genes and rows in our expression matrix. ENSEMBL identifiers are stable but difficult to interpret compared to the gene symbols. We can obtain the symbols corresponding to each ENSEMBL ID using the relevant annotation package. The `mapIds()` function ensures that only one gene symbol is returned if two symbols map to the same ENSEMBL ID. We can also identify which rows correspond to mitochondrial genes by making use of the chromosome information associated with each gene ID. To do that we need to use extra annotation describing the genomic location of each gene. Later on, we will be able to use this information to rename the rows of our `SingleCellExperiment` with the symbols, reverting to ENSEMBL identifiers for missing or duplicate symbols.
```{r}
library(AnnotationHub)
ah <- AnnotationHub()
ens.mm.v97 <- ah[["AH73905"]]

gene_symbols <- mapIds(ens.mm.v97, keys = rownames(PAG_data), 
                       keytype = "GENEID", column = "SYMBOL")
gene_location <- mapIds(ens.mm.v97, keys = rownames(PAG_data), 
                        keytype = "GENEID", column = "SEQNAME")

PAG_gene_annotations <- data.frame(ENSEMBL = rownames(PAG_data), 
                                   gene_symbols = gene_symbols,
                                   gene_location = gene_location,
                                   stringsAsFactors = FALSE)
head(PAG_gene_annotations)
```

We can finally add the annotations from the `mapIds()` function to the already existing `PAG_gene_information` variable to have everything in the same place.
```{r}
PAG_gene_information$gene_name_mapids <- PAG_gene_annotations$gene_symbols
PAG_gene_information$gene_chromosome_mapids <- PAG_gene_annotations$gene_location

head(PAG_gene_information)
table(PAG_gene_information$Chromosome)
table(PAG_gene_information$gene_chromosome_mapids)

which(PAG_gene_information$Chromosome == "M")
which(PAG_gene_information$gene_chromosome_mapids == "MT")
```

As we can see from the output of the `table()` commands, in our case the information provided by the Genome Centre Sequencing Facility (`PAG_gene_information$Chromosome`) is more complete than what we obtain with `mapIds()` (`PAG_gene_information$gene_chromosome_mapids`), as it includes the transgenes we used to label cells and the identify of the ERCC spike-ins. We will thus stick to that one in our analysis.

## Step 1.6 | Build a SingleCellExperiment object
We have now loaded both the data and the metadata, and we have it in a clean and tidy format. The next step is to create an object of the `SingleCellExperiment` class for downstream analysis. For an introduction to the `SingleCellExperiment` class see [Orchestrating Single-Cell Analysis with Bioconductor book](https://osca.bioconductor.org/data-infrastructure.html) by Robert Amezquita and Stephanie Hicks.

* The `assays` slot in a `SingleCellExperiment` object contains primary data such as counts in a list, where each entry of the list is in a matrix format, where rows correspond to features (genes) and columns correspond to samples (cells). We can extend the `assays` slot: `counts` are intended to be used for raw counts, but we can also have `logcounts` and other transformed values for normalized data (we will compute them in next steps).

* The `colData` slot is designed for metadata that describe the samples (cells) provided as a `data.frame`, where rows correspond to cells, and columns correspond to the sample (cells) metadata features (e.g. id, batch, date, etc.). Furthermore, `colData` can be used for subsetting (e.g. `PAG_sceset[, PAG_sceset$cell.type==VGAT]` or `PAG_sceset$cell.id`).

* The rows also have their own metadata slot to store information that pertains to the features of the `SingleCellExperiment` object: the `rowData` slot contains data in a `data.frame` format that describes aspects of the data corresponding to the rows of the primary data, whereas the `rowRanges` slot contains data in a `GRangesList` (where each entry is a `GenomicRanges` format) that describes the chromosome, strand, and start/end coordinates of the features (genes, genomic regions).

* The `sizeFactors` slot contains information in a numeric vector regarding the sample/cell normalization factors used to produce a normalized data representation, whereas the `reducedDims` slot contains a list of numeric matrix entries which describe dimensionality reduced representations of the primary data, such that rows represent the columns of the primary data (a.k.a. the samples/cells), and columns represent the dimensions. Just like the `assays` slot, the `reducedDims` slot can hold a list of many entries like a PCA, TSNE, and UMAP representation of a given dataset all within the `reducedDims` slot.

* Some analyses produce results that do not fit into the aforementioned slots. `SingleCellExperiment` has a slot just for this type of messy data that can accommodate any type of data, as long as it is in a named list. This is the `metadata` slot, a named list of entries, where each entry in the list can be anything you want it to be (for instance, a list of favorite genes, such as highly variable genes, that we want to save inside of our `SingleCellExperiment` object for use in our analysis at a later point).
```{r}
# Create a SingleCellExperiment object
library(SingleCellExperiment)
PAG_sceset <- SingleCellExperiment(assays = list(counts = as.matrix(PAG_data)),
                                   colData = PAG_metadata, 
                                   rowData = PAG_gene_information,
                                   metadata = PAG_scRNAseq_gene_lists
                                   )
PAG_sceset
```

```{r}
# Different ways to inspect the SingleCellExperiment object:
#PAG_sceset
#assays(PAG_sceset)
#colData(PAG_sceset)
#rowData(PAG_sceset)
#summary(metadata(PAG_sceset))

# You can get the counts using str() => structure of the object
#str(counts(PAG_sceset))
```

Once we are done, we save our progress and the `SingleCellExperiment` object so we don't have to repeat all these steps again:
```{r}
saveRDS(PAG_sceset, file = "PAG_sceset.rds")
print("Part 1 - Done!")
```

```{r}
sessionInfo()
```
---
title: "Topographic, single-cell gene expression profiling of Periaqueductal Gray neurons"
subtitle: "Parts IV: modelling technical noise and feature selection"
author:
  - name: "Oriol Pavon Arocas, Sarah F. Olesen, and Tiago Branco"
    affiliation: "Sainsbury Wellcome Centre for Neural Circuits and Behaviour, University College London, UK"
    email: "oriol.pavon.16@ucl.ac.uk"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_notebook:
    highlight: pygments
    number_sections: FALSE
    theme: lumen
    toc: TRUE
    toc_float: TRUE

#output: rmdformats::readthedown:
  #highlight: pygments
---

***

This is a pipeline to analyse single-cell RNA sequencing data from Periaqueductal Gray neurons (1) isolated from acute midbrain slices of transgenic mice using visually guided aspiration via patch pipettes and (2) processed using SMART-seq2 (Picelli et al., Nature Protocols 2014). 

This pipeline has been generated after attending the [EMBL-EBI RNA-Sequence Analysis Course](https://www.ebi.ac.uk/training/events/2019/rna-sequence-analysis) and [attending](https://training.csx.cam.ac.uk/bioinformatics/event/2823386) and following the online course on [Analysis of single cell RNA-seq data](https://github.com/hemberg-lab/scRNA.seq.course) by the [Hemberg Lab](https://www.sanger.ac.uk/science/groups/hemberg-group). Many other resources have been used, including the [Orchestrating Single-Cell Analysis with Bioconductor book](https://osca.bioconductor.org/) by Robert Amezquita and Stephanie Hicks, the [simpleSingleCell workflow in Bioconductor](https://bioconductor.org/packages/3.9/workflows/html/simpleSingleCell.html) maintained by Aaron Lun, the [rnaseqGene workflow](https://bioconductor.org/packages/3.10/workflows/html/rnaseqGene.html) maintained by Michael Love, the [RNAseq123 workflow](https://bioconductor.org/packages/3.10/workflows/html/RNAseq123.html) maintained by Matthew Ritchie, and the [EGSEA123 workflow](https://bioconductor.org/packages/3.10/workflows/html/EGSEA123.html) maintained by Matthew Ritchie.

Other key resources include [Bioconductor](http://www.bioconductor.org/) (Huber et al., Nature Methods 2015), [scRNA-tools](https://www.scrna-tools.org/), `scater` (McCarthy et al., Bioinformatics 2017), `scran` (Lun et al., F1000Res 2016), `SC3` (Kiselev et al., Nature Methods 2017), `Seurat` (Butler et al., Nature Biotechnology 2018), `clusterExperiment` (Risso et al., PLOS Computational Biology 2018), `limma` (Ritchie et al., Nucleic Acids Research 2015), `DESeq2` (Love et al., Genome Biology 2014), `edgeR` (Robinson et al., Bioinformatics 2010), `MAST` (Finak, McDavid, Yajima et al., Genome Biology 2015), `iSEE` (Rue-Albrecht & Marini et al., F1000Research 2018), `t-SNE` (van der Maaten & Hinton, Journal of Machine Learning Research 2008), `UMAP` (McInnes et al., arXiv 2018), and the [Mathematical Statistics and Machine Learning for Life Sciences](https://towardsdatascience.com/tagged/stats-ml-life-sciences) column by Nikolay Oskolkov.

***

# STEP 4 | Modelling technical and biological variability in gene expression to identify highly variable genes
_The following steps and explanations are based on the [OSCA book](https://osca.bioconductor.org/feature-selection.html), the [simpleSingleCell workflow in Bioconductor](https://bioconductor.org/packages/3.9/workflows/html/simpleSingleCell.html), and [Description of the HVG machinery in scran](https://github.com/LTLA/HVGDetection2018) maintained by Aaron Lun._

We often use scRNA-seq data in exploratory analyses to characterise heterogeneity across cells. Procedures like clustering and dimensionality reduction compare cells based on their gene expression profiles, which involves aggregating per-gene differences into a single (dis)similarity metric between a pair of cells. The choice of genes to use in this calculation has a major impact on the behavior of the metric and the performance of downstream methods. We want to select genes that contain useful information about the biology of the system while removing genes that contain random noise. This aims to preserve interesting biological structure without the variance that obscures that structure, and to reduce the size of the data to improve computational efficiency of later steps.

The simplest approach to feature selection is to select the most variable genes based on their expression across the population. This assumes that genuine biological differences will manifest as increased variation in the affected genes, compared to other genes that are only affected by technical noise or a baseline level of “uninteresting” biological variation (e.g., from transcriptional bursting). Several methods are available to quantify the variation per gene and to select an appropriate set of highly variable genes (HVGs).

We continue using the `PAG_sceset_qc_norm` after normalization. We should thus have a `logcounts` slot in `assays`:
```{r}
# Set the directory where your data and scripts are:
setwd("D:/Dropbox (UCL - SWC)/Project_transcriptomics/analysis/PAG_scRNAseq_analysis")

# Set the path to save figures from this Part:
path_for_figures <- "D:/Dropbox (UCL - SWC)/Project_transcriptomics/figures_in_progress/R_figures_Part4_HVGs/"
date <- Sys.Date()

# Load packages:
library(tidyverse)
library(SingleCellExperiment)
library(scater)
library(scran)
library(limma)
library(ggplot2)
```

```{r}
# If starting from stored results, load saved filtered dataset from previous Step:
options(stringsAsFactors = FALSE)

PAG_sceset_qc_norm <- readRDS("PAG_sceset_qc_norm.rds") # Contains filtered cells and genes, and log-normalized data
assayNames(PAG_sceset_qc_norm)
```

## Step 4.1 | Quantifying per-gene variation
Variability in the observed expression values across genes can be driven by genuine biological heterogeneity or uninteresting technical noise. To distinguish between these two possibilties, we need to model the technical component of the variability of the expression values for each gene.

### 4.1.1 | Variance of the log-counts
The simplest approach to quantifying per-gene variation is to compute the variance of the _log-normalized expression_ values (referred to as “logcounts” for simplicity) for each gene across all cells in the population (A. T. L. Lun, McCarthy, and Marioni 2016). This has an advantage in that the feature selection is based on the same log-values that are used for later downstream steps. In particular, genes with the largest variances in log-values will contribute the most to the Euclidean distances between cells. By using log-values here, we ensure that our quantitative definition of heterogeneity is consistent throughout the entire analysis.

Calculation of the per-gene variance is simple but feature selection requires modelling of the mean-variance relationship. The log-transformation does not achieve perfect variance stabilization, which means that the variance of a gene is driven more by its abundance than its underlying biological heterogeneity. To account for this effect, we use the `modelGeneVar()` function to fit a trend to the variance with respect to abundance across all genes. Note that in previouse steps we have filtered the genes so that we keep only those expressed (with at least 1 count) in 4 cells or more.

For each gene, `modelGeneVar()` computes the variance and mean of the log-expression values. A trend is fitted to the variance against the mean for all genes using `fitTrendVar`. The fitted value for each gene is used as a proxy for the technical component of variation for each gene, under the assumption that most genes exhibit a low baseline level of variation that is not biologically interesting. The biological component of variation for each gene is defined as the residual from the trend. A `DataFrame` is returned where each row corresponds to a gene containing the following numeric fields: `mean` (mean normalized log-expression per gene), `total` (variance of the normalized log-expression per gene), `bio` (biological component of the variance), `tech` (technical component of the variance), `p.value` and `FDR` (raw and adjusted p-values for the test against the null hypothesis that `bio<=0`).
```{r}
library(scran)
start_time <- Sys.time() # Takes around 2s
var_model_no_spikes <- modelGeneVar(PAG_sceset_qc_norm,
                                    block = NULL,
                                    min.mean = 0.1, parametric = TRUE,
                                    assay.type = "logcounts")

# If block is not specified, the metadata of the DataFrame contains the output of running `fitTrendVar` on the specified features, along with the mean and var used to fit the trend.
var_fit_no_spikes <- metadata(var_model_no_spikes)
sum(var_fit_no_spikes$mean == "0") # Number of genes with mean expression = 0
# If this is not 0, it means some dropouts were introduced by the normalization and log-transformation steps as we had excluded genes with zero expression in all cells before normalization

end_time <- Sys.time()
end_time - start_time
```

We next visually inspect the trend to confirm that it corresponds to the distribution of our data. A wave-like shape is typical of the mean-variance trend for log-expression values. A linear increase in the variance is observed as the mean increases from zero, as larger variances are obviously possible when the counts are not all equal to zero. In contrast, the relative contribution of sampling noise decreases at high abundances, resulting in a downward trend. The peak represents the point at which these two competing effects cancel each other out.
```{r}
par(las = 1) # plot axis labels always horizontal (defaults to 0: always parallel to the axis)

# Plot variance-mean trend without blocking
plot(var_fit_no_spikes$mean,
     var_fit_no_spikes$var,
     pch = 16, cex = 0.6,
     main = "Mean-Variance relationship",
     xlab = "Mean of log-expression",
     ylab = "Variance of log-expression")
curve(var_fit_no_spikes$trend(x), col = "dodgerblue", add = TRUE, lwd = 2)
```

At any given abundance, we assume that the expression profiles of most genes are dominated by random technical noise. Under this assumption, our trend represents an estimate of the technical noise as a function of abundance. We then break down the total variance of each gene into the technical component, i.e., the fitted value of the trend at that gene’s abundance; and the biological component, defined as the difference between the total variance and the technical component. This biological component represents the “interesting” variation for each gene and can be used as the metric for HVG selection. Some genes will have negative biological components, which have no obvious interpretation and can be ignored in most applications. They are inevitable when fitting a trend to the per-gene variances as approximately half of the genes will lie below the trend.

Ranking genes by the biological component enables identification of interesting genes for downstream analyses in a manner that accounts for the mean-variance relationship. Using log-transformed expression values blunts the impact of large positive outliers and ensures that large variances are driven by strong log-fold changes between cells rather than differences in counts. Log-expression values are also used in downstream analyses like PCA, so modelling them here avoids inconsistencies with different quantifications of variation across analysis steps.
```{r}
# Inspect the top HVG from this approach:
head(var_model_no_spikes[order(var_model_no_spikes$bio, decreasing = TRUE),])
```

### 4.1.2 | Coefficient of variation
An alternative approach to quantification uses the _squared coefficient of variation (CV2)_ of the _normalized_ expression values *prior to log-transformation*. The CV2 is a widely used metric for describing variation in non-negative data and is closely related to the dispersion parameter of the negative binomial distribution in packages like _edgeR_ and _DESeq2_. We can compute the CV2 for each gene in the dataset using the `modelGeneCV2()` function, which provides a robust implementation of the approach described by Brennecke et al. (2013).

For each gene, `modelGeneCV2()` computes the CV2 and mean of the counts after scaling them by the `size.factors`. A trend is fitted to the CV2 against the mean for all genes using `fitTrendCV2`. The fitted value for each gene is used as a proxy for the technical noise, assuming that most genes exhibit a low baseline level of variation that is not biologically interesting. The ratio of the total CV2 to the trend is used as a metric to rank interesting genes, with larger ratios being indicative of strong biological heterogeneity. A `DataFrame` is returned where each row corresponds to a gene containing the following numeric fields: `mean` (mean normalized expression per gene), `total` (squared coefficient of variation of the normalized expression per gene), `trend` (fitted value of the trend), `ratio` (ratio of `total` to `trend`), `p.value` and `FDR` (raw and adjusted p-values for the test against the null hypothesis that `ratio<=1`).
```{r}
start_time <- Sys.time() # Takes around 2s
CV2_model_no_spikes <- modelGeneCV2(PAG_sceset_qc_norm,
                                    size.factors = NULL, # If size.factors=NULL for the SingleCellExperiment method, sizeFactors(x) is used if available.
                                    block = NULL,
                                    assay.type = "counts")

# If block is not specified, the metadata of the DataFrame contains the output of running fitTrendCV2 on the specified features, along with the mean and cv2 used to fit the trend.
CV2_fit_no_spikes <- metadata(CV2_model_no_spikes)
sum(CV2_fit_no_spikes$mean == "0") # Number of genes with mean expression = 0 
# If this is not 0, it means some dropouts were introduced by the normalization step as we had excluded genes with zero expression in all cells before normalization

end_time <- Sys.time()
end_time - start_time
```

This allows us to model the mean-CV2 relationship when considering the relevance of each gene. Again, our assumption is that most genes contain random noise and that the trend captures mostly technical variation. Large CV2 values that deviate strongly from the trend are likely to represent genes affected by biological structure. We can now visually inspect our fitted trend:
```{r}
par(las = 1) # plot axis labels always horizontal (defaults to 0: always parallel to the axis)

# Plot CV2 as a function of the mean without blocking
plot(CV2_fit_no_spikes$mean,
     CV2_fit_no_spikes$cv2,
     log = "xy",
     pch = 16, cex = 0.6,
     main = "Mean-CV2 relationship",
     xlab = "Mean of normalized expression",
     ylab = "CV2 of normalized expression",
     xlim = c(1e-05, 1e+06))
curve(CV2_fit_no_spikes$trend(x), col = "dodgerblue", add = TRUE, lwd = 2)
```

For each gene, we quantify the deviation from the trend in terms of the ratio of its CV2 to the fitted value of trend at its abundance. This is more appropriate than the directly subtracting the trend from the CV2, as the magnitude of the ratio is not affected by the mean.
```{r}
head(CV2_model_no_spikes[order(CV2_model_no_spikes$ratio, decreasing = TRUE),])
```

Both the *CV2 of normalized counts* and the *variance of logcounts* are effective metrics for quantifying variation in gene expression. The CV2 tends to give higher rank to low-abundance HVGs driven by upregulation in rare subpopulations, for which the increase in variance on the raw scale is stronger than that on the log-scale. However, the variation described by the CV2 is less directly relevant to downstream procedures operating on the log-counts, and the reliance on the ratio can assign high rank to uninteresting genes with low absolute variance. We will nonetheless continue the analysis using both metrics side by side.

### 4.1.3 | Quantifying technical noise using spike-ins [not used]
Strictly speaking, the use of a trend fitted to endogenous genes assumes that the expression profiles of most genes are dominated by random technical noise. In practice, all expressed genes will exhibit some non-zero level of biological variability due to events like transcriptional bursting. This suggests that our estimates of the technical component are likely to be inflated. It would be more appropriate to consider these estimates as technical noise plus “uninteresting” biological variation, under the assumption that most genes are unaffected by the relevant heterogeneity in the population.

This revised assumption is generally reasonable but may be problematic in some scenarios where many genes at a particular abundance are affected by a biological process. For example, strong upregulation of cell type-specific genes may result in an enrichment of HVGs at high abundances. This would inflate the fitted trend in that abundance interval and compromise the detection of the relevant genes. We can avoid this problem by fitting a mean-dependent trend to the variance of the spike-in transcripts, if they are available. The premise here is that spike-ins were in theory added in the same quantity to each cell and thus should not be affected by biological variation (i.e., any variance in their counts should be technical in origin), so the fitted value of the spike-in trend should represent a better estimate of the technical component for each gene.
```{r}
#start_time <- Sys.time() # Takes around 5s
#var_model_spikes <- modelGeneVarWithSpikes(PAG_sceset_qc_norm, "ERCC")
#var_fit_spikes <- metadata(var_model_spikes)
#head(var_model_spikes[order(var_model_spikes$bio, decreasing = TRUE),])
#end_time <- Sys.time()
#end_time - start_time

# Plot variance-mean trend using spike-ins
#plot(var_model_spikes$mean,
     #var_model_spikes$total, 
     #xlab = "Mean of log-expression",
     #ylab = "Variance of log-expression")
#points(var_fit_spikes$mean, var_fit_spikes$var, col = "red", pch = 16)
#curve(var_fit_spikes$trend(x), col = "dodgerblue", add = TRUE, lwd = 2)
```

Trends based purely on technical noise tend to yield large biological components for highly-expressed genes. This often includes so-called “house-keeping” genes coding for essential cellular components such as ribosomal proteins, which are considered uninteresting for characterizing cellular heterogeneity. These observations suggest that a more accurate noise model does not necessarily yield a better ranking of HVGs, though one should keep an open mind - house-keeping genes are regularly DE in a variety of conditions (Glare et al. 2002; Nazari, Parham, and Maleki 2015; Guimaraes and Zavolan 2016), and the fact that they have large biological components indicates that there is strong variation across cells that may not be completely irrelevant.

Ideally, the technical component would be estimated by fitting a mean-variance trend to the spike-in transcripts. In practice, this strategy is compromised by the small number of spike-in transcripts, the uneven distribution of their abundances, and (for low numbers of cells) the imprecision of their variance estimates. This makes it difficult to accurately fit a complex mean-dependent trend to the spike-in variances. In some datasets, spike-in RNA may not have been added in appropriate quantities (or indeed at all). In our case, we don't detect all ERCCs in all the cells, so using them to model the variance in our dataset will yield poor results. It may also be inappropriate to assume Poisson technical noise, especially for read count data where amplification noise is non-negligible. In such cases, an alternative approach is to fit the trend to the variance estimates of the endogenous genes as we have done above. This assumes that the majority of genes are not variably expressed, such that the technical component dominates the total variance for those genes. The fitted value of the trend is then used as an estimate of the technical component. 

### 4.1.4 | Accounting for blocking factors
Data containing multiple batches will often exhibit batch effects. We are usually not interested in HVGs that are driven by batch effects. Rather, we want to focus on genes that are highly variable within each batch. This can be achieved by performing trend fitting and variance decomposition separately for each batch. The use of a batch-specific trend fit is useful as it accommodates differences in the mean-variance trends between batches. This is especially important if batches exhibit systematic technical differences, e.g., differences in coverage or in the amount of spike-in RNA added. The analysis of each plate yields estimates of the biological and technical components for each gene, which are averaged across plates to take advantage of information from multiple batches.

To make the most of this approach, our batches should be balanced. This means that each processing batch should contain an equal distribution of cells coming from all the conditions we are probing (in our case, excitatory and inhibitory cells, and the different PAG subdivisions). Unfortunately, this is only true for half of our batches. We can choose to run the `modelGeneVar` blocking by batch using only the balanced batches, and then use the HVGs obtained from this approach, which should be more accurate than if we were to use all batches (including the non-balanced ones containing exclusively excitatory or inhibitory cells). Another problem we face is the size of our batches: they are all quite small and of variable size. The variability in size can be accounted for by setting `equiweight = FALSE` in the `modelGeneVar`. The problem with the absolute size is a trickier one. Having very few cells will make it harder to get good fits, as the genes expressed in each batch of cells will be very different. This can be due to the fact that when we excluded the genes not expressed in any cell, we did so for the whole dataset. In the batch by batch scenario we will have many more genes not expressed in a given batch, and these will vary across batches due to the dropout effect in scRNA-seq. Although the fits are still quite good for the `modelGeneVar`, the fact that the mean is a denominator in the formula to calculate the CV2 seems to have a bigger effect on `modelGeneCV2`, and the fits are not be very similar across batches. We will run both approaches blocking by `processing.batch` and compare the results for each individual batch below.

We first identify and label the balanced batches:
```{r}
balanced_batch <- grepl("^b", PAG_sceset_qc_norm$batch.processing)
summary(balanced_batch)

PAG_sceset_qc_norm[,balanced_batch]$batch.processing # Should leave only the cells belonging to balanced batches
```

We then run the `modelGeneVar` using the `block` and `equiweight` arguments:
```{r}
library(scran)
start_time <- Sys.time() # Takes around 12s
var_model_no_spikes_block <- modelGeneVar(PAG_sceset_qc_norm[,balanced_batch], # use only balanced batches
                                          block = PAG_sceset_qc_norm[,balanced_batch]$batch.processing,
                                          min.mean = 0.1, parametric = TRUE,
                                          equiweight = FALSE,
                                          assay.type = "logcounts")
# If equiweight = FALSE, A weighted average is used where the value for each level is weighted by the number of cells, otherwise all levels are equally weighted when combining statistics.
head(var_model_no_spikes_block[order(var_model_no_spikes_block$bio, decreasing = TRUE),1:6])
end_time <- Sys.time()
end_time - start_time
```

We plot the fitted trends for the individual batches so that we can compare them. Although noisier, they seem quite consistent across batches.
```{r}
par(las = 1) # plot axis labels always horizontal (defaults to 0: always parallel to the axis)

#par(mfrow = c(3,4))
blocked.stats <- var_model_no_spikes_block$per.block
for (i in colnames(blocked.stats)) {
    current <- blocked.stats[[i]]
    #print(sum(current$mean == "0")) # Chech the number of genes with mean expression = 0 in each batch
    plot(current$mean,
         current$total,
         main = paste0("Batch ", i, " | ", sum(current$mean == "0"), " zero-expression genes"),
         pch = 16, cex = 0.6,
         xlab = "Mean of log-expression",
         ylab = "Variance of log-expression",
         xlim = c(0,20), ylim = c(0,30))
    curfit <- metadata(current)
    curve(curfit$trend(x), col = 'dodgerblue', add = TRUE, lwd = 2)
}
```

We now do the same for `modelGeneCV2`:
```{r}
start_time <- Sys.time() # Takes around 12s
CV2_model_no_spikes_block <- modelGeneCV2(PAG_sceset_qc_norm[,balanced_batch], # use only balanced batches
                                          block = PAG_sceset_qc_norm[,balanced_batch]$batch.processing,
                                          size.factors = NULL, # If size.factors=NULL for the SingleCellExperiment method, sizeFactors(x) is used if available.
                                          equiweight = FALSE,
                                          assay.type = "counts")
# If equiweight = FALSE, a weighted average is used where the value for each level is weighted by the number of cells, otherwise all levels are equally weighted when combining statistics.
end_time <- Sys.time()
head(CV2_model_no_spikes_block[order(CV2_model_no_spikes_block$ratio, decreasing = TRUE),1:7])
end_time - start_time
```

And plot the results:
```{r}
par(las = 1) # plot axis labels always horizontal (defaults to 0: always parallel to the axis)

#par(mfrow = c(3,4))
blocked.stats <- CV2_model_no_spikes_block$per.block
for (i in colnames(blocked.stats)) {
  current <- blocked.stats[[i]]
  #print(sum(current$mean == "0"))
  plot(current$mean,
       current$total,
       log = "xy",
       main = paste0("Batch ", i, " | ", sum(current$mean == "0"), " zero-expression genes"),
       pch = 16, cex = 0.6,
       xlab = "Mean of normalized expression",
       ylab = "CV2 of normalized expression",
       xlim = c(1e-05, 1e+06), ylim = c(0.01,50)
       )
  curfit <- metadata(current)
  curve(curfit$trend(x), col = 'dodgerblue', add = TRUE, lwd = 2)
}
```

As we can see with the `modelGeneCv2` approach, blocking by batch leads to very bad fits, where the trend doesn't really follow the distribution from the gene expression. Looking at these plots, we will compare the HVGs we obtain with each approach before deciding. 

## Step 4.2 | Strategies to identify highly variable genes
Once we have quantified the per-gene variation, the next step is to select the subset of HVGs to use in downstream analyses. Formal detection of HVGs allows us to avoid genes that are highly variable due to technical factors such as sampling noise during RNA capture and library preparation. A large subset will reduce the risk of discarding interesting biological signal by retaining more potentially relevant genes, at the cost of increasing noise from irrelevant genes that might obscure said signal. It is thus difficult to determine the optimal trade-off for any given application as noise in one context may be useful signal in another.

There are different ways to define HVGs. We could select the genes with biological components that are significantly greater than zero at a false discovery rate (FDR) of 5% or 1%. These genes are interesting as they drive differences in the expression profiles between cells, and should be prioritized for further investigation. In addition, we could consider a gene to be a HVG only if it has a biological component greater than or equal to 0.5. For transformed expression values on the log2 scale, this would mean that the average difference in true expression between any two cells will be at least 2-fold. We could also rank the results by the biological component to focus on genes with larger biological variability, and then choose a certain proportion of genes from the total.

### 4.2.1 | Based on the largest metrics
The simplest HVG selection strategy is to take the top X genes with the largest values for the relevant variance metric. The main advantage of this approach is that the user can directly control the number of genes retained, which ensures that the computational complexity of downstream calculations is easily predicted. 

The choice of X has a fairly straightforward biological interpretation. Recall our trend-fitting assumption that most genes do not exhibit biological heterogeneity; this implies that they are not differentially expressed between cell types or states in our population. If we quantify this assumption into a statement that, e.g., no more than 5% of genes are differentially expressed, we can naturally set X to 5% of the number of genes. In practice, we usually do not know the proportion of DE genes beforehand so this interpretation just exchanges one unknown for another. Nonetheless, it is still useful as it implies that we should lower X for less heterogeneous datasets, retaining most of the biological signal without unnecessary noise from irrelevant genes. Conversely, more heterogeneous datasets should use larger values of X to preserve secondary factors of variation beyond those driving the most obvious HVGs.

The main disadvantage of this approach is that it turns HVG selection into a competition between genes, whereby a subset of very highly variable genes can push other informative genes out of the top set. This can be problematic for analyses of highly heterogeneous populations if the loss of important markers prevents the resolution of certain subpopulations. In the most extreme example, consider a situation where a single subpopulation is very different from the others. In such cases, the top set will be dominated by differentially expressed genes involving that distinct subpopulation, compromising resolution of heterogeneity between the other populations. 

Another possible concern with this approach is the fact that the choice of X is fairly arbitrary, with any value from 500 to 5000 considered “reasonable”. The recommendation is to simply pick an arbitrary X and proceed with the rest of the analysis, with the intention of testing other choices later, rather than spending much time worrying about obtaining the “optimal” value.

### 4.2.2 | Based on significance
Another approach to feature selection is to set a fixed threshold of one of the metrics. This is most commonly done with the (adjusted) p-value reported by each of the above methods. The p-value for each gene is generated by testing against the null hypothesis that the variance is equal to the trend. For example, we might define our HVGs as all genes that have adjusted p-values below 0.05.

This approach is simple to implement and - if the test holds its size - it controls the false discovery rate (FDR). That is, it returns a subset of genes where the proportion of false positives is expected to be below the specified threshold. This can occasionally be useful in applications where the HVGs themselves are of interest. For example, if we were to use the list of HVGs in further experiments to verify the existence of heterogeneous expression for some of the genes, we would want to control the FDR in that list.

The downside of this approach is that it is less predictable than the top X strategy. The number of genes returned depends on the type II error rate of the test and the severity of the multiple testing correction. One might obtain no genes or every gene at a given FDR threshold, depending on the circumstances. Moreover, control of the FDR is usually not helpful at this stage of the analysis. We are not interpreting the individual HVGs themselves but are only using them for feature selection prior to downstream steps. There is no reason to think that a 5% threshold on the FDR yields a more suitable compromise between bias and noise compared to the top X selection.

As an aside, we might consider ranking genes by the p-value instead of the biological component for use in a top X approach. This results in some counterintuitive behavior due to the nature of the underlying hypothesis test, which is based on the ratio of the total variance to the expected technical variance. Ranking based on p-value tends to prioritize HVGs that are more likely to be true positives but, at the same time, less likely to be biologically interesting. Many of the largest ratios are observed in high-abundance genes and are driven by very low technical variance; the total variance is typically modest for such genes, and they do not contribute much to population heterogeneity in absolute terms. (Note that the same can be said of the ratio of CV2 values.)
 
### 4.2.3 | Keeping all genes above the trend
We can also only remove the obviously uninteresting genes with variances below the trend. By doing so, we avoid the need to make any judgement calls regarding what level of variation is interesting enough to retain. This approach represents one extreme of the bias-variance trade-off where bias is minimized at the cost of maximizing noise. For `modelGeneVar()`, it equates to keeping all positive biological components, whereas for `modelGeneCV2()`, this involves keeping all ratios above 1.

By retaining all potential biological signal, we give secondary population structure the chance to manifest. This is most useful for rare subpopulations where the relevant markers will not exhibit strong overdispersion owing to the small number of affected cells. It will also preserve a weak but consistent effect across many genes with small biological components; admittedly, though, this is not of major interest in most scRNA-seq studies given the difficulty of experimentally validating population structure in the absence of strong marker genes.

The obvious cost is that more noise is also captured, which can reduce the resolution of otherwise well-separated populations and mask the secondary signal that we were trying to preserve. The use of more genes also introduces more computational work in each downstream step. This strategy is thus best suited to very heterogeneous populations containing many different cell types (possibly across many datasets that are to be merged, as in Chapter 13) where there is a justified fear of ignoring marker genes for low-abundance subpopulations under a competitive top X approach.

### 4.2.4 | Based on a priori genes of interest
A blunt yet effective feature selection strategy is to use pre-defined sets of interesting genes. The aim is to focus on specific aspects of biological heterogeneity that may be masked by other factors when using unsupervised methods for HVG selection. One example application lies in the dissection of transcriptional changes during the earliest stages of cell fate commitment (Messmer et al. 2019), which may be modest relative to activity in other pathways (e.g., cell cycle, metabolism). Indeed, if our aim is to show that there is no meaningful heterogeneity in a given pathway, we would - at the very least - be obliged to repeat our analysis using only the genes in that pathway to maximize power for detecting such heterogeneity.

Using scRNA-seq data in this manner is conceptually equivalent to a fluorescence activated cell sorting (FACS) experiment, with the convenience of being able to (re)define the features of interest at any time. For example, in the PBMC dataset, we might use some of the C7 immunologic signatures from MSigDB (Godec et al. 2016) to improve resolution of the various T cell subtypes. We stress that there is no shame in leveraging prior biological knowledge to address specific hypotheses in this manner. We say this because a common refrain in genomics is that the data analysis should be “unbiased”, i.e., free from any biological preconceptions. Attempting to derive biological insight ab initio is admirable but such “biases” are already present at every stage, starting from experimental design (why are we interested in this cell population in the first place?) and continuing through to interpretation of marker genes.

Of course, the downside of focusing on pre-defined genes is that it will limit our capacity to detect novel or unexpected aspects of variation. Thus, this kind of focused analysis should be complementary to (rather than a replacement for) the unsupervised feature selection strategies discussed previously.

Alternatively, we can also invert this reasoning to remove genes that are unlikely to be of interest prior to downstream analyses, thus avoiding unwanted variation that interferes with downstream interpretation. Common candidates for removal include ribosomal protein genes or mitochondrial genes; for immune cell subsets, we might also be inclined to remove immunoglobulin genes and T cell receptor genes, where clonal expression introduces (possibly irrelevant) population structure. In practice, we tend to err on the side of caution and abstain from preemptive filtering on biological function until these genes are demonstrably problematic in downstream analyses.

## Step 4.3 | Selecting HVGs in our dataset
Once we have modelled the technical variability we can extract a list of genes and rank them to focus on genes with larger biological components. For `modelGeneVar()`, we select the genes with the largest biological components and limit the maximum number to 15% of the total number of genes:
```{r}
# The `getTopHVGs()` function dentifies all genes where the relevant metric of variation is greater than var.threshold
hvg_var_no_spikes <- getTopHVGs(var_model_no_spikes,
                                var.field = "bio", var.threshold = 1, # Select all genes with positive biological components above a certain threshold
                                n = round(nrow(var_model_no_spikes)*0.15) # Select the top `n` number or proportion of genes
                                #fdr.field = "FDR", fdr.threshold = 0.05 # Select those genes with an adjusted p-value below 5% FDR
                                )
str(hvg_var_no_spikes)

# To export not just the names but also the output from the `modelGeneVar() we can do as follows:
hvg_var_out_no_spikes <- var_model_no_spikes[order(var_model_no_spikes$bio, decreasing = TRUE),]

# Then we keep only the genes we obtain from the `getTopHVGs` function, which outputs only gene names.
hvg_var_out_no_spikes <- hvg_var_out_no_spikes[hvg_var_no_spikes,]
head(hvg_var_out_no_spikes)
dim(hvg_var_out_no_spikes)
```

We do the same for the results obtained from modelling the variance while blocking by `batch.processing`:
```{r}
# The `getTopHVGs()` function dentifies all genes where the relevant metric of variation is greater than var.threshold
hvg_var_no_spikes_block <- getTopHVGs(var_model_no_spikes_block,
                                      var.field = "bio", var.threshold = 1, # Select all genes with positive biological components above a certain threshold
                                      n = round(nrow(var_model_no_spikes_block)*0.15) # Select the top `n` number or proportion of genes
                                      #fdr.field = "FDR", fdr.threshold = 0.05 # Select those genes with an adjusted p-value below 5% FDR
                                      )
str(hvg_var_no_spikes_block)

# To export not just the names but also the output from the `modelGeneVar() we can do as follows:
hvg_var_out_no_spikes_block <- var_model_no_spikes_block[order(var_model_no_spikes_block$bio, decreasing = TRUE),]

# Then we keep only the genes we obtain from the `getTopHVGs` function, which outputs only gene names.
hvg_var_out_no_spikes_block <- hvg_var_out_no_spikes_block[hvg_var_no_spikes_block,]
head(hvg_var_out_no_spikes_block[,1:6])
dim(hvg_var_out_no_spikes_block)
```

For `modelGeneCV2()`, we would instead choose the genes with the largest ratios, again limiting the maximum number to 15% of the total number of genes:
```{r}
hvg_cv2_no_spikes <- getTopHVGs(CV2_model_no_spikes,
                                var.field = "ratio", var.threshold = 1,
                                n = round(nrow(CV2_model_no_spikes)*0.15) # Select the top `n` number or proportion of genes
                                #fdr.field = "FDR", fdr.threshold = 0.05 # Select those genes with an adjusted p-value below 5% FDR
                                )
str(hvg_cv2_no_spikes)

# To export not just the names but also the output from the `modelGeneVar() we can do as follows:
hvg_cv2_out_no_spikes <- CV2_model_no_spikes[order(CV2_model_no_spikes$ratio, decreasing = TRUE),]

# Then we keep only the genes we obtain from the `getTopHVGs` function, which outputs only gene names:
hvg_cv2_out_no_spikes <- hvg_cv2_out_no_spikes[hvg_cv2_no_spikes,]
head(hvg_cv2_out_no_spikes)
dim(hvg_cv2_out_no_spikes)
```

And again after blocking by `batch.processing`:
```{r}
hvg_cv2_no_spikes_block <- getTopHVGs(CV2_model_no_spikes_block,
                                      var.field = "ratio", var.threshold = 1,
                                      n = round(nrow(CV2_model_no_spikes_block)*0.15) # Select the top `n` number or proportion of genes
                                      #fdr.field = "FDR", fdr.threshold = 0.05 # Select those genes with an adjusted p-value below 5% FDR
                                      )
str(hvg_cv2_no_spikes_block)

# To export not just the names but also the output from the `modelGeneVar() we can do as follows:
hvg_cv2_out_no_spikes_block <- CV2_model_no_spikes_block[order(CV2_model_no_spikes_block$ratio, decreasing = TRUE),]

# Then we keep only the genes we obtain from the `getTopHVGs` function, which outputs only gene names:
hvg_cv2_out_no_spikes_block <- hvg_cv2_out_no_spikes_block[hvg_cv2_no_spikes_block,]
head(hvg_cv2_out_no_spikes_block[,1:6])
dim(hvg_cv2_out_no_spikes_block)
```

### 4.3.1 | Filter uninteresting genes from the dataset
_One important thing..._
Now that we have modelled the gene expression variance and CV2, and before moving on to downstream analysis, we consider dropping any Ribosomal, Mitochondrial, ERCC, sex-specific genes (e.g. XIST), transgenes (EYFP, tdTomato, Cre, TSO concatamers), and genes used for transgenic labelling of cells (VGAT and VGluT2) from the dataset, as some of them are not be biologically informative and others have been used to select the cells. We do so for both our `SingleCellExperiment` object and for the different sets of HVGs:
```{r}
##### 
##Identify and mark the genes we want to drop:
# ERCCs
rowData(PAG_sceset_qc_norm)$is_spike <- grepl("^ERCC-", rownames(PAG_sceset_qc_norm)) # This should be empty as we already moved the ERCC genes to the altExps slot
# Mitochondrial genes
rowData(PAG_sceset_qc_norm)$is_mitochondrial <- (rowData(PAG_sceset_qc_norm)$Chromosome == "M") # Select the mitochondrial chromosome
# Ribosomal genes
rowData(PAG_sceset_qc_norm)$is_ribosomal <- (rowData(PAG_sceset_qc_norm)$gene_biotype == "rRNA")
# Genes from sex chromosomes
rowData(PAG_sceset_qc_norm)$is_X <- (rowData(PAG_sceset_qc_norm)$Chromosome == "X")
rowData(PAG_sceset_qc_norm)$is_Y <- (rowData(PAG_sceset_qc_norm)$Chromosome == "Y")
# EYFP, tdTomato, Cre, and TSO concatamers
rowData(PAG_sceset_qc_norm)$is_tdTomato <- (rowData(PAG_sceset_qc_norm)$Chromosome == "A") # tdTomato fluorophore
rowData(PAG_sceset_qc_norm)$is_EYFP <- (rowData(PAG_sceset_qc_norm)$Chromosome == "B") # EYFP fluorophore
rowData(PAG_sceset_qc_norm)$is_Cre <- (rowData(PAG_sceset_qc_norm)$Chromosome == "C") # Cre transgene to express fluorophores
rowData(PAG_sceset_qc_norm)$is_SmartSeqTSO <- (rowData(PAG_sceset_qc_norm)$Chromosome == "D") # TSO concatamers
# VGAT and VGluT2
rowData(PAG_sceset_qc_norm)$is_VGAT <- (rowData(PAG_sceset_qc_norm)$gene_name == "Slc32a1")
rowData(PAG_sceset_qc_norm)$is_VGluT2 <- (rowData(PAG_sceset_qc_norm)$gene_name == "Slc17a6")

###### 
## Merge all the genes to exclude:
rowData(PAG_sceset_qc_norm)$filter_genes_qc_norm <- !(rowData(PAG_sceset_qc_norm)$is_spike | 
                                                        rowData(PAG_sceset_qc_norm)$is_mitochondrial | 
                                                        rowData(PAG_sceset_qc_norm)$is_ribosomal | 
                                                        rowData(PAG_sceset_qc_norm)$is_X | 
                                                        rowData(PAG_sceset_qc_norm)$is_Y |
                                                        rowData(PAG_sceset_qc_norm)$is_tdTomato | 
                                                        rowData(PAG_sceset_qc_norm)$is_EYFP | 
                                                        rowData(PAG_sceset_qc_norm)$is_Cre | 
                                                        rowData(PAG_sceset_qc_norm)$is_SmartSeqTSO | 
                                                        rowData(PAG_sceset_qc_norm)$is_VGAT | 
                                                        rowData(PAG_sceset_qc_norm)$is_VGluT2)
summary(rowData(PAG_sceset_qc_norm)$filter_genes_qc_norm) # Genes to exclude are FALSE

#####
## Apply the gene filter to the SingleCellExperiment object:
dim(PAG_sceset_qc_norm)
PAG_sceset_qc_norm_filt <- PAG_sceset_qc_norm[rowData(PAG_sceset_qc_norm)$filter_genes_qc_norm, ]
dim(PAG_sceset_qc_norm_filt)

#####
## Apply the filter to the HVGs:
filt_hvg_var <- rownames(hvg_var_out_no_spikes) %in% rownames(PAG_sceset_qc_norm_filt)
hvg_var_out_no_spikes_filt <- hvg_var_out_no_spikes[filt_hvg_var, ]
nrow(hvg_var_out_no_spikes_filt)

filt_hvg_var_block <- rownames(hvg_var_out_no_spikes_block) %in% rownames(PAG_sceset_qc_norm_filt)
hvg_var_out_no_spikes_block_filt <- hvg_var_out_no_spikes_block[filt_hvg_var_block, ]
nrow(hvg_var_out_no_spikes_block_filt)

filt_hvg_cv2 <- rownames(hvg_cv2_out_no_spikes) %in% rownames(PAG_sceset_qc_norm_filt)
hvg_cv2_out_no_spikes_filt <- hvg_cv2_out_no_spikes[filt_hvg_cv2, ]
nrow(hvg_cv2_out_no_spikes_filt)

filt_hvg_cv2_block <- rownames(hvg_cv2_out_no_spikes_block) %in% rownames(PAG_sceset_qc_norm_filt)
hvg_cv2_out_no_spikes_block_filt <- hvg_cv2_out_no_spikes_block[filt_hvg_cv2_block, ]
nrow(hvg_cv2_out_no_spikes_block_filt)
```

### 4.3.2 | Compare feature selection approaches
Now that we have removed the genes we are not interested in, we can use `limma` and `vennDiagram` to compare how many genes we get in each condition, and how much overlap we have between approaches:
```{r}
library(limma)
# Inspect the overlap between HVGs obtained with Var and Var-Block:
venn_diag_var <- vennCounts(cbind(rownames(PAG_sceset_qc_norm_filt) %in% rownames(hvg_var_out_no_spikes_filt),
                                  rownames(PAG_sceset_qc_norm_filt) %in% rownames(hvg_var_out_no_spikes_block_filt)))
vennDiagram(venn_diag_var,
            names = c("Variance", "Variance $ Block"),
            circle.col = c("#E69F00", "#56B4E9"))

# Inspect the overlap between HVGs obtained with CV2 and CV2-Block:
venn_diag_cv2 <- vennCounts(cbind(rownames(PAG_sceset_qc_norm_filt) %in% rownames(hvg_cv2_out_no_spikes_filt),
                                  rownames(PAG_sceset_qc_norm_filt) %in% rownames(hvg_cv2_out_no_spikes_block_filt)))
vennDiagram(venn_diag_cv2,
            names = c("CV2", "CV2 $ Block"),
            circle.col = c("#595028", "#E87F5D"))

# Inspect the overlap between HVGs obtained with Var and CV2:
venn_diag_varcv2 <- vennCounts(cbind(rownames(PAG_sceset_qc_norm_filt) %in% rownames(hvg_var_out_no_spikes_filt),
                                     rownames(PAG_sceset_qc_norm_filt) %in% rownames(hvg_cv2_out_no_spikes_filt)))
vennDiagram(venn_diag_varcv2,
            names = c("Variance", "CV2"),
            circle.col = c("#E69F00", "#595028"))

# Inspect the overlap between HVGs obtained with Var-Block and CV2-block:
venn_diag_varcv2_block <- vennCounts(cbind(rownames(PAG_sceset_qc_norm_filt) %in% rownames(hvg_var_out_no_spikes_block_filt),
                                           rownames(PAG_sceset_qc_norm_filt) %in% rownames(hvg_cv2_out_no_spikes_block_filt))
                                     )
vennDiagram(venn_diag_varcv2_block,
            names = c("Variance $ Block", "CV2 $ Block"),
            circle.col = c("#56B4E9", "#E87F5D"))

# Inspect the overlap between HVGs obtained with Var-Block and CV2:
venn_diag_varblock_cv2 <- vennCounts(cbind(rownames(PAG_sceset_qc_norm_filt) %in% rownames(hvg_var_out_no_spikes_block_filt),
                                           rownames(PAG_sceset_qc_norm_filt) %in% rownames(hvg_cv2_out_no_spikes_filt)))
vennDiagram(venn_diag_varblock_cv2,
            names = c("Variance $ Block", "CV2"),
            circle.col = c("#56B4E9", "#595028"))

# Inspect the overlap between HVGs from all approaches at once:
venn_diag_all <- vennCounts(cbind(rownames(PAG_sceset_qc_norm_filt) %in% rownames(hvg_var_out_no_spikes_filt),
                                  rownames(PAG_sceset_qc_norm_filt) %in% rownames(hvg_var_out_no_spikes_block_filt),
                                  rownames(PAG_sceset_qc_norm_filt) %in% rownames(hvg_cv2_out_no_spikes_filt),
                                  rownames(PAG_sceset_qc_norm_filt) %in% rownames(hvg_cv2_out_no_spikes_block_filt)))
vennDiagram(venn_diag_all,
            names = c("Variance", "Variance $ Block", "CV2", "CV2 $ Block"),
            circle.col = c("#E69F00", "#56B4E9", "#595028", "#E87F5D"))


## Save all plots
ggsave(filename = str_c(date, "_venn_HVGs_var.pdf"),
       plot = vennDiagram(venn_diag_var,
                          names = c("Variance", "Variance $ Block"),
                          circle.col = c("#E69F00", "#56B4E9")),
       device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
       path = path_for_figures,
       width = 12, height = 9, units = "in", dpi = 300,
       family = "Helvetica", bg = "transparent", pointsize = 12
       )

ggsave(filename = str_c(date, "_venn_HVGs_cv2.pdf"),
       plot = vennDiagram(venn_diag_cv2,
                          names = c("CV2", "CV2 $ Block"),
                          circle.col = c("#595028", "#E87F5D")),
       device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
       path = path_for_figures,
       width = 12, height = 9, units = "in", dpi = 300,
       family = "Helvetica", bg = "transparent", pointsize = 12
       )

ggsave(filename = str_c(date, "_venn_HVGs_varcv2.pdf"),
       plot = vennDiagram(venn_diag_varcv2,
                          names = c("Variance", "CV2"),
                          circle.col = c("#E69F00", "#595028")),
       device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
       path = path_for_figures,
       width = 12, height = 9, units = "in", dpi = 300,
       family = "Helvetica", bg = "transparent", pointsize = 12
       )

ggsave(filename = str_c(date, "_venn_HVGs_varcv2_block.pdf"),
       plot = vennDiagram(venn_diag_varcv2_block,
                          names = c("Variance $ Block", "CV2 $ Block"),
                          circle.col = c("#56B4E9", "#E87F5D")),
       device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
       path = path_for_figures,
       width = 12, height = 9, units = "in", dpi = 300,
       family = "Helvetica", bg = "transparent", pointsize = 12
       )

ggsave(filename = str_c(date, "_venn_HVGs_varblock_cv2.pdf"),
       plot = vennDiagram(venn_diag_varblock_cv2,
                          names = c("Variance $ Block", "CV2"),
                          circle.col = c("#56B4E9", "#595028")),
       device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
       path = path_for_figures,
       width = 12, height = 9, units = "in", dpi = 300,
       family = "Helvetica", bg = "transparent", pointsize = 12
       )

ggsave(filename = str_c(date, "_venn_HVGs_all.pdf"),
       plot = vennDiagram(venn_diag_all,
                          names = c("Variance", "Variance $ Block", "CV2", "CV2 $ Block"),
                          circle.col = c("#E69F00", "#56B4E9", "#595028", "#E87F5D")),
       device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
       path = path_for_figures,
       width = 12, height = 9, units = "in", dpi = 300,
       family = "Helvetica", bg = "transparent", pointsize = 12
       )
```

Taking into account the above Venn Diagrams and the plots of the fitted mean-variance trends, it seems that modelling the variance with blocking by `batch.processing` selects most of the genes captured without blocking, with the advantage that it should more accurately capture the technical variability across batches. Although they look slightly noisier, the plots of the mean-variance relation for the individual batches look quite similar to each other and to the one obtained from the full dataset, so using the HVGs obtained with the blocking approach should be the better option here.

Unfortunately, the same cannot be said for the HVGs obtained from modelling the CV2 with and without blocking. The overlap between HVGs from CV2 and CV2 after blocking is much lower than that obtained from modelling the variance, as seen in the Venn Diagrams. Looking at the plots for the CV2-mean trend for each individual batch we can see that the fitted trends are very variable and in most cases they don't really follow the distribution of the full population. In comparison to the one obtained from the full dataset, the CV2-mean trend of the individual batches look really bad and variable, so using the HVG obtained after blocking might not be a good idea in this case. 

Taking all this into consideration, we will use the HVGs obtained after modelling the *mean-variance after blocking* and the *mean-CV2 without blocking*.

### 4.3.3 | Visualize, store, and export HVGs
Before we store the identified HVGs in our `SingleCellExperiment` object, we quickly check the distribution of expression values for the genes with the largest biological components to ensure that the variance/CV2 estimate is not being dominated by one or two outlier cells.
```{r}
# We can set any visualization parameters common to all plots at the beginning like this:
theme_args <- theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1), axis.ticks.x = element_blank())

violin_HVG_var <- plotExpression(PAG_sceset_qc_norm_filt, features = rownames(hvg_var_out_no_spikes_filt)[1:50],
                                 exprs_values = "logcounts", theme_size = 12, point_alpha = 0.8
                                 ) + ggtitle("Top 50 HVGs from mean-var modelling") + theme_args
violin_HVG_var
ggsave(filename = str_c(date, "_violin_HVG_var.pdf"),
       plot = violin_HVG_var,
       device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
       path = path_for_figures,
       width = 20, height = 5, units = "in", dpi = 300,
       family = "Helvetica", bg = "transparent", pointsize = 12
       )

violin_HVG_var_block <- plotExpression(PAG_sceset_qc_norm_filt, features = rownames(hvg_var_out_no_spikes_block_filt)[1:50],
                                       exprs_values = "logcounts", theme_size = 12, point_alpha = 0.8
                                       ) + ggtitle("Top 50 HVGs from mean-var modelling after blocking") + theme_args
violin_HVG_var_block
ggsave(filename = str_c(date, "_violin_HVG_var_block.pdf"),
       plot = violin_HVG_var_block,
       device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
       path = path_for_figures,
       width = 20, height = 5, units = "in", dpi = 300,
       family = "Helvetica", bg = "transparent", pointsize = 12
       )

violin_HVG_cv2 <- plotExpression(PAG_sceset_qc_norm_filt, features = rownames(hvg_cv2_out_no_spikes_filt)[1:50],
                                       exprs_values = "logcounts", theme_size = 12, point_alpha = 0.8
                                 ) + ggtitle("Top 50 HVGs from mean-cv2 modelling") + theme_args
violin_HVG_cv2
ggsave(filename = str_c(date, "_violin_HVG_cv2.pdf"),
       plot = violin_HVG_cv2,
       device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
       path = path_for_figures,
       width = 20, height = 5, units = "in", dpi = 300,
       family = "Helvetica", bg = "transparent", pointsize = 12
       )

violin_HVG_cv2_block <- plotExpression(PAG_sceset_qc_norm_filt, features = rownames(hvg_cv2_out_no_spikes_block_filt)[1:50],
                                       exprs_values = "logcounts", theme_size = 12, point_alpha = 0.8
                                       ) + ggtitle("Top 50 HVGs from mean-cv2 modelling after blocking") + theme_args
violin_HVG_cv2_block
ggsave(filename = str_c(date, "_violin_HVG_cv2_block.pdf"),
       plot = violin_HVG_cv2_block,
       device = "pdf", # or one of "eps", "ps", "tex" (pictex), "pdf", "jpeg", "tiff", "png", "bmp", "svg" or "wmf" (windows only).
       path = path_for_figures,
       width = 20, height = 5, units = "in", dpi = 300,
       family = "Helvetica", bg = "transparent", pointsize = 12
       )
```

Now that we have ordered, filtered, and inspected the identified HVGs we can add the results to the `metadata` component of the `PAG_sceset_qc_norm_filt` object. The metadata component can hold any object, as it is a list container. Any results that we’d like to keep are safe to store here, and this is a great way to save or share intermediate results that would otherwise be kept in separate objects. We thus store the names of the HVGs from the different approaches we used (even without filtering) so we can go back and find them again for any future comparisons we might want to do:
```{r}
# hvg_var_out_no_spikes_filt
metadata(PAG_sceset_qc_norm_filt)$hvg_var_out_no_spikes <- rownames(hvg_var_out_no_spikes)
length(metadata(PAG_sceset_qc_norm_filt)$hvg_var_out_no_spikes)

metadata(PAG_sceset_qc_norm_filt)$hvg_var_out_no_spikes_filt <- rownames(hvg_var_out_no_spikes_filt)
length(metadata(PAG_sceset_qc_norm_filt)$hvg_var_out_no_spikes_filt)

# hvg_var_out_no_spikes_block_filt
metadata(PAG_sceset_qc_norm_filt)$hvg_var_out_no_spikes_block <- rownames(hvg_var_out_no_spikes_block)
length(metadata(PAG_sceset_qc_norm_filt)$hvg_var_out_no_spikes_block)

metadata(PAG_sceset_qc_norm_filt)$hvg_var_out_no_spikes_block_filt <- rownames(hvg_var_out_no_spikes_block_filt)
length(metadata(PAG_sceset_qc_norm_filt)$hvg_var_out_no_spikes_block_filt)

# hvg_cv2_out_no_spikes_filt
metadata(PAG_sceset_qc_norm_filt)$hvg_cv2_out_no_spikes <- rownames(hvg_cv2_out_no_spikes)
length(metadata(PAG_sceset_qc_norm_filt)$hvg_cv2_out_no_spikes)

metadata(PAG_sceset_qc_norm_filt)$hvg_cv2_out_no_spikes_filt <- rownames(hvg_cv2_out_no_spikes_filt)
length(metadata(PAG_sceset_qc_norm_filt)$hvg_cv2_out_no_spikes_filt)

# hvg_cv2_out_no_spikes_block_filt
metadata(PAG_sceset_qc_norm_filt)$hvg_cv2_out_no_spikes_block <- rownames(hvg_cv2_out_no_spikes_block)
length(metadata(PAG_sceset_qc_norm_filt)$hvg_cv2_out_no_spikes_block)

metadata(PAG_sceset_qc_norm_filt)$hvg_cv2_out_no_spikes_block_filt <- rownames(hvg_cv2_out_no_spikes_block_filt)
length(metadata(PAG_sceset_qc_norm_filt)$hvg_cv2_out_no_spikes_block_filt)
```

Just to ensure we keep everything, we also export the full table (not just the gene names) into a `.tsv` file:
```{r}
# Before filtering unwanted genes:
write.table(file = "PAG_hvg_var_out_no_spikes.tsv", hvg_var_out_no_spikes, sep = "\t", quote = FALSE, col.names = NA)
write.table(file = "PAG_hvg_var_out_no_spikes_block.tsv", hvg_var_out_no_spikes_block, sep = "\t", quote = FALSE, col.names = NA)
write.table(file = "PAG_hvg_cv2_out_no_spikes.tsv", hvg_cv2_out_no_spikes, sep = "\t", quote = FALSE, col.names = NA)
write.table(file = "PAG_hvg_cv2_out_no_spikes_block.tsv", hvg_cv2_out_no_spikes_block, sep = "\t", quote = FALSE, col.names = NA)

# After filtering unwanted genes:
write.table(file = "PAG_hvg_var_out_no_spikes_filt.tsv", hvg_var_out_no_spikes_filt, sep = "\t", quote = FALSE, col.names = NA)
write.table(file = "PAG_hvg_var_out_no_spikes_block_filt.tsv", hvg_var_out_no_spikes_block_filt, sep = "\t", quote = FALSE, col.names = NA)
write.table(file = "PAG_hvg_cv2_out_no_spikes_filt.tsv", hvg_cv2_out_no_spikes_filt, sep = "\t", quote = FALSE, col.names = NA)
write.table(file = "PAG_hvg_cv2_out_no_spikes_block_filt.tsv", hvg_cv2_out_no_spikes_block_filt, sep = "\t", quote = FALSE, col.names = NA)
```

And we finally plot the modelled trend with the selected HVGs colored:
```{r}
par(las = 1) # plot axis labels always horizontal (defaults to 0: always parallel to the axis)

# Identify selected HVGs from mean-var modelling without blocking
hvg_index_var <- which(names(var_fit_no_spikes$mean) %in% rownames(hvg_var_out_no_spikes_filt))

# Plot variance-mean trend without blocking
plot(var_fit_no_spikes$mean, 
     var_fit_no_spikes$var, 
     pch = 16, cex = 0.6,
     main = paste0("Mean-Variance relationship (no block) | ", length(hvg_index_var), " HVGs"),
     xlab = "Mean of log-expression", 
     ylab = "Variance of log-expression")
curve(var_fit_no_spikes$trend(x), col = "dodgerblue", add = TRUE, lwd = 2)
points(var_fit_no_spikes$mean[hvg_index_var], var_fit_no_spikes$var[hvg_index_var], col = "orange")

# Identify selected HVGs from mean-var modelling after blocking (although we plot them on the non-blocked graph instead of on 12 separate ones)
hvg_index_var_block <- which(names(var_fit_no_spikes$mean) %in% rownames(hvg_var_out_no_spikes_block_filt))
# Should be pretty similar to the previous plot

# Plot variance-mean trend without blocking
plot(var_fit_no_spikes$mean, 
     var_fit_no_spikes$var, 
     pch = 16, cex = 0.6,
     main = paste0("Mean-Variance relationship (block) | ", length(hvg_index_var_block), " HVGs"),
     xlab = "Mean of log-expression", 
     ylab = "Variance of log-expression")
curve(var_fit_no_spikes$trend(x), col = "dodgerblue", add = TRUE, lwd = 2)
points(var_fit_no_spikes$mean[hvg_index_var_block], var_fit_no_spikes$var[hvg_index_var_block], col = "orange")

# Identify selected HVGs from mean-cv2 modelling without blocking
hvg_index_cv2 <- which(names(CV2_fit_no_spikes$mean) %in% rownames(hvg_cv2_out_no_spikes_filt))

# Plot CV2 as a function of the mean without blocking and color HVGs differently
plot(CV2_fit_no_spikes$mean,
     CV2_fit_no_spikes$cv2, 
     log = "xy",
     pch = 16, cex = 0.6,
     main = paste0("Mean-CV2 relationship (no block) | ", length(hvg_index_cv2), " HVGs"),
     xlab = "Mean of normalized expression", 
     ylab = "CV2 of normalized expression", 
     xlim = c(1e-05, 1e+06))
curve(CV2_fit_no_spikes$trend(x), col = "dodgerblue", add = TRUE, lwd = 2)
points(CV2_fit_no_spikes$mean[hvg_index_cv2], CV2_fit_no_spikes$cv2[hvg_index_cv2], col = "orange")

# Identify selected HVGs from mean-cv2 modelling after blocking (although we plot them on the non-blocked graph instead of on 12 separate ones)
hvg_index_cv2_block <- which(names(CV2_fit_no_spikes$mean) %in% rownames(hvg_cv2_out_no_spikes_block_filt))

# Plot CV2 as a function of the mean without blocking and color HVGs differently
plot(CV2_fit_no_spikes$mean,
     CV2_fit_no_spikes$cv2, 
     log = "xy",
     pch = 16, cex = 0.6,
     main = paste0("Mean-CV2 relationship (block) | ", length(hvg_index_cv2_block), " HVGs"),
     xlab = "Mean of normalized expression", 
     ylab = "CV2 of normalized expression", 
     xlim = c(1e-05, 1e+06))
curve(CV2_fit_no_spikes$trend(x), col = "dodgerblue", add = TRUE, lwd = 2)
points(CV2_fit_no_spikes$mean[hvg_index_cv2_block], CV2_fit_no_spikes$cv2[hvg_index_cv2_block], col = "orange")

## Print the number of detected HVGs for each case:
length(hvg_index_var)
length(hvg_index_var_block)
length(hvg_index_cv2)
length(hvg_index_cv2_block)


## Save all the plots:
pdf(file = str_c(path_for_figures, date, "_trend_HVGs_var.pdf"),
    width = 12, height = 9, pointsize = 12,
    family = "Helvetica", bg = "transparent")
plot(var_fit_no_spikes$mean, 
     var_fit_no_spikes$var, 
     pch = 16, cex = 0.6,
     main = paste0("Mean-Variance relationship (no block) | ", length(hvg_index_var), " HVGs"),
     xlab = "Mean of log-expression", 
     ylab = "Variance of log-expression")
curve(var_fit_no_spikes$trend(x), col = "dodgerblue", add = TRUE, lwd = 2)
points(var_fit_no_spikes$mean[hvg_index_var], var_fit_no_spikes$var[hvg_index_var], col = "orange")
dev.off()

pdf(file = str_c(path_for_figures, date, "_trend_HVGs_var_block.pdf"),
    width = 12, height = 9, pointsize = 12,
    family = "Helvetica", bg = "transparent")
plot(var_fit_no_spikes$mean, 
     var_fit_no_spikes$var, 
     pch = 16, cex = 0.6,
     main = paste0("Mean-Variance relationship (block) | ", length(hvg_index_var_block), " HVGs"),
     xlab = "Mean of log-expression", 
     ylab = "Variance of log-expression")
curve(var_fit_no_spikes$trend(x), col = "dodgerblue", add = TRUE, lwd = 2)
points(var_fit_no_spikes$mean[hvg_index_var_block], var_fit_no_spikes$var[hvg_index_var_block], col = "orange")
dev.off()

pdf(file = str_c(path_for_figures, date, "_trend_HVGs_cv2.pdf"),
    width = 12, height = 9, pointsize = 12,
    family = "Helvetica", bg = "transparent")
plot(CV2_fit_no_spikes$mean,
     CV2_fit_no_spikes$cv2, 
     log = "xy",
     pch = 16, cex = 0.6,
     main = paste0("Mean-CV2 relationship (no block) | ", length(hvg_index_cv2), " HVGs"),
     xlab = "Mean of normalized expression", 
     ylab = "CV2 of normalized expression", 
     xlim = c(1e-05, 1e+06))
curve(CV2_fit_no_spikes$trend(x), col = "dodgerblue", add = TRUE, lwd = 2)
points(CV2_fit_no_spikes$mean[hvg_index_cv2], CV2_fit_no_spikes$cv2[hvg_index_cv2], col = "orange")
dev.off()

pdf(file = str_c(path_for_figures, date, "_trend_HVGs_cv2_block.pdf"),
    width = 12, height = 9, pointsize = 12,
    family = "Helvetica", bg = "transparent")
plot(CV2_fit_no_spikes$mean,
     CV2_fit_no_spikes$cv2, 
     log = "xy",
     pch = 16, cex = 0.6,
     main = paste0("Mean-CV2 relationship (block) | ", length(hvg_index_cv2_block), " HVGs"),
     xlab = "Mean of normalized expression", 
     ylab = "CV2 of normalized expression", 
     xlim = c(1e-05, 1e+06))
curve(CV2_fit_no_spikes$trend(x), col = "dodgerblue", add = TRUE, lwd = 2)
points(CV2_fit_no_spikes$mean[hvg_index_cv2_block], CV2_fit_no_spikes$cv2[hvg_index_cv2_block], col = "orange")
dev.off()
```

We can clearly see now why it is not a good idea to use the HVGs obtained from modelling the mean-cv2 trend after blocking, but we can do so for the mean-var trend.

## Step 4.4 | Save the filtered SingleCellExperiment object containing HVGs
```{r}
# Save the filtered data:
saveRDS(PAG_sceset_qc_norm_filt, file = "PAG_sceset_qc_norm_filt.rds")
print("Part 4 - Done!")
```

```{r}
sessionInfo()
```
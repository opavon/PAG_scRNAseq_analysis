---
title: "Topographic, single-cell gene expression profiling of Periaqueductal Gray neurons"
subtitle: "Part IV: modelling the technical noise and removing batch effects"
author:
  - name: "Oriol Pavon Arocas, Sarah F. Olesen, and Tiago Branco"
    affiliation: "Sainsbury Wellcome Centre for Neural Circuits and Behaviour, University College London, UK"
    email: "oriol.pavon.16@ucl.ac.uk"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_notebook:
    highlight: pygments
    number_sections: FALSE
    theme: lumen
    toc: TRUE
    toc_float: TRUE

#output: rmdformats::readthedown:
  #highlight: pygments
---

***

This is a pipeline to analyse single-cell RNA sequencing data from Periaqueductal Gray neurons (1) isolated from acute midbrain slices of transgenic mice using visually guided aspiration via patch pipettes and (2) processed using SMART-seq2 (Picelli et al., Nature Protocols 2014). 

This pipeline has been generated after attending the [EMBL-EBI RNA-Sequence Analysis Course](https://www.ebi.ac.uk/training/events/2019/rna-sequence-analysis) and [attending](https://training.csx.cam.ac.uk/bioinformatics/event/2823386) and following the online course on [Analysis of single cell RNA-seq data](https://github.com/hemberg-lab/scRNA.seq.course) by the [Hemberg Lab](https://www.sanger.ac.uk/science/groups/hemberg-group). Many other resources have been used, including the [Orchestrating Single-Cell Analysis with Bioconductor book](https://osca.bioconductor.org/) by Robert Amezquita and Stephanie Hicks, the [simpleSingleCell workflow in Bioconductor](https://bioconductor.org/packages/3.9/workflows/html/simpleSingleCell.html) maintained by Aaron Lun, the [rnaseqGene workflow](https://bioconductor.org/packages/3.10/workflows/html/rnaseqGene.html) maintained by Michael Love, the [RNAseq123 workflow](https://bioconductor.org/packages/3.10/workflows/html/RNAseq123.html) maintained by Matthew Ritchie, and the [EGSEA123 workflow](https://bioconductor.org/packages/3.10/workflows/html/EGSEA123.html) maintained by Matthew Ritchie.

Other key resources include [Bioconductor](http://www.bioconductor.org/) (Huber et al., Nature Methods 2015), [scRNA-tools](https://www.scrna-tools.org/), `scater` (McCarthy et al., Bioinformatics 2017), `scran` (Lun et al., F1000Res 2016), `SC3` (Kiselev et al., Nature Methods 2017), `Seurat` (Butler et al., Nature Biotechnology 2018), `clusterExperiment` (Risso et al., PLOS Computational Biology 2018), `limma` (Ritchie et al., Nucleic Acids Research 2015), `DESeq2` (Love et al., Genome Biology 2014), `edgeR` (Robinson et al., Bioinformatics 2010), `MAST` (Finak, McDavid, Yajima et al., Genome Biology 2015), `iSEE` (Rue-Albrecht & Marini et al., F1000Research 2018), `t-SNE` (van der Maaten & Hinton, Journal of Machine Learning Research 2008), `UMAP` (McInnes et al., arXiv 2018), and the [Mathematical Statistics and Machine Learning for Life Sciences](https://towardsdatascience.com/tagged/stats-ml-life-sciences) column by Nikolay Oskolkov.

***

# STEP 4 | Modelling technical and biological variability in gene expression to identify highly variable genes
__Based on the [OSCA book](https://osca.bioconductor.org/feature-selection.html), the [simpleSingleCell workflow in Bioconductor](https://bioconductor.org/packages/3.9/workflows/html/simpleSingleCell.html), and [Description of the HVG machinery in scran](https://github.com/LTLA/HVGDetection2018) maintained by Aaron Lun.__

We often use scRNA-seq data in exploratory analyses to characterize heterogeneity across cells. Procedures like clustering and dimensionality reduction compare cells based on their gene expression profiles, which involves aggregating per-gene differences into a single (dis)similarity metric between a pair of cells. The choice of genes to use in this calculation has a major impact on the behavior of the metric and the performance of downstream methods. We want to select genes that contain useful information about the biology of the system while removing genes that contain random noise. This aims to preserve interesting biological structure without the variance that obscures that structure, and to reduce the size of the data to improve computational efficiency of later steps.

The simplest approach to feature selection is to select the most variable genes based on their expression across the population. This assumes that genuine biological differences will manifest as increased variation in the affected genes, compared to other genes that are only affected by technical noise or a baseline level of “uninteresting” biological variation (e.g., from transcriptional bursting). Several methods are available to quantify the variation per gene and to select an appropriate set of highly variable genes (HVGs).

We continue using the `PAG_sceset_qc_norm` after normalization. We should thus have a `logcounts` slot in `assays`:
```{r}
# If starting from stored results, load saved filtered dataset from previous Step:
set.seed(1991)
options(stringsAsFactors = FALSE)
library(SingleCellExperiment)
library(scater)
library(scran)

PAG_sceset_qc_norm <- readRDS("PAG_sceset_qc_norm.rds") # Contains filtered cells and genes, and log-normalized data
assayNames(PAG_sceset_qc_norm)
PAG_sceset_qc_norm
```

## Step 4.1 | Quantifying per-gene variation
Variability in the observed expression values across genes can be driven by genuine biological heterogeneity or uninteresting technical noise. To distinguish between these two possibilties, we need to model the technical component of the variance of the expression values for each gene.

### 4.1.1 | Variance of the log-counts
The simplest approach to quantifying per-gene variation is to simply compute the variance of the log-normalized expression values (referred to as “log-counts” for simplicity) for each gene across all cells in the population (A. T. L. Lun, McCarthy, and Marioni 2016). This has an advantage in that the feature selection is based on the same log-values that are used for later downstream steps. In particular, genes with the largest variances in log-values will contribute the most to the Euclidean distances between cells. By using log-values here, we ensure that our quantitative definition of heterogeneity is consistent throughout the entire analysis.

Calculation of the per-gene variance is simple but feature selection requires modelling of the mean-variance relationship. The log-transformation does not achieve perfect variance stabilization, which means that the variance of a gene is driven more by its abundance than its underlying biological heterogeneity. To account for this effect, we use the `modelGeneVar()` function to fit a trend to the variance with respect to abundance across all genes.
```{r}
library(scran)
start_time <- Sys.time() # Takes around 1s
var_model_no_spikes <- modelGeneVar(PAG_sceset_qc_norm,
                                    min.mean = 0.1, parametric = TRUE)
# If block is not specified, the metadata of the DataFrame contains the output of running `fitTrendVar` on the specified features, along with the mean and var used to fit the trend.
var_fit_no_spikes <- metadata(var_model_no_spikes) 
end_time <- Sys.time()
end_time - start_time
```

We visually inspect the trend to confirm that it corresponds to the spike-in variances. A wave-like shape is typical of the mean-variance trend for log-expression values. A linear increase in the variance is observed as the mean increases from zero, as larger variances are obviously possible when the counts are not all equal to zero. In contrast, the relative contribution of sampling noise decreases at high abundances, resulting in a downward trend. The peak represents the point at which these two competing effects cancel each other out.
```{r}
# Plot variance-mean trend without blocking
plot(var_fit_no_spikes$mean, 
     var_fit_no_spikes$var, 
     pch = 16, cex = 0.6,
     xlab = "Mean of log-expression", 
     ylab = "Variance of log-expression")

curve(var_fit_no_spikes$trend(x), col = "dodgerblue", add = TRUE, lwd = 2)
```

At any given abundance, we assume that the expression profiles of most genes are dominated by random technical noise. Under this assumption, our trend represents an estimate of the technical noise as a function of abundance. We then break down the total variance of each gene into the technical component, i.e., the fitted value of the trend at that gene’s abundance; and the biological component, defined as the difference between the total variance and the technical component. This biological component represents the “interesting” variation for each gene and can be used as the metric for HVG selection. Some genes will have negative biological components, which have no obvious interpretation and can be ignored in most applications. They are inevitable when fitting a trend to the per-gene variances as approximately half of the genes will lie below the trend.
```{r}
head(var_model_no_spikes[order(var_model_no_spikes$bio, decreasing = TRUE),])
```

### 4.1.2 | Coefficient of variation
An alternative approach to quantification uses the squared coefficient of variation (CV2) of the normalized expression values prior to log-transformation. The CV2 is a widely used metric for describing variation in non-negative data and is closely related to the dispersion parameter of the negative binomial distribution in packages like _edgeR_ and _DESeq2_. We can compute the CV2 for each gene in the dataset using the `modelGeneCV2()` function, which provides a robust implementation of the approach described by Brennecke et al. (2013).
```{r}
start_time <- Sys.time() # Takes around 1s
CV2_model_no_spikes <- modelGeneCV2(PAG_sceset_qc_norm)
CV2_fit_no_spikes <- metadata(CV2_model_no_spikes)
end_time <- Sys.time()
end_time - start_time
```

This allows us to model the mean-variance relationship when considering the relevance of each gene. Again, our assumption is that most genes contain random noise and that the trend captures mostly technical variation. Large CV2 values that deviate strongly from the trend are likely to represent genes affected by biological structure.
```{r}
# Plot CV2 as a function of the mean without blocking
plot(CV2_fit_no_spikes$mean,
     CV2_fit_no_spikes$cv2, 
     log = "xy",
     pch = 16, cex = 0.6,
     xlab = "Mean of expression", 
     ylab = "CV2 of expression", 
     xlim = c(1e-05, 1e+06))
curve(CV2_fit_no_spikes$trend(x), col = "dodgerblue", add = TRUE, lwd = 2)
```

For each gene, we quantify the deviation from the trend in terms of the ratio of its CV2 to the fitted value of trend at its abundance. This is more appropriate than the directly subtracting the trend from the CV2, as the magnitude of the ratio is not affected by the mean.
```{r}
head(CV2_model_no_spikes[order(CV2_model_no_spikes$ratio, decreasing = TRUE),])
```

Both the CV2 and the variance of log-counts are effective metrics for quantifying variation in gene expression. The CV2 tends to give higher rank to low-abundance HVGs driven by upregulation in rare subpopulations, for which the increase in variance on the raw scale is stronger than that on the log-scale. However, the variation described by the CV2 is less directly relevant to downstream procedures operating on the log-counts, and the reliance on the ratio can assign high rank to uninteresting genes with low absolute variance. We generally prefer the use of the variance of log-counts and will use it in the following sections, though the many of the same principles apply to procedures based on the CV2.

### 4.1.3 | Quantifying technical noise using spike-ins [not used]
Strictly speaking, the use of a trend fitted to endogenous genes assumes that the expression profiles of most genes are dominated by random technical noise. In practice, all expressed genes will exhibit some non-zero level of biological variability due to events like transcriptional bursting. This suggests that our estimates of the technical component are likely to be inflated. It would be more appropriate to consider these estimates as technical noise plus “uninteresting” biological variation, under the assumption that most genes are unaffected by the relevant heterogeneity in the population.

This revised assumption is generally reasonable but may be problematic in some scenarios where many genes at a particular abundance are affected by a biological process. For example, strong upregulation of cell type-specific genes may result in an enrichment of HVGs at high abundances. This would inflate the fitted trend in that abundance interval and compromise the detection of the relevant genes. We can avoid this problem by fitting a mean-dependent trend to the variance of the spike-in transcripts, if they are available. The premise here is that spike-ins were in theory added in the same quantity to each cell and thus should not be affected by biological variation (i.e., any variance in their counts should be technical in origin), so the fitted value of the spike-in trend should represent a better estimate of the technical component for each gene.
```{r}
#start_time <- Sys.time() # Takes around 5s
#var_model_spikes <- modelGeneVarWithSpikes(PAG_sceset_qc_norm, "ERCC")
#var_fit_spikes <- metadata(var_model_spikes)
#head(var_model_spikes[order(var_model_spikes$bio, decreasing = TRUE),])
#end_time <- Sys.time()
#end_time - start_time

# Plot variance-mean trend using spike-ins
#plot(var_model_spikes$mean,
     #var_model_spikes$total, 
     #xlab = "Mean of log-expression",
     #ylab = "Variance of log-expression")
#points(var_fit_spikes$mean, var_fit_spikes$var, col = "red", pch = 16)
#curve(var_fit_spikes$trend(x), col = "dodgerblue", add = TRUE, lwd = 2)
```

Trends based purely on technical noise tend to yield large biological components for highly-expressed genes. This often includes so-called “house-keeping” genes coding for essential cellular components such as ribosomal proteins, which are considered uninteresting for characterizing cellular heterogeneity. These observations suggest that a more accurate noise model does not necessarily yield a better ranking of HVGs, though one should keep an open mind - house-keeping genes are regularly DE in a variety of conditions (Glare et al. 2002; Nazari, Parham, and Maleki 2015; Guimaraes and Zavolan 2016), and the fact that they have large biological components indicates that there is strong variation across cells that may not be completely irrelevant.

Ideally, the technical component would be estimated by fitting a mean-variance trend to the spike-in transcripts. In practice, this strategy is compromised by the small number of spike-in transcripts, the uneven distribution of their abundances, and (for low numbers of cells) the imprecision of their variance estimates. This makes it difficult to accurately fit a complex mean-dependent trend to the spike-in variances. In some datasets, spike-in RNA may not have been added in appropriate quantities (or indeed at all). In our case, we don't detect all ERCCs in all the cells, so using them to model the variance in our dataset will yield poor results. It may also be inappropriate to assume Poisson technical noise, especially for read count data where amplification noise is non-negligible. In such cases, an alternative approach is to fit the trend to the variance estimates of the endogenous genes. This assumes that the majority of genes are not variably expressed, such that the technical component dominates the total variance for those genes. The fitted value of the trend is then used as an estimate of the technical component. 

### 4.1.4 | Accounting for blocking factors
Data containing multiple batches will often exhibit batch effects. We are usually not interested in HVGs that are driven by batch effects. Rather, we want to focus on genes that are highly variable within each batch. This is naturally achieved by performing trend fitting and variance decomposition separately for each batch.
```{r}
library(scran)
start_time <- Sys.time() # Takes around 20s
var_model_no_spikes_block <- modelGeneVar(PAG_sceset_qc_norm,
                                          block = PAG_sceset_qc_norm$batch.processing,
                                          min.mean = 0.1, parametric = TRUE)
head(var_model_no_spikes_block[order(var_model_no_spikes_block$bio, decreasing=TRUE),1:6])
end_time <- Sys.time()
end_time - start_time
```

The use of a batch-specific trend fit is useful as it accommodates differences in the mean-variance trends between batches. This is especially important if batches exhibit systematic technical differences, e.g., differences in coverage or in the amount of spike-in RNA added. 
```{r}
par(mfrow = c(4,6))
blocked.stats <- var_model_no_spikes_block$per.block
for (i in colnames(blocked.stats)) {
    current <- blocked.stats[[i]]
    plot(current$mean, 
         current$total,
         main = i, pch = 16, cex = 0.6,
         xlab = "Mean of log-expression", 
         ylab = "Variance of log-expression",
         xlim = c(0,20), ylim = c(0,30))
    curfit <- metadata(current)
    curve(curfit$trend(x), col = 'dodgerblue', add = TRUE, lwd = 2) 
}
```

## Step 4.2 | Strategies to identify highly variable genes
Once we have quantified the per-gene variation, the next step is to select the subset of HVGs to use in downstream analyses. Formal detection of HVGs allows us to avoid genes that are highly variable due to technical factors such as sampling noise during RNA capture and library preparation. A large subset will reduce the risk of discarding interesting biological signal by retaining more potentially relevant genes, at the cost of increasing noise from irrelevant genes that might obscure said signal. It is thus difficult to determine the optimal trade-off for any given application as noise in one context may be useful signal in another.

There are different ways to define HVGs. We could select the genes with biological components that are significantly greater than zero at a false discovery rate (FDR) of 5% or 1%. These genes are interesting as they drive differences in the expression profiles between cells, and should be prioritized for further investigation. In addition, we could consider a gene to be a HVG only if it has a biological component greater than or equal to 0.5. For transformed expression values on the log2 scale, this would mean that the average difference in true expression between any two cells will be at least 2-fold. We could also rank the results by the biological component to focus on genes with larger biological variability, and then choose a certain proportion of genes from the total.

### 4.2.1 | Based on the largest metrics
The simplest HVG selection strategy is to take the top X genes with the largest values for the relevant variance metric. The main advantage of this approach is that the user can directly control the number of genes retained, which ensures that the computational complexity of downstream calculations is easily predicted. 

The choice of X has a fairly straightforward biological interpretation. Recall our trend-fitting assumption that most genes do not exhibit biological heterogeneity; this implies that they are not differentially expressed between cell types or states in our population. If we quantify this assumption into a statement that, e.g., no more than 5% of genes are differentially expressed, we can naturally set X to 5% of the number of genes. In practice, we usually do not know the proportion of DE genes beforehand so this interpretation just exchanges one unknown for another. Nonetheless, it is still useful as it implies that we should lower X for less heterogeneous datasets, retaining most of the biological signal without unnecessary noise from irrelevant genes. Conversely, more heterogeneous datasets should use larger values of X to preserve secondary factors of variation beyond those driving the most obvious HVGs.

The main disadvantage of this approach is that it turns HVG selection into a competition between genes, whereby a subset of very highly variable genes can push other informative genes out of the top set. This can be problematic for analyses of highly heterogeneous populations if the loss of important markers prevents the resolution of certain subpopulations. In the most extreme example, consider a situation where a single subpopulation is very different from the others. In such cases, the top set will be dominated by differentially expressed genes involving that distinct subpopulation, compromising resolution of heterogeneity between the other populations. 

Another possible concern with this approach is the fact that the choice of X is fairly arbitrary, with any value from 500 to 5000 considered “reasonable”. The recommendation is to simply pick an arbitrary X and proceed with the rest of the analysis, with the intention of testing other choices later, rather than spending much time worrying about obtaining the “optimal” value.

### 4.2.2 | Based on significance
Another approach to feature selection is to set a fixed threshold of one of the metrics. This is most commonly done with the (adjusted) p-value reported by each of the above methods. The p-value for each gene is generated by testing against the null hypothesis that the variance is equal to the trend. For example, we might define our HVGs as all genes that have adjusted p-values below 0.05.

This approach is simple to implement and - if the test holds its size - it controls the false discovery rate (FDR). That is, it returns a subset of genes where the proportion of false positives is expected to be below the specified threshold. This can occasionally be useful in applications where the HVGs themselves are of interest. For example, if we were to use the list of HVGs in further experiments to verify the existence of heterogeneous expression for some of the genes, we would want to control the FDR in that list.

The downside of this approach is that it is less predictable than the top X strategy. The number of genes returned depends on the type II error rate of the test and the severity of the multiple testing correction. One might obtain no genes or every gene at a given FDR threshold, depending on the circumstances. Moreover, control of the FDR is usually not helpful at this stage of the analysis. We are not interpreting the individual HVGs themselves but are only using them for feature selection prior to downstream steps. There is no reason to think that a 5% threshold on the FDR yields a more suitable compromise between bias and noise compared to the top X selection.

As an aside, we might consider ranking genes by the p-value instead of the biological component for use in a top X approach. This results in some counterintuitive behavior due to the nature of the underlying hypothesis test, which is based on the ratio of the total variance to the expected technical variance. Ranking based on p-value tends to prioritize HVGs that are more likely to be true positives but, at the same time, less likely to be biologically interesting. Many of the largest ratios are observed in high-abundance genes and are driven by very low technical variance; the total variance is typically modest for such genes, and they do not contribute much to population heterogeneity in absolute terms. (Note that the same can be said of the ratio of CV2 values.)
 
### 4.2.3 | Keeping all genes above the trend
We can also only remove the obviously uninteresting genes with variances below the trend. By doing so, we avoid the need to make any judgement calls regarding what level of variation is interesting enough to retain. This approach represents one extreme of the bias-variance trade-off where bias is minimized at the cost of maximizing noise. For `modelGeneVar()`, it equates to keeping all positive biological components, whereas for `modelGeneCV2()`, this involves keeping all ratios above 1.

By retaining all potential biological signal, we give secondary population structure the chance to manifest. This is most useful for rare subpopulations where the relevant markers will not exhibit strong overdispersion owing to the small number of affected cells. It will also preserve a weak but consistent effect across many genes with small biological components; admittedly, though, this is not of major interest in most scRNA-seq studies given the difficulty of experimentally validating population structure in the absence of strong marker genes.

The obvious cost is that more noise is also captured, which can reduce the resolution of otherwise well-separated populations and mask the secondary signal that we were trying to preserve. The use of more genes also introduces more computational work in each downstream step. This strategy is thus best suited to very heterogeneous populations containing many different cell types (possibly across many datasets that are to be merged, as in Chapter 13) where there is a justified fear of ignoring marker genes for low-abundance subpopulations under a competitive top X approach.

### 4.2.4 | Based on a priori genes of interest
A blunt yet effective feature selection strategy is to use pre-defined sets of interesting genes. The aim is to focus on specific aspects of biological heterogeneity that may be masked by other factors when using unsupervised methods for HVG selection. One example application lies in the dissection of transcriptional changes during the earliest stages of cell fate commitment (Messmer et al. 2019), which may be modest relative to activity in other pathways (e.g., cell cycle, metabolism). Indeed, if our aim is to show that there is no meaningful heterogeneity in a given pathway, we would - at the very least - be obliged to repeat our analysis using only the genes in that pathway to maximize power for detecting such heterogeneity.

Using scRNA-seq data in this manner is conceptually equivalent to a fluorescence activated cell sorting (FACS) experiment, with the convenience of being able to (re)define the features of interest at any time. For example, in the PBMC dataset, we might use some of the C7 immunologic signatures from MSigDB (Godec et al. 2016) to improve resolution of the various T cell subtypes. We stress that there is no shame in leveraging prior biological knowledge to address specific hypotheses in this manner. We say this because a common refrain in genomics is that the data analysis should be “unbiased”, i.e., free from any biological preconceptions. Attempting to derive biological insight ab initio is admirable but such “biases” are already present at every stage, starting from experimental design (why are we interested in this cell population in the first place?) and continuing through to interpretation of marker genes.

Of course, the downside of focusing on pre-defined genes is that it will limit our capacity to detect novel or unexpected aspects of variation. Thus, this kind of focused analysis should be complementary to (rather than a replacement for) the unsupervised feature selection strategies discussed previously.

Alternatively, we can also invert this reasoning to remove genes that are unlikely to be of interest prior to downstream analyses, thus avoiding unwanted variation that interferes with downstream interpretation. Common candidates for removal include ribosomal protein genes or mitochondrial genes; for immune cell subsets, we might also be inclined to remove immunoglobulin genes and T cell receptor genes, where clonal expression introduces (possibly irrelevant) population structure. In practice, we tend to err on the side of caution and abstain from preemptive filtering on biological function until these genes are demonstrably problematic in downstream analyses.

## Step 4.3 | Selecting HVGs in our dataset
We extract and rank the results to focus on genes with larger biological components. This highlights an interesting aspect of the underlying hypothesis test, which is based on the ratio of the total variance to the expected technical variance. Ranking based on p-value tends to prioritize HVGs that are more likely to be true positives but, at the same time, less likely to be interesting. This is because the ratio can be very large for HVGs that have very low total variance and do not contribute much to the cell-cell heterogeneity.

For `modelGeneVar()` and `modelGeneVarWithSpikes()`, we would select the genes with the largest biological components:
```{r}
# The `getTopHVGs()` function dentifies all genes where the relevant metric of variation is greater than var.threshold
hvg_var_no_spikes <- getTopHVGs(var_model_no_spikes,
                                var.field = "bio", var.threshold = 1, # Select all genes with positive biological components above a certain threshold
                                n = round(nrow(var_model_no_spikes)*0.15) # Select the top `n` number or proportion of genes
                                #fdr.field = "FDR", fdr.threshold = 0.05 # Select those genes with an adjusted p-value below 5% FDR
                                )
str(hvg_var_no_spikes)

# To export not just the names but also the output from the `modelGeneVar() we can do as follows:
hvg_var_out_no_spikes <- var_model_no_spikes[order(var_model_no_spikes$bio, decreasing = TRUE),]
hvg_var_out_no_spikes <- hvg_var_out_no_spikes[hvg_var_no_spikes,]
head(hvg_var_out_no_spikes)
dim(hvg_var_out_no_spikes)
```

We do the same for the variance modeling blocking by `batch.processing`
```{r}
# The `getTopHVGs()` function dentifies all genes where the relevant metric of variation is greater than var.threshold
hvg_var_no_spikes_block <- getTopHVGs(var_model_no_spikes_block,
                                      var.field = "bio", var.threshold = 1, # Select all genes with positive biological components above a certain threshold
                                      n = round(nrow(var_model_no_spikes_block)*0.15) # Select the top `n` number or proportion of genes
                                      #fdr.field = "FDR", fdr.threshold = 0.05 # Select those genes with an adjusted p-value below 5% FDR
                                      )
str(hvg_var_no_spikes_block)

# To export not just the names but also the output from the `modelGeneVar() we can do as follows:
hvg_var_out_no_spikes_block <- var_model_no_spikes_block[order(var_model_no_spikes_block$bio, decreasing = TRUE),]
hvg_var_out_no_spikes_block <- hvg_var_out_no_spikes_block[hvg_var_no_spikes_block,]
head(hvg_var_out_no_spikes_block[,1:6])
dim(hvg_var_out_no_spikes_block)
```

For `modelGeneCV2()` (and its relative, `modelGeneCV2WithSpikes()`), this would instead be the genes with the largest ratios:
```{r}
hvg_cv2_no_spikes <- getTopHVGs(CV2_model_no_spikes, 
                                var.field="ratio", var.threshold = 1,
                                n = round(nrow(CV2_model_no_spikes)*0.15) # Select the top `n` number or proportion of genes
                                #fdr.field = "FDR", fdr.threshold = 0.05 # Select those genes with an adjusted p-value below 5% FDR
                                )
str(hvg_cv2_no_spikes)

# To export not just the names but also the output from the `modelGeneVar() we can do as follows:
hvg_cv2_out_no_spikes <- CV2_model_no_spikes[order(CV2_model_no_spikes$ratio, decreasing = TRUE),]
hvg_cv2_out_no_spikes <- hvg_cv2_out_no_spikes[hvg_cv2_no_spikes,]
head(hvg_cv2_out_no_spikes)
dim(hvg_cv2_out_no_spikes)
```

### 4.3.1 | Filter uninteresting genes from the dataset
__One important thing...__
Before moving on to downstream analysis, we consider dropping any Ribosomal, Mitochondrial, ERCC, sex-specific genes (e.g. XIST), transgenes (EYFP, tdTomato, Cre, TSO concatamers) and genes used for transgenic labeling of cells (VGAT and VGluT2) from the dataset, as some of them are not be biologically informative and others have been used to select the cells. We do so for both our `SingleCellExperiment` object and for the different HVGs:
```{r}
##### 
##Identify the genes we want to drop:
# ERCCs
rowData(PAG_sceset_qc_norm)$is_spike <- grepl("^ERCC-", rownames(PAG_sceset_qc_norm))
# Mitochondrial genes
rowData(PAG_sceset_qc_norm)$is_mitochondrial <- (rowData(PAG_sceset_qc_norm)$Chromosome == "M") # Select the mitochondrial chromosome
# Ribosomal genes, if you somehow marked the ribosomal gene IDs.
rowData(PAG_sceset_qc_norm)$is_ribosomal <- (rowData(PAG_sceset_qc_norm)$gene_biotype == "rRNA")
# Genes from sex chromosomes
rowData(PAG_sceset_qc_norm)$is_X <- (rowData(PAG_sceset_qc_norm)$Chromosome == "X")
rowData(PAG_sceset_qc_norm)$is_Y <- (rowData(PAG_sceset_qc_norm)$Chromosome == "Y")
# EYFP, tdTomato, Cre, and TSO concatamers
rowData(PAG_sceset_qc_norm)$is_tdTomato <- (rowData(PAG_sceset_qc_norm)$Chromosome == "A") # tdTomato fluorophor
rowData(PAG_sceset_qc_norm)$is_EYFP <- (rowData(PAG_sceset_qc_norm)$Chromosome == "B") # EYFP fluorophor
rowData(PAG_sceset_qc_norm)$is_Cre <- (rowData(PAG_sceset_qc_norm)$Chromosome == "C") # Cre transgene to express fluorophors
rowData(PAG_sceset_qc_norm)$is_SmartSeqTSO <- (rowData(PAG_sceset_qc_norm)$Chromosome == "D") # TSO concatamers
# VGAT and VGluT2
rowData(PAG_sceset_qc_norm)$is_VGAT <- (rowData(PAG_sceset_qc_norm)$gene_name == "Slc32a1")
rowData(PAG_sceset_qc_norm)$is_VGluT2 <- (rowData(PAG_sceset_qc_norm)$gene_name == "Slc17a6") 

###### 
## Merge all the genes to exclude:
rowData(PAG_sceset_qc_norm)$filter_genes_qc_norm <- !(rowData(PAG_sceset_qc_norm)$is_spike | 
                                                        rowData(PAG_sceset_qc_norm)$is_mitochondrial | 
                                                        rowData(PAG_sceset_qc_norm)$is_ribosomal | 
                                                        rowData(PAG_sceset_qc_norm)$is_X | 
                                                        rowData(PAG_sceset_qc_norm)$is_Y |
                                                        rowData(PAG_sceset_qc_norm)$is_tdTomato | 
                                                        rowData(PAG_sceset_qc_norm)$is_EYFP | 
                                                        rowData(PAG_sceset_qc_norm)$is_Cre | 
                                                        rowData(PAG_sceset_qc_norm)$is_SmartSeqTSO | 
                                                        rowData(PAG_sceset_qc_norm)$is_VGAT | 
                                                        rowData(PAG_sceset_qc_norm)$is_VGluT2)
sum(!rowData(PAG_sceset_qc_norm)$filter_genes_qc_norm)

#####
## Apply the filter to the SingleCellExperiment object:
dim(PAG_sceset_qc_norm)
PAG_sceset_qc_norm_filt <- PAG_sceset_qc_norm[rowData(PAG_sceset_qc_norm)$filter_genes_qc_norm, ]
dim(PAG_sceset_qc_norm_filt)

#####
## Apply the filter to the HVGs:
filt_hvg_var <- rownames(hvg_var_out_no_spikes) %in% rownames(PAG_sceset_qc_norm_filt)
hvg_var_out_no_spikes_filt <- hvg_var_out_no_spikes[filt_hvg_var, ]
nrow(hvg_var_out_no_spikes_filt)

filt_hvg_var_block <- rownames(hvg_var_out_no_spikes_block) %in% rownames(PAG_sceset_qc_norm_filt)
hvg_var_out_no_spikes_block_filt <- hvg_var_out_no_spikes_block[filt_hvg_var_block, ]
nrow(hvg_var_out_no_spikes_block_filt)

filt_hvg_cv2 <- rownames(hvg_cv2_out_no_spikes) %in% rownames(PAG_sceset_qc_norm_filt)
hvg_cv2_out_no_spikes_filt <- hvg_cv2_out_no_spikes[filt_hvg_cv2, ]
nrow(hvg_cv2_out_no_spikes_filt)
```

### 4.3.2 | Visualize, store, and export HVGs
Now that we have removed the genes we are not interested in, we can use `limma` and `vennDiagram` to compare how many genes we get in each condition:
```{r}
library(limma)
# Inspect the overlap between HVGs obtained with the different approaches:
sum(rownames(hvg_var_out_no_spikes_filt) %in% rownames(hvg_var_out_no_spikes_block_filt))
sum(rownames(hvg_var_out_no_spikes_filt) %in% rownames(hvg_cv2_out_no_spikes_filt))
sum(rownames(hvg_cv2_out_no_spikes_filt) %in% rownames(hvg_var_out_no_spikes_block_filt))
venn_diag <- vennCounts(cbind(rownames(PAG_sceset_qc_norm_filt) %in% rownames(hvg_var_out_no_spikes_filt),
                              rownames(PAG_sceset_qc_norm_filt) %in% rownames(hvg_var_out_no_spikes_block_filt),
                              rownames(PAG_sceset_qc_norm_filt) %in% rownames(hvg_cv2_out_no_spikes_filt))
                        )
vennDiagram(venn_diag,
            names = c("Variance", "Variance $ Block", "CV2"),
            circle.col = c("#E69F00", "#56B4E9", "#009E73")
            )
```

Taking into account the above Venn Diagrams, it seems that modeling the variance with blocking by `batch.processing` captures almost all the genes captured without blocking. There list of HVGs for the variance and the CV2 modeling are quite different. We will thus keep all groups and compare them in the downstream analysis.

Before we store the identified HVGs in our `SingleCellExperiment` object, we check the distribution of expression values for the genes with the largest biological components to ensure that the variance estimate is not being dominated by one or two outlier cells.
```{r}
fontsize <- theme(axis.text = element_text(size = 12), axis.title = element_text(size = 16))

plotExpression(PAG_sceset_qc_norm_filt, features = rownames(hvg_var_out_no_spikes_filt)[1:50]) + fontsize
plotExpression(PAG_sceset_qc_norm_filt, features = rownames(hvg_var_out_no_spikes_block_filt)[1:50]) + fontsize
plotExpression(PAG_sceset_qc_norm_filt, features = rownames(hvg_cv2_out_no_spikes_filt)[1:50]) + fontsize
```

Now that we have ordered, filtered, and inspected the identified HVGs we can add the results into the `metadata` component of the `PAG_sceset_qc_norm_filt` object. The metadata component can hold any object, as it is a list container. Any results that we’d like to keep are safe to store here, and a great way to save or share intermediate results that would otherwise be kept in separate objects. We thus store the HVGs from the different approaches we used (even without filtering) so we can go back and find them again for any future comparisons we might want to do:
```{r}
# hvg_var_out_no_spikes_filt
metadata(PAG_sceset_qc_norm_filt)$hvg_var_out_no_spikes <- rownames(hvg_var_out_no_spikes)
length(metadata(PAG_sceset_qc_norm_filt)$hvg_var_out_no_spikes)

metadata(PAG_sceset_qc_norm_filt)$hvg_var_out_no_spikes_filt <- rownames(hvg_var_out_no_spikes_filt)
length(metadata(PAG_sceset_qc_norm_filt)$hvg_var_out_no_spikes_filt)

# hvg_var_out_no_spikes_block_filt
metadata(PAG_sceset_qc_norm_filt)$hvg_var_out_no_spikes_block <- rownames(hvg_var_out_no_spikes_block)
length(metadata(PAG_sceset_qc_norm_filt)$hvg_var_out_no_spikes_block)

metadata(PAG_sceset_qc_norm_filt)$hvg_var_out_no_spikes_block_filt <- rownames(hvg_var_out_no_spikes_block_filt)
length(metadata(PAG_sceset_qc_norm_filt)$hvg_var_out_no_spikes_block_filt)

# hvg_cv2_out_no_spikes_filt
metadata(PAG_sceset_qc_norm_filt)$hvg_cv2_out_no_spikes <- rownames(hvg_cv2_out_no_spikes)
length(metadata(PAG_sceset_qc_norm_filt)$hvg_cv2_out_no_spikes)

metadata(PAG_sceset_qc_norm_filt)$hvg_cv2_out_no_spikes_filt <- rownames(hvg_cv2_out_no_spikes_filt)
length(metadata(PAG_sceset_qc_norm_filt)$hvg_cv2_out_no_spikes_filt)
```

We can also export them into a `.tsv` file:
```{r}
# Before filtering unwanted genes:
#write.table(file="PAG_hvg_var_out_no_spikes.tsv", hvg_var_out_no_spikes, sep="\t", quote=FALSE, col.names=NA)
#write.table(file="PAG_hvg_var_out_no_spikes_block.tsv", hvg_var_out_no_spikes_block, sep="\t", quote=FALSE, col.names=NA)
#write.table(file="PAG_hvg_cv2_out_no_spikes.tsv", hvg_cv2_out_no_spikes, sep="\t", quote=FALSE, col.names=NA)

# After filtering unwanted genes:
write.table(file="PAG_hvg_var_out_no_spikes_filt.tsv", hvg_var_out_no_spikes_filt, sep="\t", quote=FALSE, col.names=NA)
write.table(file="PAG_hvg_var_out_no_spikes_block_filt.tsv", hvg_var_out_no_spikes_block_filt, sep="\t", quote=FALSE, col.names=NA)
write.table(file="PAG_hvg_cv2_out_no_spikes_filt.tsv", hvg_cv2_out_no_spikes_filt, sep="\t", quote=FALSE, col.names=NA)
```

## Step 4.4 | Save the filtered SingleCellExperiment object
```{r}
# Save the filtered data:
saveRDS(PAG_sceset_qc_norm_filt, file = "PAG_sceset_qc_norm_filt.rds")
print("Part 4 - Done!")
```

# STEP 5 | Identifying confounding factors and correcting batch effects factors
To account for technical confounders we need to identify and remove sources of variation in the expression data that are not related to the biological signal of interest. We could use spike-ins for this (in theory you add the same amount of ERCC in each cell lysate, so any variability should be technical noise), but these can turn out to be extremely variable across cells. Instead, we could use endogenous or housekeeping genes that do not vary systematically between cells. Where we have a large number of endogenous genes that, on average, do not vary systematically between cells and where we expect technical effects to affect a large number of genes (a very common and reasonable assumption), then such methods of batch correction can perform well.

The most prominent technical covariates in single-cell data are count depth and batch (Luecken & Theis, Mol Syst Biol. 2019). Correcting for batch effects between samples or cells in the same experiment is the classical scenario known as _batch correction_ from bulk RNA-seq. This is different from _data integration_ from multiple experiments or collaborative projects. Irrespective of computational methods, the best method of batch correction is pre-empting the effect and avoiding it altogether by clever experimental design (Hicks et al, 2017). Batch effects can be avoided by pooling cells across experimental conditions and samples. 

Our data have been collected from samples originated from several animals and processed on different days. Small uncontrollable differences in processing between batches (changes in operator, differences in reagent quality) can result in systematic differences in the observed expression in cells from different batches, which are refered to as "batch effects". Such differences are not interesting and can be problematic as they can be major drivers of heterogeneity in the data, masking the relevant biological differences and complicating interpretation of the results.

## Step 5.1 | Identifying confounding and technical factors
As we have mentioned, a big source of variability in scRNA-seq data, besides bad cells, are batch effects: the person processing the samples, date of processing, reagent kit, etc. We want to try to identify such effects and remove them, so our analysis picks up mainly biological effects.

### 5.1.1 | Screening for obvious biases with the table function
The `table` and `summary` functions allow us to quickly inspect if we have any obvious biases or confounds (i.e. all the cells come from male or female mice, or from a particular location or sequencing batch).
```{r}
table(PAG_sceset_qc_norm_filt$cell.type, PAG_sceset_qc_norm_filt$PAG.hemisphere)
table(PAG_sceset_qc_norm_filt$cell.type, PAG_sceset_qc_norm_filt$PAG.arearegistration)
table(PAG_sceset_qc_norm_filt$cell.type, PAG_sceset_qc_norm_filt$PAG.APaxis)
table(PAG_sceset_qc_norm_filt$cell.type, PAG_sceset_qc_norm_filt$mouse.sex)
table(PAG_sceset_qc_norm_filt$cell.type, PAG_sceset_qc_norm_filt$mouse.id)
table(PAG_sceset_qc_norm_filt$cell.type, PAG_sceset_qc_norm_filt$batch.processing)
```

```{r}
summary(PAG_sceset_qc_norm_filt$cell.type)
summary(PAG_sceset_qc_norm_filt$PAG.hemisphere)
summary(PAG_sceset_qc_norm_filt$PAG.areacollection)
summary(PAG_sceset_qc_norm_filt$mouse.sex)
summary(PAG_sceset_qc_norm_filt$PAG.arearegistration)
```

### 5.1.2 | Checking for important technical factors or explanatory variables
We check whether there are technical factors that contribute substantially to the heterogeneity of gene expression. If so, the factor may need to be regressed out to ensure that it does not inflate the variances or introduce spurious correlations. scater can compute the marginal R^2^ for each variable when fitting a linear model regressing expression values for each gene against just that variable, and display a density plot of the gene-wise marginal R^2^ values for the variables.

For each gene, it calculates the percentage of the variance of the expression values that is explained by the variable. Small percentages (1-3%) indicate that the expression profiles of most genes are not strongly associated with this factor. If, on the other hand, we get density curves that are shifted to the right (i.e. with a peak towards the 100% end of the x-axis), this tells us that for a large proportion of the genes in our dataset this particular variable explains a large proportion of the variation.
```{r}
# How much of the variance does each variable explain? Some of these variables are calculated when we run the CalculateQC function from scater, and others are added by us in the metadata (such as batch or individual).

# After scran normalization
plotExplanatoryVariables(PAG_sceset_qc_norm_filt,
                         nvars_to_plot = 16,
                         exprs_values = "logcounts",
                         variables = c("mouse.id",
                                       "mouse.sex",
                                       "mouse.age",
                                       "mouse.singlehousedays",
                                       "cell.type",
                                       "cell.fluorophor",
                                       "slice.number",
                                       "slice.depth",
                                       "PAG.areacollection",
                                       "PAG.hemisphere",
                                       "PAG.APaxis",
                                       "time.sinceslicinghour",
                                       "batch.processing",
                                       "batch.sequencing_round",
                                       "total_features_by_counts",
                                       "total_counts"
                                       )
                         ) + ggtitle("scran")

# To check how the explanatory variables change before normalization, run the same using `exprs_values = "counts" + ggtitle("Raw counts")` or `exprs_values = "logcounts_raw" + ggtitle("Logcounts Raw")` and `multiplot(explV1, explV2, explV3, cols=1)`.
```

We can see that the two variables standing out are `batch.processing` and `mouse.id`. This makes perfect sense, as they illustrate how the cells were acquired and processed. Due to the way we isolated cells, however, `mouse.id` is confounded with `cell.type`: each transgenic mouse labeled either VGAT or VGluT2 neurons, which means that if we regress out the variability in `mouse.id` we will also be removing much of the biology linked to the `cell.type` that came from each mouse.

A better option would be to regress out the `batch.processing`, but only half of our samples were assigned to a balanced design. For the other half, all the cells obtained from the same animal were processed together, thereby confounding the `batch.processing` with the `mouse.id` (and by extension with `cell.type`) and leading to a similar scenario as above. However, this might be the best option we have, so we will regress out `batch.processing` and compare the results without the correction.

## Step 5.2 | Batch Correction (dealing with confounders)
Small uncontrollable differences in processing between plates can result in a batch effect, i.e., systematic differences in expression between cells on different plates. Computational correction of these effects is critical for eliminating batch-to-batch variation, allowing data across multiple batches to be combined for valid downstream analysis. One method to achieve this is `removeBatchEffect()` from the __limma__ package (Ritchie et al. 2015). `removeBatchEffect()` performs a linear regression and sets the coefficients corresponding to the blocking factors to zero. This is effective provided that the population composition within each batch is either known (and supplied as `design=`) or identical across batches. In our case we know exactly which cell type ended up in each batch. 

In most scRNA-seq applications, however, the factors of variation are not identical across batches and not known in advance. This motivates the use of more sophisticated batch correction methods such as `mnnCorrect()`, based on the detection of mutual nearest neighbours (MNNs) (Haghverdi et al. 2018). The MNN approach does not rely on pre-defined or equal population compositions across batches, only requiring that a subset of the population be shared between batches. In our case, each animal could be treated as a separate batch in their own right, reflecting (presumably uninteresting) biological differences due to genotype, age, sex or other factors that are inherent to our experimental design. `mnnCorrect()` was developed to merge different datasets obtained from the same biological system. It assumes that each batch shares at least one biological condition with each other batch, thus it works well for a variety of balanced experimental designs. However, in a confounded/replicate design biological effects will not be fit/preserved and we will only be able to remove batch effects from each individual separately in order to preserve biological (and technical) variance between individuals.

Batch correction is necessary for downstream procedures that are not model-based, e.g., clustering and most forms of dimensionality reduction. However, if an analysis method can accept a design matrix (such as differential expression analysis), blocking on nuisance factors in the design matrix is preferable to using `removeBatchEffect()`. This is because the latter does not account for the loss of residual degrees of freedom, nor the uncertainty of estimation of the blocking factor terms. For our experimental design, `removeBatchEffect()` seems more appropriate than `mnnCorrect()`. Whereas we know the exact composition of each batch and can provide in the `batch` argument of `removeBatchEffect()`, the main requirement for `mnnCorrect()` is unfortunately not fulfilled, as each batch contains only one of two possible cell types. We will apply `removeBatchEffect()` in our dataset and store the results in a new slot so that we can compare them in our clustering analysis. 

*Important:* The OSCA book suggests limiting the use of per-gene corrected values to visualization, e.g., when coloring points on a t-SNE plot by per-cell expression. This can be more aesthetically pleasing than uncorrected expression values that may contain large shifts on the colour scale between cells in different batches. Use of the corrected values in any quantitative procedure should be treated with caution, and should be backed up by similar results from an analysis on the uncorrected values. For gene-based procedures like differential expression (DE) analyses or gene network construction, it is desirable to use the original log-expression values or counts with batch effects being handled explicitly using blocking terms or via a meta-analysis across batches. 

### 5.2.1 | Applying removeBatchEffect()
`removeBatchEffect()` performs a linear regression and sets the coefficients corresponding to the blocking factors to zero. This function is useful for removing batch effects associated with technical variables prior to clustering or unsupervised analysis such as PCA, MDS or heatmaps. The design matrix is used to describe comparisons between the samples, for example treatment effects, which should not be removed. The function fits a linear model to the data, including both batches and regular treatments, then removes the component due to the batch effects.

This method is effective provided that the population composition within each batch is known (and supplied as `design=`) or identical across batches. In our case, the composition of our cell population is __not__ identical across batches, as each batch comes from one transgenic mouse and thus has only one out of two possible cell types. However, individually aspirating cells based on expression of a transgene has the advantage that it allows us to know exactly the composition of each batch, so we can set the `design` and `batch` arguments as follows:
```{r}
library(limma)
assay(PAG_sceset_qc_norm_filt, "corrected") <- removeBatchEffect(logcounts(PAG_sceset_qc_norm_filt),
                                                                 design = model.matrix(~PAG_sceset_qc_norm_filt$PAGarea_celltype),
                                                                 batch = PAG_sceset_qc_norm_filt$batch.processing)
assayNames(PAG_sceset_qc_norm_filt)
```

### 5.2.2 | Effectiveness of the correction
We can evaluate the effectiveness of the correction by inspecting the PCA plot where colour corresponds the technical replicates and shape corresponds to the individuals from which biological samples where acquired. Separation of biological samples and interspersed batches indicates that technical variation has been removed.

*[IMP]*: If `feature_set=NULL`, the `ntop` features with the largest variances are used instead. This literally computes the variances from the expression values without considering any mean-variance trend. Note that the value of `ntop` is ignored if `feature_set` is specified. Given that we have fitted a mean-variance trend and obtained highly variable genes from it, we will use our HVG instead of using the `ntop` option.
```{r}
for(n in assayNames(PAG_sceset_qc_norm_filt)) {
    print(
        plotPCA(
            PAG_sceset_qc_norm_filt,
            rerun = TRUE, 
            colour_by = "PAG.areacollection",
            shape_by = "cell.type",
            size_by = "total_features_by_counts",
            run_args = list(exprs_values = n, feature_set = metadata(PAG_sceset_qc_norm_filt)$hvg_out_no_spikes_filt[1:1000]) # ntop = 1000
        ) + ggtitle(n) 
        + coord_cartesian(xlim = c(-35, 35), ylim = c(-35, 35))
        #+ coord_cartesian(xlim = c(-50, 50), ylim = c(-60, 60))
    )
}
```

```{r}
# How much of the variance does each variable explain? Some of these variables are calculated when we run the CalculateQC function from scater, and others are added by us in the metadata (such as batch or individual).
for(n in assayNames(PAG_sceset_qc_norm_filt)) {
    print(
      plotExplanatoryVariables(PAG_sceset_qc_norm_filt,
                               nvars_to_plot = 16,
                               exprs_values = n,
                               variables = c("mouse.id",
                                             "mouse.sex",
                                             "mouse.age",
                                             "mouse.singlehousedays",
                                             "cell.type",
                                             "cell.fluorophor",
                                             "slice.number",
                                             "slice.depth",
                                             "PAG.areacollection",
                                             "PAG.hemisphere",
                                             "PAG.APaxis",
                                             "time.sinceslicinghour",
                                             "batch.processing",
                                             "batch.sequencing_round",
                                             "total_features_by_counts",
                                             "total_counts")
                               ) + ggtitle(n)
      ) 
}
```

## Step 5.3 | Correlations with Principal Components - Choosing the number of PCs
`scater` allows us to identify principal components that correlate with experimental and QC variables of interest (it ranks principle components by R^2^ from a linear model regressing PC value against any variable or annotation we have associated with each cell) to see which factor is driving a particular principal component.
```{r}
plotExplanatoryPCs(PAG_sceset_qc_norm_filt,
                   nvars_to_plot = 16,
                   npcs_to_plot = 20,                 
                   variables = c("mouse.id",
                                 "mouse.sex",
                                 "mouse.age",
                                 "mouse.singlehousedays",
                                 "cell.type",
                                 "cell.fluorophor",
                                 "slice.number",
                                 "slice.depth",
                                 "PAG.areacollection",
                                 "PAG.hemisphere",
                                 "PAG.APaxis",
                                 "time.sinceslicinghour",
                                 "batch.processing",
                                 "batch.sequencing_round",
                                 "total_features_by_counts",
                                 "total_counts"
                                 )
                   )
```

## Step 5.4 | Denoising expression values using PCA
Once the technical noise is modelled and we have corrected our batch effects, we can use principal component analysis (PCA) to remove random technical noise. Consider that each cell represents a point in the high-dimensional expression space, where the spread of points represents the total variance. PCA identifies axes in this space that capture as much of this variance as possible. Each axis is a principal component (PC), where any early PC will explain more of the variance than a later PC.

We assume that biological processes involving co-regulated groups of genes will account for the most variance in the data. If this is the case, this process should be represented by one or more of the earlier PCs. In contrast, random technical noise affects each gene independently and will be represented by later PCs. The `denoisePCA()` function removes later PCs until the total discarded variance is equal to the sum of technical components for all genes used in the PCA.

We use all genes with a positive biological component in `denoisePCA()` and perform PCA on the expression profiles, choosing the number of PCs to retain based on the total technical noise in the data set. The idea is to discard later PCs that contain random technical noise, thus enriching for early biological signal (and also reducing work in downstream steps).

* `denoisePCA()` will only use genes that have positive biological components, i.e., variances greater than the fitted trend. This guarantees that the total technical variance to be discarded will not be greater than the total variance in the data.
* For the `technical=` argument, the function will also accept the trend function directly (i.e., `var.fit$trend`) or a vector of technical components per gene. Here, we supply the  DataFrame from `decomposeVar()` to allow the function to adjust for the loss of residual degrees of freedom after batch correction. Specifically, the variance in the batch-corrected matrix is slightly understated, requiring some rescaling of the technical components to compensate.
* No filtering is performed on abundance here, which ensures that PCs corresponding to rare subpopulations can still be detected. Discreteness is less of an issue as low-abundance genes also have lower variance, thus reducing their contribution to the PCA.
* It is also possible to obtain a low-rank approximation of the original expression matrix, capturing the variance equivalent to the retained PCs. This is useful for denoising prior to downstream procedures that require gene-wise expression values.
```{r}
# We need to remove the genes we filtered from the var_out object, otherwise the dimensions between var_out and PAG_sceset_qc_norm_filt will be different and denoisePCA will not work
dim(PAG_sceset_qc_norm_filt)
dim(var_out_no_spikes)
var_out_no_spikes$filter <- rownames(var_out_no_spikes) %in% rownames(PAG_sceset_qc_norm_filt)
dim(var_out_no_spikes)
var_out_no_spikes_filt <- var_out_no_spikes[var_out_no_spikes$filter==TRUE, ]
nrow(var_out_no_spikes_filt)

# Run denoisePCA
PAG_sceset_qc_norm_filt_corr <- denoisePCA(PAG_sceset_qc_norm_filt,
                                           technical = var_out_no_spikes_filt, 
                                           assay.type = "corrected")

dim(reducedDim(PAG_sceset_qc_norm_filt_corr, "PCA")) # Cells are rows, PCs are columns
```

The function returns a `SingleCellExperiment` object containing the PC scores for each cell in the `reducedDims` slot, where cells are rows and PCs are columns. The aim is to eliminate technical noise and enrich for biological signal in the retained PCs. This improves resolution of the underlying biology during downstream procedures such as clustering.

We can also look at the proportion of variance explained by each PC and keep the components before the "elbow":
```{r}
principal_components <- reducedDim(PAG_sceset_qc_norm_filt_corr, "PCA")
proportion_var <- attr(principal_components, "percentVar")
plot(proportion_var, xlab="PC", ylab="Proportion of variance explained")
```

## Step 5.5 | Save the filtered, corrected, and denoised SingleCellExperiment object
```{r}
# Save the normalized data:
saveRDS(PAG_sceset_qc_norm_filt_corr, file = "PAG_sceset_qc_norm_filt_corr.rds")
print("Part 5 - Done!")
```

```{r}
sessionInfo()
```
